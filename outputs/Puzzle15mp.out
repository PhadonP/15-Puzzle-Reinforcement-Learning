Preparation of Training Data time: 27.600 seconds
TRAINING: | Iteration [1/12] | Loss 0.59 | Norm 5.000
TRAINING: | Iteration [2/12] | Loss 10.92 | Norm 5.000
TRAINING: | Iteration [3/12] | Loss 4.38 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 6.62 | Norm 5.000
TRAINING: | Iteration [5/12] | Loss 3.68 | Norm 5.000
TRAINING: | Iteration [6/12] | Loss 2.17 | Norm 5.000
TRAINING: | Iteration [7/12] | Loss 1.27 | Norm 5.000
TRAINING: | Iteration [8/12] | Loss 1.11 | Norm 5.000
TRAINING: | Iteration [9/12] | Loss 1.04 | Norm 5.000
TRAINING: | Iteration [10/12] | Loss 1.04 | Norm 5.000
TRAINING: | Iteration [11/12] | Loss 0.76 | Norm 5.000
TRAINING: | Iteration [12/12] | Loss 0.76 | Norm 5.000
Epoch: 1/10000 | Epoch Time: 0.110 seconds
TRAINING: | Iteration [1/12] | Loss 0.84 | Norm 4.842
TRAINING: | Iteration [2/12] | Loss 0.71 | Norm 4.975
TRAINING: | Iteration [3/12] | Loss 0.67 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 0.78 | Norm 3.658
TRAINING: | Iteration [5/12] | Loss 0.66 | Norm 3.399
TRAINING: | Iteration [6/12] | Loss 0.55 | Norm 4.213
TRAINING: | Iteration [7/12] | Loss 0.56 | Norm 2.621
TRAINING: | Iteration [8/12] | Loss 0.53 | Norm 3.127
TRAINING: | Iteration [9/12] | Loss 0.56 | Norm 4.296
TRAINING: | Iteration [10/12] | Loss 0.64 | Norm 2.908
TRAINING: | Iteration [11/12] | Loss 0.57 | Norm 2.075
TRAINING: | Iteration [12/12] | Loss 0.46 | Norm 3.252
Epoch: 2/10000 | Epoch Time: 0.097 seconds
TRAINING: | Iteration [1/12] | Loss 0.53 | Norm 2.734
TRAINING: | Iteration [2/12] | Loss 0.51 | Norm 4.686
TRAINING: | Iteration [3/12] | Loss 0.57 | Norm 4.295
TRAINING: | Iteration [4/12] | Loss 0.51 | Norm 3.550
TRAINING: | Iteration [5/12] | Loss 0.46 | Norm 4.865
TRAINING: | Iteration [6/12] | Loss 0.47 | Norm 3.318
TRAINING: | Iteration [7/12] | Loss 0.41 | Norm 4.467
TRAINING: | Iteration [8/12] | Loss 0.49 | Norm 4.105
TRAINING: | Iteration [9/12] | Loss 0.42 | Norm 3.610
TRAINING: | Iteration [10/12] | Loss 0.29 | Norm 1.681
TRAINING: | Iteration [11/12] | Loss 0.38 | Norm 2.605
TRAINING: | Iteration [12/12] | Loss 0.35 | Norm 3.155
Epoch: 3/10000 | Epoch Time: 0.097 seconds
TRAINING: | Iteration [1/12] | Loss 0.41 | Norm 2.688
TRAINING: | Iteration [2/12] | Loss 0.40 | Norm 3.502
TRAINING: | Iteration [3/12] | Loss 0.38 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 0.36 | Norm 3.401
TRAINING: | Iteration [5/12] | Loss 0.36 | Norm 2.232
TRAINING: | Iteration [6/12] | Loss 0.34 | Norm 3.252
TRAINING: | Iteration [7/12] | Loss 0.31 | Norm 2.736
TRAINING: | Iteration [8/12] | Loss 0.35 | Norm 3.687
TRAINING: | Iteration [9/12] | Loss 0.32 | Norm 2.322
TRAINING: | Iteration [10/12] | Loss 0.30 | Norm 1.992
TRAINING: | Iteration [11/12] | Loss 0.32 | Norm 1.984
TRAINING: | Iteration [12/12] | Loss 0.31 | Norm 5.000
Epoch: 4/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.30 | Norm 2.787
TRAINING: | Iteration [2/12] | Loss 0.24 | Norm 2.052
TRAINING: | Iteration [3/12] | Loss 0.31 | Norm 2.985
TRAINING: | Iteration [4/12] | Loss 0.27 | Norm 1.741
TRAINING: | Iteration [5/12] | Loss 0.32 | Norm 4.633
TRAINING: | Iteration [6/12] | Loss 0.20 | Norm 2.657
TRAINING: | Iteration [7/12] | Loss 0.28 | Norm 3.706
TRAINING: | Iteration [8/12] | Loss 0.27 | Norm 2.533
TRAINING: | Iteration [9/12] | Loss 0.23 | Norm 4.876
TRAINING: | Iteration [10/12] | Loss 0.23 | Norm 1.759
TRAINING: | Iteration [11/12] | Loss 0.20 | Norm 1.776
TRAINING: | Iteration [12/12] | Loss 0.21 | Norm 2.492
Epoch: 5/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.24 | Norm 1.781
TRAINING: | Iteration [2/12] | Loss 0.24 | Norm 2.114
TRAINING: | Iteration [3/12] | Loss 0.21 | Norm 1.229
TRAINING: | Iteration [4/12] | Loss 0.22 | Norm 3.514
TRAINING: | Iteration [5/12] | Loss 0.19 | Norm 4.255
TRAINING: | Iteration [6/12] | Loss 0.17 | Norm 3.275
TRAINING: | Iteration [7/12] | Loss 0.22 | Norm 4.132
TRAINING: | Iteration [8/12] | Loss 0.25 | Norm 5.000
TRAINING: | Iteration [9/12] | Loss 0.15 | Norm 2.126
TRAINING: | Iteration [10/12] | Loss 0.23 | Norm 1.900
TRAINING: | Iteration [11/12] | Loss 0.21 | Norm 3.256
TRAINING: | Iteration [12/12] | Loss 0.25 | Norm 5.000
Epoch: 6/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.19 | Norm 1.573
TRAINING: | Iteration [2/12] | Loss 0.21 | Norm 4.714
TRAINING: | Iteration [3/12] | Loss 0.20 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 0.22 | Norm 5.000
TRAINING: | Iteration [5/12] | Loss 0.15 | Norm 1.882
TRAINING: | Iteration [6/12] | Loss 0.17 | Norm 5.000
TRAINING: | Iteration [7/12] | Loss 0.16 | Norm 4.734
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 3.462
TRAINING: | Iteration [9/12] | Loss 0.14 | Norm 2.275
TRAINING: | Iteration [10/12] | Loss 0.15 | Norm 3.285
TRAINING: | Iteration [11/12] | Loss 0.19 | Norm 3.463
TRAINING: | Iteration [12/12] | Loss 0.17 | Norm 4.391
Epoch: 7/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.17 | Norm 2.844
TRAINING: | Iteration [2/12] | Loss 0.20 | Norm 2.138
TRAINING: | Iteration [3/12] | Loss 0.23 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 0.16 | Norm 4.451
TRAINING: | Iteration [5/12] | Loss 0.18 | Norm 2.111
TRAINING: | Iteration [6/12] | Loss 0.15 | Norm 4.500
TRAINING: | Iteration [7/12] | Loss 0.16 | Norm 1.608
TRAINING: | Iteration [8/12] | Loss 0.16 | Norm 3.568
TRAINING: | Iteration [9/12] | Loss 0.15 | Norm 1.430
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 3.240
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 1.522
TRAINING: | Iteration [12/12] | Loss 0.16 | Norm 2.096
Epoch: 8/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.18 | Norm 2.835
TRAINING: | Iteration [2/12] | Loss 0.14 | Norm 1.744
TRAINING: | Iteration [3/12] | Loss 0.16 | Norm 1.283
TRAINING: | Iteration [4/12] | Loss 0.14 | Norm 1.098
TRAINING: | Iteration [5/12] | Loss 0.17 | Norm 1.860
TRAINING: | Iteration [6/12] | Loss 0.16 | Norm 2.535
TRAINING: | Iteration [7/12] | Loss 0.22 | Norm 1.958
TRAINING: | Iteration [8/12] | Loss 0.18 | Norm 1.772
TRAINING: | Iteration [9/12] | Loss 0.15 | Norm 1.471
TRAINING: | Iteration [10/12] | Loss 0.24 | Norm 2.433
TRAINING: | Iteration [11/12] | Loss 0.22 | Norm 4.095
TRAINING: | Iteration [12/12] | Loss 0.15 | Norm 2.482
Epoch: 9/10000 | Epoch Time: 0.095 seconds
TRAINING: | Iteration [1/12] | Loss 0.17 | Norm 3.860
TRAINING: | Iteration [2/12] | Loss 0.15 | Norm 5.000
TRAINING: | Iteration [3/12] | Loss 0.16 | Norm 1.592
TRAINING: | Iteration [4/12] | Loss 0.17 | Norm 1.385
TRAINING: | Iteration [5/12] | Loss 0.18 | Norm 3.845
TRAINING: | Iteration [6/12] | Loss 0.17 | Norm 5.000
TRAINING: | Iteration [7/12] | Loss 0.16 | Norm 1.110
TRAINING: | Iteration [8/12] | Loss 0.21 | Norm 3.290
TRAINING: | Iteration [9/12] | Loss 0.16 | Norm 4.634
TRAINING: | Iteration [10/12] | Loss 0.19 | Norm 1.246
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 1.051
TRAINING: | Iteration [12/12] | Loss 0.19 | Norm 5.000
Epoch: 10/10000 | Epoch Time: 0.094 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.15 | Norm 1.084
TRAINING: | Iteration [2/12] | Loss 0.21 | Norm 2.757
TRAINING: | Iteration [3/12] | Loss 0.18 | Norm 3.494
TRAINING: | Iteration [4/12] | Loss 0.18 | Norm 3.821
TRAINING: | Iteration [5/12] | Loss 0.18 | Norm 2.846
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 2.044
TRAINING: | Iteration [7/12] | Loss 0.18 | Norm 2.839
TRAINING: | Iteration [8/12] | Loss 0.15 | Norm 2.814
TRAINING: | Iteration [9/12] | Loss 0.19 | Norm 3.201
TRAINING: | Iteration [10/12] | Loss 0.16 | Norm 3.104
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 1.798
TRAINING: | Iteration [12/12] | Loss 0.18 | Norm 2.364
Epoch: 11/10000 | Epoch Time: 0.095 seconds
TRAINING: | Iteration [1/12] | Loss 0.22 | Norm 3.808
TRAINING: | Iteration [2/12] | Loss 0.19 | Norm 2.543
TRAINING: | Iteration [3/12] | Loss 0.18 | Norm 2.376
TRAINING: | Iteration [4/12] | Loss 0.19 | Norm 3.236
TRAINING: | Iteration [5/12] | Loss 0.15 | Norm 4.174
TRAINING: | Iteration [6/12] | Loss 0.16 | Norm 2.518
TRAINING: | Iteration [7/12] | Loss 0.19 | Norm 3.743
TRAINING: | Iteration [8/12] | Loss 0.21 | Norm 5.000
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 2.048
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 2.025
TRAINING: | Iteration [11/12] | Loss 0.16 | Norm 1.075
TRAINING: | Iteration [12/12] | Loss 0.18 | Norm 3.937
Epoch: 12/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.15 | Norm 1.440
TRAINING: | Iteration [2/12] | Loss 0.17 | Norm 2.340
TRAINING: | Iteration [3/12] | Loss 0.17 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 2.242
TRAINING: | Iteration [5/12] | Loss 0.14 | Norm 1.503
TRAINING: | Iteration [6/12] | Loss 0.14 | Norm 1.490
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 1.349
TRAINING: | Iteration [8/12] | Loss 0.22 | Norm 5.000
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 2.226
TRAINING: | Iteration [10/12] | Loss 0.17 | Norm 4.164
TRAINING: | Iteration [11/12] | Loss 0.15 | Norm 4.508
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 1.289
Epoch: 13/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 2.830
TRAINING: | Iteration [2/12] | Loss 0.15 | Norm 1.637
TRAINING: | Iteration [3/12] | Loss 0.14 | Norm 2.633
TRAINING: | Iteration [4/12] | Loss 0.18 | Norm 5.000
TRAINING: | Iteration [5/12] | Loss 0.19 | Norm 3.759
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 1.373
TRAINING: | Iteration [7/12] | Loss 0.21 | Norm 3.261
TRAINING: | Iteration [8/12] | Loss 0.16 | Norm 4.999
TRAINING: | Iteration [9/12] | Loss 0.14 | Norm 2.355
TRAINING: | Iteration [10/12] | Loss 0.15 | Norm 3.900
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 2.389
TRAINING: | Iteration [12/12] | Loss 0.16 | Norm 5.000
Epoch: 14/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.14 | Norm 3.402
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 1.425
TRAINING: | Iteration [3/12] | Loss 0.15 | Norm 3.808
TRAINING: | Iteration [4/12] | Loss 0.14 | Norm 3.422
TRAINING: | Iteration [5/12] | Loss 0.16 | Norm 4.524
TRAINING: | Iteration [6/12] | Loss 0.14 | Norm 3.365
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 2.491
TRAINING: | Iteration [8/12] | Loss 0.16 | Norm 1.292
TRAINING: | Iteration [9/12] | Loss 0.15 | Norm 3.993
TRAINING: | Iteration [10/12] | Loss 0.16 | Norm 2.686
TRAINING: | Iteration [11/12] | Loss 0.15 | Norm 3.838
TRAINING: | Iteration [12/12] | Loss 0.16 | Norm 3.805
Epoch: 15/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 1.342
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 2.570
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 4.656
TRAINING: | Iteration [4/12] | Loss 0.14 | Norm 2.150
TRAINING: | Iteration [5/12] | Loss 0.19 | Norm 1.732
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 1.367
TRAINING: | Iteration [7/12] | Loss 0.13 | Norm 3.508
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 2.095
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 1.485
TRAINING: | Iteration [10/12] | Loss 0.16 | Norm 4.209
TRAINING: | Iteration [11/12] | Loss 0.16 | Norm 2.587
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 2.490
Epoch: 16/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 2.008
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 2.204
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 2.649
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 3.221
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 1.571
TRAINING: | Iteration [6/12] | Loss 0.14 | Norm 4.078
TRAINING: | Iteration [7/12] | Loss 0.14 | Norm 1.107
TRAINING: | Iteration [8/12] | Loss 0.17 | Norm 4.858
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 5.000
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 1.845
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 2.047
TRAINING: | Iteration [12/12] | Loss 0.20 | Norm 5.000
Epoch: 17/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.16 | Norm 3.923
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 2.962
TRAINING: | Iteration [3/12] | Loss 0.14 | Norm 3.896
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 2.444
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 4.465
TRAINING: | Iteration [6/12] | Loss 0.15 | Norm 3.966
TRAINING: | Iteration [7/12] | Loss 0.15 | Norm 2.883
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 3.557
TRAINING: | Iteration [9/12] | Loss 0.16 | Norm 5.000
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 4.136
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 1.788
TRAINING: | Iteration [12/12] | Loss 0.15 | Norm 2.297
Epoch: 18/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 2.724
TRAINING: | Iteration [2/12] | Loss 0.15 | Norm 5.000
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.513
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.064
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 1.424
TRAINING: | Iteration [6/12] | Loss 0.19 | Norm 5.000
TRAINING: | Iteration [7/12] | Loss 0.13 | Norm 4.508
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 4.017
TRAINING: | Iteration [9/12] | Loss 0.15 | Norm 3.720
TRAINING: | Iteration [10/12] | Loss 0.16 | Norm 3.814
TRAINING: | Iteration [11/12] | Loss 0.17 | Norm 5.000
TRAINING: | Iteration [12/12] | Loss 0.15 | Norm 4.486
Epoch: 19/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.16 | Norm 5.000
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 1.280
TRAINING: | Iteration [3/12] | Loss 0.14 | Norm 2.370
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 1.874
TRAINING: | Iteration [5/12] | Loss 0.19 | Norm 5.000
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 2.998
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.675
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 1.849
TRAINING: | Iteration [9/12] | Loss 0.14 | Norm 4.918
TRAINING: | Iteration [10/12] | Loss 0.15 | Norm 2.056
TRAINING: | Iteration [11/12] | Loss 0.14 | Norm 2.326
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 1.940
Epoch: 20/10000 | Epoch Time: 0.094 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 1.908
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 2.253
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 0.988
TRAINING: | Iteration [4/12] | Loss 0.14 | Norm 5.000
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 1.872
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 1.820
TRAINING: | Iteration [7/12] | Loss 0.14 | Norm 2.210
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 1.827
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 2.340
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 1.886
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 4.191
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 3.912
Epoch: 21/10000 | Epoch Time: 0.095 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 2.100
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 1.655
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 3.539
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 3.682
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 4.086
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 3.427
TRAINING: | Iteration [7/12] | Loss 0.15 | Norm 5.000
TRAINING: | Iteration [8/12] | Loss 0.15 | Norm 5.000
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 4.329
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 3.141
TRAINING: | Iteration [11/12] | Loss 0.19 | Norm 5.000
TRAINING: | Iteration [12/12] | Loss 0.18 | Norm 5.000
Epoch: 22/10000 | Epoch Time: 0.095 seconds
TRAINING: | Iteration [1/12] | Loss 0.15 | Norm 4.914
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 1.945
TRAINING: | Iteration [3/12] | Loss 0.17 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 0.18 | Norm 5.000
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 4.053
TRAINING: | Iteration [6/12] | Loss 0.17 | Norm 5.000
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 1.846
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 1.992
TRAINING: | Iteration [9/12] | Loss 0.16 | Norm 5.000
TRAINING: | Iteration [10/12] | Loss 0.20 | Norm 5.000
TRAINING: | Iteration [11/12] | Loss 0.16 | Norm 4.977
TRAINING: | Iteration [12/12] | Loss 0.18 | Norm 4.519
Epoch: 23/10000 | Epoch Time: 0.095 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 2.044
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 5.000
TRAINING: | Iteration [3/12] | Loss 0.14 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 0.15 | Norm 5.000
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 3.092
TRAINING: | Iteration [6/12] | Loss 0.15 | Norm 4.814
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.069
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 5.000
TRAINING: | Iteration [9/12] | Loss 0.16 | Norm 5.000
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 5.000
TRAINING: | Iteration [11/12] | Loss 0.15 | Norm 5.000
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 3.979
Epoch: 24/10000 | Epoch Time: 0.095 seconds
TRAINING: | Iteration [1/12] | Loss 0.14 | Norm 4.763
TRAINING: | Iteration [2/12] | Loss 0.14 | Norm 1.637
TRAINING: | Iteration [3/12] | Loss 0.16 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 0.24 | Norm 5.000
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 1.842
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 4.005
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 1.332
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 3.162
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 4.423
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 2.024
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 2.604
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 3.987
Epoch: 25/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.18 | Norm 5.000
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 5.000
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 1.096
TRAINING: | Iteration [4/12] | Loss 0.16 | Norm 2.901
TRAINING: | Iteration [5/12] | Loss 0.16 | Norm 5.000
TRAINING: | Iteration [6/12] | Loss 0.21 | Norm 5.000
TRAINING: | Iteration [7/12] | Loss 0.13 | Norm 5.000
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.543
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 2.130
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 2.141
TRAINING: | Iteration [11/12] | Loss 0.18 | Norm 5.000
TRAINING: | Iteration [12/12] | Loss 0.19 | Norm 5.000
Epoch: 26/10000 | Epoch Time: 0.095 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 2.887
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 1.159
TRAINING: | Iteration [3/12] | Loss 0.16 | Norm 3.319
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 1.744
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 3.075
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 2.735
TRAINING: | Iteration [7/12] | Loss 0.16 | Norm 3.212
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 2.575
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 0.982
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 3.619
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 1.754
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.239
Epoch: 27/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 5.000
TRAINING: | Iteration [2/12] | Loss 0.17 | Norm 5.000
TRAINING: | Iteration [3/12] | Loss 0.16 | Norm 2.065
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 2.096
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 1.175
TRAINING: | Iteration [6/12] | Loss 0.14 | Norm 1.751
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 3.240
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.475
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 3.999
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 3.558
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 4.928
TRAINING: | Iteration [12/12] | Loss 0.16 | Norm 5.000
Epoch: 28/10000 | Epoch Time: 0.095 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 1.720
TRAINING: | Iteration [2/12] | Loss 0.19 | Norm 5.000
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 4.459
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 5.000
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.760
TRAINING: | Iteration [6/12] | Loss 0.16 | Norm 5.000
TRAINING: | Iteration [7/12] | Loss 0.14 | Norm 5.000
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 5.000
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 2.166
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 0.939
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.567
TRAINING: | Iteration [12/12] | Loss 0.16 | Norm 4.875
Epoch: 29/10000 | Epoch Time: 0.095 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 2.936
TRAINING: | Iteration [2/12] | Loss 0.14 | Norm 2.016
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 2.291
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 2.591
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 2.045
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 1.904
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 3.648
TRAINING: | Iteration [8/12] | Loss 0.17 | Norm 5.000
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.188
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 2.078
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 2.291
TRAINING: | Iteration [12/12] | Loss 0.17 | Norm 5.000
Epoch: 30/10000 | Epoch Time: 0.094 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 5.000
TRAINING: | Iteration [2/12] | Loss 0.23 | Norm 5.000
TRAINING: | Iteration [3/12] | Loss 0.14 | Norm 4.257
TRAINING: | Iteration [4/12] | Loss 0.15 | Norm 5.000
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 4.361
TRAINING: | Iteration [6/12] | Loss 0.14 | Norm 4.057
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 1.224
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 3.407
TRAINING: | Iteration [9/12] | Loss 0.19 | Norm 4.762
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 3.733
TRAINING: | Iteration [11/12] | Loss 0.15 | Norm 5.000
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.935
Epoch: 31/10000 | Epoch Time: 0.096 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 2.992
TRAINING: | Iteration [2/12] | Loss 0.15 | Norm 3.654
TRAINING: | Iteration [3/12] | Loss 0.18 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 0.14 | Norm 2.185
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 2.312
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 2.459
TRAINING: | Iteration [7/12] | Loss 0.15 | Norm 5.000
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.897
TRAINING: | Iteration [9/12] | Loss 0.18 | Norm 5.000
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 2.310
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.131
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 2.859
Epoch: 32/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 2.569
TRAINING: | Iteration [2/12] | Loss 0.17 | Norm 5.000
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 1.908
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.250
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.462
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 2.156
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 3.101
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 3.375
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 2.626
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 3.356
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 2.346
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 2.515
Epoch: 33/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 2.296
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 1.517
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 2.461
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 2.045
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 3.532
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.371
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.736
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 2.973
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 4.987
TRAINING: | Iteration [10/12] | Loss 0.16 | Norm 5.000
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.548
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 2.611
Epoch: 34/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.960
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.228
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 3.567
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 5.000
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 4.250
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.379
TRAINING: | Iteration [7/12] | Loss 0.13 | Norm 5.000
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 3.008
TRAINING: | Iteration [9/12] | Loss 0.18 | Norm 5.000
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.743
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 3.410
TRAINING: | Iteration [12/12] | Loss 0.15 | Norm 5.000
Epoch: 35/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 4.842
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.444
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 2.353
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 1.207
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 5.000
TRAINING: | Iteration [7/12] | Loss 0.14 | Norm 5.000
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.703
TRAINING: | Iteration [9/12] | Loss 0.17 | Norm 5.000
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 1.503
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 3.551
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 5.000
Epoch: 36/10000 | Epoch Time: 0.095 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 5.000
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 1.771
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.640
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 3.532
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 2.869
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.027
TRAINING: | Iteration [7/12] | Loss 0.17 | Norm 5.000
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 1.560
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 3.085
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 2.080
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 3.682
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 5.000
Epoch: 37/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 1.219
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.407
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 3.512
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 4.880
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.753
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 1.029
TRAINING: | Iteration [7/12] | Loss 0.14 | Norm 1.736
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 3.678
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 2.942
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 3.093
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.385
TRAINING: | Iteration [12/12] | Loss 0.15 | Norm 3.871
Epoch: 38/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 1.825
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.042
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 4.644
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 2.111
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 4.829
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 3.729
TRAINING: | Iteration [7/12] | Loss 0.16 | Norm 5.000
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 2.031
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 3.561
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 4.108
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 3.673
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 3.065
Epoch: 39/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.978
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.642
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 4.630
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 5.000
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.567
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 3.669
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.074
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 3.587
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 2.263
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.920
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.651
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 3.634
Epoch: 40/10000 | Epoch Time: 0.093 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 5.000
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 0.789
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 1.016
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.690
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 2.114
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 2.397
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 3.637
TRAINING: | Iteration [8/12] | Loss 0.16 | Norm 5.000
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 2.333
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 4.948
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.535
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.290
Epoch: 41/10000 | Epoch Time: 0.095 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 3.125
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 3.723
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.462
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 5.000
TRAINING: | Iteration [5/12] | Loss 0.14 | Norm 4.647
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 3.462
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 1.301
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.981
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 4.118
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 3.596
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.602
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.874
Epoch: 42/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 5.000
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 4.832
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.403
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.280
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 1.867
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 3.274
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 0.939
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 2.537
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 1.814
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.487
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.879
Epoch: 43/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.921
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 4.669
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.971
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 1.697
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 5.000
TRAINING: | Iteration [6/12] | Loss 0.17 | Norm 1.849
TRAINING: | Iteration [7/12] | Loss 0.17 | Norm 5.000
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.883
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 2.727
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 3.364
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 2.261
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 3.802
Epoch: 44/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.335
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 2.421
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 3.705
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.141
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.647
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.419
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 4.402
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 1.067
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 3.225
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 2.916
TRAINING: | Iteration [12/12] | Loss 0.15 | Norm 5.000
Epoch: 45/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.165
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.086
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.710
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 1.508
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.773
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 2.802
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.697
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 5.000
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.111
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 1.751
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.245
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.419
Epoch: 46/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 1.936
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 3.378
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 1.836
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 2.786
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 2.141
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 1.285
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 1.636
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 5.000
TRAINING: | Iteration [9/12] | Loss 0.14 | Norm 2.497
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.479
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 0.801
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 5.000
Epoch: 47/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.16 | Norm 5.000
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.897
TRAINING: | Iteration [3/12] | Loss 0.15 | Norm 4.514
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 4.750
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 3.415
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 3.387
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 2.183
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.742
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 3.026
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 3.834
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.228
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 3.595
Epoch: 48/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.578
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.338
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.314
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 2.414
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 3.832
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 2.565
TRAINING: | Iteration [7/12] | Loss 0.13 | Norm 2.551
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 1.391
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.131
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 2.259
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.242
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.142
Epoch: 49/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.562
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 1.581
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.638
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.356
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 4.403
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 1.780
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.111
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 3.084
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 1.693
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.954
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.614
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 2.956
Epoch: 50/10000 | Epoch Time: 0.095 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 3.608
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 5.000
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.187
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 3.662
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 2.697
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.642
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.404
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 1.818
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 2.305
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 3.558
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 4.720
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 3.363
Epoch: 51/10000 | Epoch Time: 0.095 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 3.228
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.307
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 3.277
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 3.343
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 3.744
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 2.364
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 3.713
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 5.000
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.781
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.096
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 2.232
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 1.806
Epoch: 52/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.034
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.256
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.080
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.638
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.988
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 2.538
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 2.565
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.830
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 5.000
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 4.820
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 3.318
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 4.571
Epoch: 53/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.855
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.244
TRAINING: | Iteration [3/12] | Loss 0.18 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 5.000
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 5.000
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.674
TRAINING: | Iteration [7/12] | Loss 0.15 | Norm 5.000
TRAINING: | Iteration [8/12] | Loss 0.17 | Norm 5.000
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 5.000
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 5.000
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 2.508
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 2.592
Epoch: 54/10000 | Epoch Time: 0.097 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.430
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 5.000
TRAINING: | Iteration [3/12] | Loss 0.20 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 5.000
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 2.770
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.995
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 3.071
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 4.172
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 2.235
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 2.894
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.255
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 4.556
Epoch: 55/10000 | Epoch Time: 0.096 seconds
TRAINING: | Iteration [1/12] | Loss 0.14 | Norm 2.339
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 1.968
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 3.568
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.690
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.637
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 1.367
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 3.674
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 2.370
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 4.348
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.634
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 2.978
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 2.699
Epoch: 56/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 5.000
TRAINING: | Iteration [2/12] | Loss 0.15 | Norm 4.331
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 2.239
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 3.366
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 3.739
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 2.719
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.800
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.968
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 3.374
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 4.310
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.549
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.989
Epoch: 57/10000 | Epoch Time: 0.095 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 3.863
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 3.918
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.826
TRAINING: | Iteration [4/12] | Loss 0.14 | Norm 5.000
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 2.184
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.102
TRAINING: | Iteration [7/12] | Loss 0.14 | Norm 1.854
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 2.946
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.868
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 5.000
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.176
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 2.299
Epoch: 58/10000 | Epoch Time: 0.095 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.564
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.342
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 2.723
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 3.769
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 3.067
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 1.308
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.261
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.085
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 2.652
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.752
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 0.608
TRAINING: | Iteration [12/12] | Loss 0.19 | Norm 5.000
Epoch: 59/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.448
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 3.009
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 3.426
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.385
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 4.774
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 4.549
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 4.622
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.642
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.287
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 2.980
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 4.417
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 4.159
Epoch: 60/10000 | Epoch Time: 0.094 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 2.582
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.577
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 2.663
TRAINING: | Iteration [4/12] | Loss 0.16 | Norm 5.000
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 4.228
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.892
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.154
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 5.000
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 2.788
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 5.000
TRAINING: | Iteration [11/12] | Loss 0.15 | Norm 2.692
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 3.424
Epoch: 61/10000 | Epoch Time: 0.100 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 3.159
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 3.262
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 0.14 | Norm 4.462
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.067
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 5.000
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 0.930
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 3.189
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 3.620
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 5.000
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 3.676
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.705
Epoch: 62/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 3.500
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.489
TRAINING: | Iteration [3/12] | Loss 0.15 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 3.091
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 3.445
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 4.463
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.525
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 3.389
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 2.721
TRAINING: | Iteration [10/12] | Loss 0.15 | Norm 2.527
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.687
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 3.311
Epoch: 63/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.237
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 1.718
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 2.725
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.229
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.638
TRAINING: | Iteration [6/12] | Loss 0.14 | Norm 5.000
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 1.811
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 3.794
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 3.590
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 3.498
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 3.682
TRAINING: | Iteration [12/12] | Loss 0.17 | Norm 3.305
Epoch: 64/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 3.817
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 2.795
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 4.116
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 2.194
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.860
TRAINING: | Iteration [7/12] | Loss 0.13 | Norm 4.829
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 3.442
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.216
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.633
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 5.000
TRAINING: | Iteration [12/12] | Loss 0.15 | Norm 5.000
Epoch: 65/10000 | Epoch Time: 0.095 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 4.144
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 3.561
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.427
TRAINING: | Iteration [4/12] | Loss 0.22 | Norm 5.000
TRAINING: | Iteration [5/12] | Loss 0.15 | Norm 5.000
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 5.000
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 4.404
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 2.496
TRAINING: | Iteration [9/12] | Loss 0.16 | Norm 5.000
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 4.751
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 5.000
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 2.916
Epoch: 66/10000 | Epoch Time: 0.095 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.062
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 5.000
TRAINING: | Iteration [3/12] | Loss 0.15 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 5.000
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.010
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.642
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.211
TRAINING: | Iteration [8/12] | Loss 0.15 | Norm 5.000
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 5.000
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 2.897
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 2.456
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.314
Epoch: 67/10000 | Epoch Time: 0.095 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.006
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 3.280
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.626
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 3.602
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 2.633
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.790
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.139
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 4.658
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.778
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.199
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 4.203
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 2.121
Epoch: 68/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 0.919
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.458
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.701
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 5.000
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 3.271
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.887
TRAINING: | Iteration [7/12] | Loss 0.13 | Norm 3.352
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.504
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 2.259
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 4.671
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 3.384
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 4.066
Epoch: 69/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.139
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.689
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 1.758
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 3.495
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 1.208
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 4.887
TRAINING: | Iteration [7/12] | Loss 0.16 | Norm 5.000
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.009
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.398
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 0.923
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.222
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 3.137
Epoch: 70/10000 | Epoch Time: 0.094 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 5.000
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.434
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.569
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 3.499
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.992
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.614
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.800
TRAINING: | Iteration [8/12] | Loss 0.15 | Norm 2.742
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 1.286
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 1.825
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 1.998
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.912
Epoch: 71/10000 | Epoch Time: 0.096 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 4.913
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.004
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.796
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.743
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 3.065
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 5.000
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.675
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 2.452
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 2.228
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.333
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 1.489
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 2.930
Epoch: 72/10000 | Epoch Time: 0.095 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 3.778
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.694
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.924
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.348
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.355
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 5.000
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.440
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 5.000
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 2.021
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 2.602
TRAINING: | Iteration [11/12] | Loss 0.14 | Norm 5.000
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 5.000
Epoch: 73/10000 | Epoch Time: 0.095 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 5.000
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.969
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.818
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 5.000
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 3.312
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 1.496
TRAINING: | Iteration [7/12] | Loss 0.16 | Norm 4.805
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 2.025
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.135
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.988
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 4.444
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.090
Epoch: 74/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 4.460
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 2.376
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 1.959
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.208
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 3.607
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 5.000
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 3.916
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.702
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 3.114
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 1.943
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 3.652
TRAINING: | Iteration [12/12] | Loss 0.16 | Norm 3.018
Epoch: 75/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.789
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.412
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.180
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 1.086
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 3.980
TRAINING: | Iteration [6/12] | Loss 0.20 | Norm 5.000
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.212
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.923
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.021
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 4.800
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.107
TRAINING: | Iteration [12/12] | Loss 0.17 | Norm 5.000
Epoch: 76/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 0.873
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.817
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.438
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.772
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 2.362
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 3.455
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 3.660
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 3.969
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.328
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 4.632
TRAINING: | Iteration [11/12] | Loss 0.14 | Norm 2.036
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.240
Epoch: 77/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 2.611
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.253
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 4.331
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 1.664
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 3.481
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 4.801
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 1.643
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.988
TRAINING: | Iteration [9/12] | Loss 0.16 | Norm 5.000
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 3.464
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 2.655
TRAINING: | Iteration [12/12] | Loss 0.15 | Norm 4.856
Epoch: 78/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 5.000
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 3.595
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 3.280
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 4.745
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.475
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 3.389
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.008
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.222
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 3.896
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 2.224
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 0.967
TRAINING: | Iteration [12/12] | Loss 0.16 | Norm 2.233
Epoch: 79/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.351
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.896
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 2.529
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.479
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.839
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.537
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.468
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 3.401
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 3.211
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 3.704
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 3.349
TRAINING: | Iteration [12/12] | Loss 0.24 | Norm 5.000
Epoch: 80/10000 | Epoch Time: 0.094 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.844
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.865
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 2.694
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 3.218
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.473
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.661
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 4.486
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.393
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 4.517
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 3.170
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.317
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 0.888
Epoch: 81/10000 | Epoch Time: 0.096 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 3.212
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.088
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 0.919
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 1.125
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 3.661
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.192
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 3.220
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.529
TRAINING: | Iteration [9/12] | Loss 0.17 | Norm 2.405
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.236
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 3.724
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 5.000
Epoch: 82/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 4.512
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 5.000
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.368
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.811
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.994
TRAINING: | Iteration [6/12] | Loss 0.18 | Norm 5.000
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 1.064
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.582
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.096
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 4.261
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 4.411
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 0.942
Epoch: 83/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 2.505
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.620
TRAINING: | Iteration [3/12] | Loss 0.18 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 3.928
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.019
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.518
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.973
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 5.000
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.471
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 3.778
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.764
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 3.734
Epoch: 84/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.15 | Norm 5.000
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 5.000
TRAINING: | Iteration [3/12] | Loss 0.15 | Norm 3.256
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 1.434
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.992
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 4.608
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 2.624
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.672
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.559
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 5.000
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 3.086
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.932
Epoch: 85/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 3.697
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.827
TRAINING: | Iteration [3/12] | Loss 0.16 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.771
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 3.687
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 1.983
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.846
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 5.000
TRAINING: | Iteration [9/12] | Loss 0.22 | Norm 5.000
TRAINING: | Iteration [10/12] | Loss 0.26 | Norm 5.000
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.766
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 1.919
Epoch: 86/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.049
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 3.169
TRAINING: | Iteration [3/12] | Loss 0.18 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 0.17 | Norm 5.000
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 3.621
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 2.804
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 3.508
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 3.406
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 4.321
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 4.235
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.914
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 2.529
Epoch: 87/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 2.127
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 3.875
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.570
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 2.872
TRAINING: | Iteration [5/12] | Loss 0.14 | Norm 4.298
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 1.460
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.759
TRAINING: | Iteration [8/12] | Loss 0.20 | Norm 5.000
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.790
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 4.034
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 3.417
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 2.754
Epoch: 88/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 1.776
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.624
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 1.782
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 4.156
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.997
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 2.662
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.052
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 0.936
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 2.875
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 5.000
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 3.142
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 2.024
Epoch: 89/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 2.492
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 2.980
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 2.403
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 3.047
TRAINING: | Iteration [5/12] | Loss 0.16 | Norm 3.088
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.600
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 4.418
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.150
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 1.444
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 0.877
TRAINING: | Iteration [11/12] | Loss 0.15 | Norm 2.554
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.728
Epoch: 90/10000 | Epoch Time: 0.094 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.388
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.296
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 3.624
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.735
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 2.038
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.162
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 4.386
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 4.288
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.474
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.612
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.441
TRAINING: | Iteration [12/12] | Loss 0.19 | Norm 5.000
Epoch: 91/10000 | Epoch Time: 0.099 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 2.980
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 4.127
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 0.16 | Norm 4.155
TRAINING: | Iteration [5/12] | Loss 0.16 | Norm 4.527
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 4.661
TRAINING: | Iteration [7/12] | Loss 0.13 | Norm 5.000
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 4.166
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 4.872
TRAINING: | Iteration [10/12] | Loss 0.17 | Norm 5.000
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.822
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.850
Epoch: 92/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 5.000
TRAINING: | Iteration [2/12] | Loss 0.15 | Norm 5.000
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 4.072
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 0.662
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.070
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 3.262
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 1.833
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.614
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 4.438
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.851
TRAINING: | Iteration [11/12] | Loss 0.22 | Norm 2.266
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 3.064
Epoch: 93/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.691
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 5.000
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 3.958
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 1.972
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 3.009
TRAINING: | Iteration [6/12] | Loss 0.14 | Norm 4.864
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.623
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.866
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 2.573
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.753
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 3.619
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 2.120
Epoch: 94/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 2.306
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.002
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 3.593
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.600
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.679
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 3.837
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.927
TRAINING: | Iteration [8/12] | Loss 0.15 | Norm 2.515
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.310
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 2.970
TRAINING: | Iteration [11/12] | Loss 0.18 | Norm 5.000
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.885
Epoch: 95/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 5.000
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 3.880
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.703
TRAINING: | Iteration [4/12] | Loss 0.17 | Norm 2.894
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 3.667
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.447
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 2.496
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 4.427
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 2.592
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.254
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 3.746
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 3.396
Epoch: 96/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.729
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 3.108
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 2.636
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 2.265
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.280
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.201
TRAINING: | Iteration [7/12] | Loss 0.14 | Norm 2.938
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.664
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 3.322
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 3.698
TRAINING: | Iteration [11/12] | Loss 0.15 | Norm 4.095
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 2.843
Epoch: 97/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 3.550
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 2.304
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.180
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 1.926
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 4.072
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.871
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.511
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 3.205
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.976
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 4.058
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.541
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.745
Epoch: 98/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 2.026
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.188
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.592
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.050
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.094
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.889
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 3.909
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 1.954
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 3.396
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.894
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 2.889
TRAINING: | Iteration [12/12] | Loss 0.18 | Norm 3.093
Epoch: 99/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.368
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.162
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 5.000
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.493
TRAINING: | Iteration [6/12] | Loss 0.15 | Norm 5.000
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 2.633
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 3.978
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.861
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 2.488
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.748
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 3.626
Epoch: 100/10000 | Epoch Time: 0.094 seconds
Saving Model
Preparation of Training Data time: 61.046 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.890
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.779
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.954
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.456
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.341
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.472
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 2.143
TRAINING: | Iteration [8/12] | Loss 0.15 | Norm 3.593
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 2.349
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 3.243
TRAINING: | Iteration [11/12] | Loss 0.16 | Norm 2.499
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 4.427
Epoch: 101/10000 | Epoch Time: 0.128 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.340
TRAINING: | Iteration [2/12] | Loss 0.17 | Norm 5.000
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.542
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.809
TRAINING: | Iteration [5/12] | Loss 0.16 | Norm 3.104
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 3.124
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 2.306
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.533
TRAINING: | Iteration [9/12] | Loss 0.14 | Norm 3.810
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.385
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 3.172
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 3.261
Epoch: 102/10000 | Epoch Time: 0.113 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.539
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 3.491
TRAINING: | Iteration [3/12] | Loss 0.18 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 0.15 | Norm 5.000
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.316
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 2.566
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.478
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 5.000
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 2.709
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 2.676
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.437
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 3.498
Epoch: 103/10000 | Epoch Time: 0.110 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 4.462
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.182
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.239
TRAINING: | Iteration [4/12] | Loss 0.21 | Norm 2.549
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 3.827
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 4.381
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 2.923
TRAINING: | Iteration [8/12] | Loss 0.15 | Norm 3.906
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 4.032
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.910
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 2.103
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 5.000
Epoch: 104/10000 | Epoch Time: 0.110 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.256
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.606
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 4.364
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 4.294
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 2.702
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 1.741
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 1.866
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 5.000
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 4.746
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 2.970
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.396
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 4.120
Epoch: 105/10000 | Epoch Time: 0.108 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 4.357
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 3.959
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 3.180
TRAINING: | Iteration [4/12] | Loss 0.14 | Norm 1.981
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.951
TRAINING: | Iteration [6/12] | Loss 0.17 | Norm 4.867
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 2.965
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 3.108
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.288
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 3.160
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 2.527
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.804
Epoch: 106/10000 | Epoch Time: 0.109 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 3.280
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.999
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.081
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 0.899
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 4.534
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 5.000
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 3.475
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 2.067
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 2.243
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.999
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 4.844
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.127
Epoch: 107/10000 | Epoch Time: 0.108 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 4.706
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 3.396
TRAINING: | Iteration [3/12] | Loss 0.15 | Norm 3.464
TRAINING: | Iteration [4/12] | Loss 0.17 | Norm 4.814
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 4.292
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 4.414
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 1.971
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 3.423
TRAINING: | Iteration [9/12] | Loss 0.15 | Norm 2.558
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 5.000
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 3.860
TRAINING: | Iteration [12/12] | Loss 0.15 | Norm 5.000
Epoch: 108/10000 | Epoch Time: 0.108 seconds
TRAINING: | Iteration [1/12] | Loss 0.15 | Norm 3.231
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 2.168
TRAINING: | Iteration [3/12] | Loss 0.14 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 4.476
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 4.876
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 2.421
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.479
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.750
TRAINING: | Iteration [9/12] | Loss 0.17 | Norm 5.000
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 3.683
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 4.871
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 1.431
Epoch: 109/10000 | Epoch Time: 0.108 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.918
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.843
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.922
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 5.000
TRAINING: | Iteration [5/12] | Loss 0.14 | Norm 5.000
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.745
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.598
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 3.747
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 2.341
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 3.011
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 3.031
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.508
Epoch: 110/10000 | Epoch Time: 0.109 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.135
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 3.220
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 3.195
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.317
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.486
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.505
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.887
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 3.208
TRAINING: | Iteration [9/12] | Loss 0.20 | Norm 4.485
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.173
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 2.343
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.523
Epoch: 111/10000 | Epoch Time: 0.110 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 2.138
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 2.934
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.699
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 2.589
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.083
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.849
TRAINING: | Iteration [7/12] | Loss 0.19 | Norm 3.383
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 2.589
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.078
TRAINING: | Iteration [10/12] | Loss 0.17 | Norm 5.000
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 2.677
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 1.877
Epoch: 112/10000 | Epoch Time: 0.108 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.801
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.107
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 3.774
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.182
TRAINING: | Iteration [5/12] | Loss 0.18 | Norm 4.545
TRAINING: | Iteration [6/12] | Loss 0.14 | Norm 2.399
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 1.861
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.856
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 3.324
TRAINING: | Iteration [10/12] | Loss 0.15 | Norm 3.328
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 3.694
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 3.124
Epoch: 113/10000 | Epoch Time: 0.108 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 3.790
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.355
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.802
TRAINING: | Iteration [4/12] | Loss 0.16 | Norm 5.000
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 5.000
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 2.910
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 2.887
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.493
TRAINING: | Iteration [9/12] | Loss 0.14 | Norm 3.041
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.884
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 3.524
TRAINING: | Iteration [12/12] | Loss 0.20 | Norm 4.555
Epoch: 114/10000 | Epoch Time: 0.108 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 3.559
TRAINING: | Iteration [2/12] | Loss 0.17 | Norm 3.227
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 4.703
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 2.472
TRAINING: | Iteration [5/12] | Loss 0.16 | Norm 5.000
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 4.697
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 0.854
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 3.977
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 2.438
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 3.939
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 4.534
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 1.710
Epoch: 115/10000 | Epoch Time: 0.108 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.581
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 4.220
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 3.152
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 2.635
TRAINING: | Iteration [5/12] | Loss 0.19 | Norm 3.877
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 2.305
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 2.545
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 0.919
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 3.878
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 3.266
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 2.839
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 1.863
Epoch: 116/10000 | Epoch Time: 0.108 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.929
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.240
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 4.034
TRAINING: | Iteration [4/12] | Loss 0.14 | Norm 2.614
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 1.796
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.625
TRAINING: | Iteration [7/12] | Loss 0.13 | Norm 1.734
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 3.226
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.197
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 1.551
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 3.889
TRAINING: | Iteration [12/12] | Loss 0.16 | Norm 1.874
Epoch: 117/10000 | Epoch Time: 0.108 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 4.230
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 2.471
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.643
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.202
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 2.145
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.416
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.616
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 3.257
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 1.668
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 4.892
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.207
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 2.756
Epoch: 118/10000 | Epoch Time: 0.108 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 5.000
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.628
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.117
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.443
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.911
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 4.486
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 0.864
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.526
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 4.305
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 2.874
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 1.961
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 2.331
Epoch: 119/10000 | Epoch Time: 0.108 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.767
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.078
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 2.121
TRAINING: | Iteration [4/12] | Loss 0.14 | Norm 3.303
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.017
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 3.973
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.115
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.785
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.518
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 2.062
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 2.070
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.903
Epoch: 120/10000 | Epoch Time: 0.108 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.500
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 2.265
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 1.755
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.255
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 1.500
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 2.324
TRAINING: | Iteration [7/12] | Loss 0.15 | Norm 3.973
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.033
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 2.124
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.103
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 4.042
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 3.638
Epoch: 121/10000 | Epoch Time: 0.110 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.826
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 2.428
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.287
TRAINING: | Iteration [4/12] | Loss 0.18 | Norm 2.059
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 4.613
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 1.749
TRAINING: | Iteration [7/12] | Loss 0.28 | Norm 5.000
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.614
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.049
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 5.000
TRAINING: | Iteration [11/12] | Loss 0.14 | Norm 5.000
TRAINING: | Iteration [12/12] | Loss 0.18 | Norm 5.000
Epoch: 122/10000 | Epoch Time: 0.109 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.439
TRAINING: | Iteration [2/12] | Loss 0.14 | Norm 5.000
TRAINING: | Iteration [3/12] | Loss 0.14 | Norm 2.819
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 4.832
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.095
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.688
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 3.067
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.822
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.020
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 2.811
TRAINING: | Iteration [11/12] | Loss 0.16 | Norm 3.218
TRAINING: | Iteration [12/12] | Loss 0.22 | Norm 5.000
Epoch: 123/10000 | Epoch Time: 0.109 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.812
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 2.847
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.565
TRAINING: | Iteration [4/12] | Loss 0.14 | Norm 4.002
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.286
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 2.144
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 2.334
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.902
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 3.164
TRAINING: | Iteration [10/12] | Loss 0.15 | Norm 2.815
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.994
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.870
Epoch: 124/10000 | Epoch Time: 0.108 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 3.330
TRAINING: | Iteration [2/12] | Loss 0.15 | Norm 5.000
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.439
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 1.691
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 3.296
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 2.622
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.421
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.510
TRAINING: | Iteration [9/12] | Loss 0.17 | Norm 2.880
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.333
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.703
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 1.666
Epoch: 125/10000 | Epoch Time: 0.108 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 2.152
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.338
TRAINING: | Iteration [3/12] | Loss 0.16 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.386
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.400
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 3.609
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 4.615
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 4.568
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.436
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.283
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.981
TRAINING: | Iteration [12/12] | Loss 0.18 | Norm 5.000
Epoch: 126/10000 | Epoch Time: 0.108 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 3.437
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 2.730
TRAINING: | Iteration [3/12] | Loss 0.14 | Norm 1.914
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.641
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 5.000
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.101
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.270
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.996
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 3.921
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 4.302
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 3.368
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 4.158
Epoch: 127/10000 | Epoch Time: 0.108 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 4.800
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.147
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 3.038
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.948
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.214
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.493
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.529
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.188
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 3.086
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.304
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 2.366
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 3.087
Epoch: 128/10000 | Epoch Time: 0.108 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 4.291
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.730
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 4.051
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.231
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.016
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 3.498
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.394
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.262
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 2.233
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 4.877
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.217
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.275
Epoch: 129/10000 | Epoch Time: 0.107 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.596
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 4.379
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.454
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 1.901
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.185
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.649
TRAINING: | Iteration [7/12] | Loss 0.18 | Norm 5.000
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 4.602
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 1.676
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.291
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.637
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 3.557
Epoch: 130/10000 | Epoch Time: 0.108 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 5.000
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.761
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.077
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 3.036
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 4.223
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 3.231
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.347
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 1.794
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.773
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.451
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.574
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 2.450
Epoch: 131/10000 | Epoch Time: 0.109 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.181
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.292
TRAINING: | Iteration [3/12] | Loss 0.17 | Norm 3.269
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 2.518
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.050
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.032
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.584
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 0.985
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.444
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.758
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.700
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 3.817
Epoch: 132/10000 | Epoch Time: 0.109 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 2.632
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.918
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 2.235
TRAINING: | Iteration [4/12] | Loss 0.31 | Norm 4.188
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.543
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 1.255
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.920
TRAINING: | Iteration [8/12] | Loss 0.17 | Norm 3.120
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 4.557
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.005
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.169
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 2.201
Epoch: 133/10000 | Epoch Time: 0.109 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 4.085
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.664
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 2.224
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.381
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.699
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 3.015
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.810
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.302
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 3.199
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.127
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.773
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 0.968
Epoch: 134/10000 | Epoch Time: 0.108 seconds
TRAINING: | Iteration [1/12] | Loss 0.14 | Norm 2.694
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.353
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.383
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 3.009
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.680
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.276
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.213
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 2.963
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.033
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.781
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.109
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.148
Epoch: 135/10000 | Epoch Time: 0.109 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 3.720
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.629
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.597
TRAINING: | Iteration [4/12] | Loss 0.14 | Norm 3.934
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 3.335
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.085
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.354
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.749
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 5.000
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 5.000
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 4.160
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.983
Epoch: 136/10000 | Epoch Time: 0.109 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.384
TRAINING: | Iteration [2/12] | Loss 0.16 | Norm 5.000
TRAINING: | Iteration [3/12] | Loss 0.20 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 0.19 | Norm 5.000
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 5.000
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.682
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 1.683
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.457
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 5.000
TRAINING: | Iteration [10/12] | Loss 0.22 | Norm 5.000
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 4.779
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 1.860
Epoch: 137/10000 | Epoch Time: 0.111 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 1.612
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.270
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 3.247
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 5.000
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 5.000
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.702
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.536
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 5.000
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 3.848
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 4.838
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 3.771
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 3.203
Epoch: 138/10000 | Epoch Time: 0.110 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 4.877
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 3.775
TRAINING: | Iteration [3/12] | Loss 0.14 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 3.646
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 1.343
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.488
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 4.301
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 5.000
TRAINING: | Iteration [9/12] | Loss 0.14 | Norm 5.000
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 4.122
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.267
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.163
Epoch: 139/10000 | Epoch Time: 0.109 seconds
TRAINING: | Iteration [1/12] | Loss 0.14 | Norm 5.000
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 4.620
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 3.270
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 4.456
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.353
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.738
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 3.406
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 4.131
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 4.846
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 2.873
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 3.440
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.658
Epoch: 140/10000 | Epoch Time: 0.108 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 3.245
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 4.691
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 4.359
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.603
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 4.193
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 3.058
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 4.640
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.248
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 2.996
TRAINING: | Iteration [10/12] | Loss 0.16 | Norm 2.745
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 2.379
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.080
Epoch: 141/10000 | Epoch Time: 0.109 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.429
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 2.079
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 1.879
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 1.135
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.834
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 1.254
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 2.728
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 3.220
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 3.196
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.899
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.518
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 0.945
Epoch: 142/10000 | Epoch Time: 0.108 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 2.838
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.435
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.662
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.439
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.411
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 2.767
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.254
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 2.160
TRAINING: | Iteration [9/12] | Loss 0.16 | Norm 5.000
TRAINING: | Iteration [10/12] | Loss 0.15 | Norm 4.499
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 4.822
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.745
Epoch: 143/10000 | Epoch Time: 0.108 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 3.508
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.132
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 3.075
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.854
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 5.000
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 1.584
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 1.892
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.541
TRAINING: | Iteration [9/12] | Loss 0.16 | Norm 5.000
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 5.000
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 4.515
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 2.315
Epoch: 144/10000 | Epoch Time: 0.109 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 3.203
TRAINING: | Iteration [2/12] | Loss 0.14 | Norm 5.000
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 4.333
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.343
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 1.293
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 1.989
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 3.009
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 3.920
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.835
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 2.573
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.455
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 3.991
Epoch: 145/10000 | Epoch Time: 0.108 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.484
TRAINING: | Iteration [2/12] | Loss 0.21 | Norm 4.324
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 2.506
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.236
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.093
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 1.686
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 2.958
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.022
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.602
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.357
TRAINING: | Iteration [11/12] | Loss 0.15 | Norm 1.700
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.822
Epoch: 146/10000 | Epoch Time: 0.109 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.379
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.325
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 1.381
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.048
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 2.173
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 1.194
TRAINING: | Iteration [7/12] | Loss 0.13 | Norm 2.498
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 4.038
TRAINING: | Iteration [9/12] | Loss 0.14 | Norm 3.194
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.735
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 3.065
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 2.530
Epoch: 147/10000 | Epoch Time: 0.108 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.920
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 2.255
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 2.105
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 5.000
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 2.282
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.368
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 2.992
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 4.614
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.766
TRAINING: | Iteration [10/12] | Loss 0.15 | Norm 3.951
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.420
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.815
Epoch: 148/10000 | Epoch Time: 0.108 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 5.000
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.767
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.193
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.571
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.658
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 3.276
TRAINING: | Iteration [7/12] | Loss 0.16 | Norm 3.612
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 4.831
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.438
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 0.976
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 3.518
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.285
Epoch: 149/10000 | Epoch Time: 0.108 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 2.684
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 0.863
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.173
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.544
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.765
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.038
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.117
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.634
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 2.498
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 2.489
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.757
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 1.740
Epoch: 150/10000 | Epoch Time: 0.108 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 3.754
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 4.323
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 2.489
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.975
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 0.701
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 1.540
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 2.172
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.684
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 0.968
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.276
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.282
TRAINING: | Iteration [12/12] | Loss 0.15 | Norm 3.599
Epoch: 151/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 4.016
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 1.703
TRAINING: | Iteration [3/12] | Loss 0.18 | Norm 2.498
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 3.462
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.607
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 2.553
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.133
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.424
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.080
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 3.247
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.918
TRAINING: | Iteration [12/12] | Loss 0.17 | Norm 3.121
Epoch: 152/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.556
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 5.000
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 3.457
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 4.228
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 1.707
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 2.662
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.365
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.539
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 4.398
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 2.605
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.139
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.449
Epoch: 153/10000 | Epoch Time: 0.110 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.474
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 3.355
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 3.257
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.970
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 3.114
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 1.624
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 2.200
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.187
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 1.611
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 0.884
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.664
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 3.361
Epoch: 154/10000 | Epoch Time: 0.118 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.911
TRAINING: | Iteration [2/12] | Loss 0.17 | Norm 2.248
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.647
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 2.218
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 2.858
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 3.076
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.229
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 2.415
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.327
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 2.401
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 2.466
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.538
Epoch: 155/10000 | Epoch Time: 0.117 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 0.946
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 1.787
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.421
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 2.285
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.160
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.848
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 1.568
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 3.504
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 2.323
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 3.125
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.249
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 2.620
Epoch: 156/10000 | Epoch Time: 0.105 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 1.757
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 4.156
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 3.636
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 1.011
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 1.860
TRAINING: | Iteration [6/12] | Loss 0.14 | Norm 3.885
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 0.796
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 0.970
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 3.178
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 2.183
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.890
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 3.226
Epoch: 157/10000 | Epoch Time: 0.117 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.731
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.693
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 2.745
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 3.707
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 3.409
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 3.584
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 2.991
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.904
TRAINING: | Iteration [9/12] | Loss 0.14 | Norm 3.502
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.129
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 1.596
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.192
Epoch: 158/10000 | Epoch Time: 0.105 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.224
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 4.040
TRAINING: | Iteration [3/12] | Loss 0.14 | Norm 4.844
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 2.314
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 4.597
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 2.452
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.079
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 4.766
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 3.554
TRAINING: | Iteration [10/12] | Loss 0.18 | Norm 3.832
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.353
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 5.000
Epoch: 159/10000 | Epoch Time: 0.105 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.701
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.879
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.614
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 3.612
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.158
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.239
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 1.671
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.823
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.364
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.138
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.254
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 3.462
Epoch: 160/10000 | Epoch Time: 0.106 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 4.845
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 2.084
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.133
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.041
TRAINING: | Iteration [5/12] | Loss 0.16 | Norm 4.535
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 3.035
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.432
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 2.975
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.352
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 3.073
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 3.351
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.970
Epoch: 161/10000 | Epoch Time: 0.115 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 3.662
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.082
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.891
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 5.000
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 3.483
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 3.282
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 3.808
TRAINING: | Iteration [8/12] | Loss 0.19 | Norm 5.000
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 1.916
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 3.513
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 4.012
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.325
Epoch: 162/10000 | Epoch Time: 0.115 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.977
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.399
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 3.897
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 4.555
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.857
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 2.049
TRAINING: | Iteration [7/12] | Loss 0.15 | Norm 3.649
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 4.407
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 2.455
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.884
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 0.963
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 3.953
Epoch: 163/10000 | Epoch Time: 0.116 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 4.261
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.180
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.876
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 2.555
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.574
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 2.582
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.616
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.662
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.696
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.346
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.067
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 1.941
Epoch: 164/10000 | Epoch Time: 0.121 seconds
TRAINING: | Iteration [1/12] | Loss 0.16 | Norm 3.273
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.535
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 1.969
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 3.151
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.774
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 5.000
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.275
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.312
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.343
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.321
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 1.785
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 5.000
Epoch: 165/10000 | Epoch Time: 0.113 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.543
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.253
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.298
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 4.129
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.672
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.404
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.472
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 3.350
TRAINING: | Iteration [9/12] | Loss 0.15 | Norm 2.196
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 0.829
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 3.173
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.799
Epoch: 166/10000 | Epoch Time: 0.113 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.029
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 2.173
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.178
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.312
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.145
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.099
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.186
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.253
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.036
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 1.976
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 1.960
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.570
Epoch: 167/10000 | Epoch Time: 0.113 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 4.200
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.356
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.315
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 4.383
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.018
TRAINING: | Iteration [6/12] | Loss 0.18 | Norm 3.289
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 2.613
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 4.224
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.345
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.779
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 2.273
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 2.850
Epoch: 168/10000 | Epoch Time: 0.121 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 2.801
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.895
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.099
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 0.943
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 2.292
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 2.292
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 2.753
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 3.237
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 3.310
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 3.844
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.760
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 2.601
Epoch: 169/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.950
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.966
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.982
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.897
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.927
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 1.665
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 1.971
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 3.443
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.714
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 2.562
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 1.818
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.293
Epoch: 170/10000 | Epoch Time: 0.102 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.430
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.398
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 2.629
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.249
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.658
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 3.564
TRAINING: | Iteration [7/12] | Loss 0.14 | Norm 2.292
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.069
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.348
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 2.534
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 2.394
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.843
Epoch: 171/10000 | Epoch Time: 0.105 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.999
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 2.321
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.430
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.622
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 2.235
TRAINING: | Iteration [6/12] | Loss 0.17 | Norm 4.062
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 0.896
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.962
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.467
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.072
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.764
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.246
Epoch: 172/10000 | Epoch Time: 0.106 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.313
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 3.305
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.100
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.677
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 4.009
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.888
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.780
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 3.257
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.080
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.349
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.992
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.467
Epoch: 173/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 1.803
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 3.291
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 3.749
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 0.933
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 3.094
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.206
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.728
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.249
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 3.448
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 3.197
TRAINING: | Iteration [11/12] | Loss 0.15 | Norm 2.068
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 2.187
Epoch: 174/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.309
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.894
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 0.958
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 2.204
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 1.830
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 1.830
TRAINING: | Iteration [7/12] | Loss 0.19 | Norm 5.000
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 2.018
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.647
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.281
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.558
TRAINING: | Iteration [12/12] | Loss 0.18 | Norm 3.655
Epoch: 175/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.238
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 4.024
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 4.603
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 2.304
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.601
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.699
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 3.218
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.920
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.383
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 1.667
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 2.103
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.646
Epoch: 176/10000 | Epoch Time: 0.100 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 4.877
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 0.630
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.543
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.560
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 3.294
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.138
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 3.338
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 0.825
TRAINING: | Iteration [9/12] | Loss 0.15 | Norm 5.000
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.809
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.990
TRAINING: | Iteration [12/12] | Loss 0.19 | Norm 5.000
Epoch: 177/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 0.833
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 4.417
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 4.749
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.377
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.497
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.395
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 2.403
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.171
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.738
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 2.584
TRAINING: | Iteration [11/12] | Loss 0.14 | Norm 2.653
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 4.006
Epoch: 178/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.064
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.926
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 0.928
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.174
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 3.157
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.409
TRAINING: | Iteration [7/12] | Loss 0.13 | Norm 2.936
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 3.500
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.785
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.131
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.187
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.481
Epoch: 179/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.517
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 3.761
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.293
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.476
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.907
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 4.078
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 2.417
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.206
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 2.225
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.686
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 3.980
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 5.000
Epoch: 180/10000 | Epoch Time: 0.115 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.751
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.874
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 1.771
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 2.071
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 3.065
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.487
TRAINING: | Iteration [7/12] | Loss 0.13 | Norm 4.525
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 4.318
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 1.952
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.402
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 2.905
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 3.622
Epoch: 181/10000 | Epoch Time: 0.106 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 0.744
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.166
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.378
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.225
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 0.725
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 2.907
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.267
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.643
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 1.265
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.809
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.792
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 3.096
Epoch: 182/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 3.985
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 1.640
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.380
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 3.154
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.282
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 1.912
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 1.598
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.613
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 1.660
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 3.661
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 3.865
TRAINING: | Iteration [12/12] | Loss 0.19 | Norm 2.393
Epoch: 183/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.619
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.629
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 2.053
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.409
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 1.892
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 2.125
TRAINING: | Iteration [7/12] | Loss 0.14 | Norm 2.076
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 3.458
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 3.531
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.385
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.960
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 2.328
Epoch: 184/10000 | Epoch Time: 0.118 seconds
TRAINING: | Iteration [1/12] | Loss 0.16 | Norm 4.133
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 0.933
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 1.791
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.119
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.166
TRAINING: | Iteration [6/12] | Loss 0.15 | Norm 2.541
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 2.868
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.869
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 0.959
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 0.953
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 3.202
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.153
Epoch: 185/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 3.005
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.768
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.979
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.889
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.809
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.922
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 3.576
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 5.000
TRAINING: | Iteration [9/12] | Loss 0.15 | Norm 5.000
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.105
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 3.503
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.956
Epoch: 186/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.14 | Norm 3.752
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.305
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.414
TRAINING: | Iteration [4/12] | Loss 0.17 | Norm 2.549
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 3.221
TRAINING: | Iteration [6/12] | Loss 0.16 | Norm 2.615
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.799
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.252
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.814
TRAINING: | Iteration [10/12] | Loss 0.15 | Norm 4.452
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.744
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 3.083
Epoch: 187/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 3.304
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 2.645
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 0.765
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 3.353
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 2.654
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.675
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 3.748
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.944
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 0.912
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 3.991
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 3.188
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 3.470
Epoch: 188/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.735
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 2.996
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.241
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 2.783
TRAINING: | Iteration [6/12] | Loss 0.18 | Norm 2.224
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.881
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 2.298
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 3.597
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 2.154
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.227
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 3.000
Epoch: 189/10000 | Epoch Time: 0.106 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.048
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.710
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 0.765
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.014
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 1.959
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.963
TRAINING: | Iteration [7/12] | Loss 0.14 | Norm 1.868
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.069
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 1.638
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 2.874
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 2.024
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 3.234
Epoch: 190/10000 | Epoch Time: 0.116 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.563
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 3.082
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.039
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.030
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 2.352
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.250
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.385
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 2.350
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 2.694
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.214
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.760
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.518
Epoch: 191/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 4.017
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.037
TRAINING: | Iteration [3/12] | Loss 0.14 | Norm 4.104
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.843
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.108
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.692
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.090
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 3.607
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.544
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.908
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.319
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.175
Epoch: 192/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.849
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 3.242
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.058
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 1.464
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.571
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.051
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.301
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 2.700
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.563
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 1.810
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.111
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.403
Epoch: 193/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.18 | Norm 3.037
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.039
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 3.166
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.229
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.776
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 4.212
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 2.405
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.584
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 2.227
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.460
TRAINING: | Iteration [11/12] | Loss 0.14 | Norm 2.922
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 2.544
Epoch: 194/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.564
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 2.778
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 2.387
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.214
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.524
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.186
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 3.090
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.802
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 3.076
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.300
TRAINING: | Iteration [11/12] | Loss 0.16 | Norm 2.824
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.112
Epoch: 195/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.643
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.549
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 3.168
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 0.991
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.807
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 4.074
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 4.670
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 2.850
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 4.512
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 3.367
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 3.504
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 3.121
Epoch: 196/10000 | Epoch Time: 0.114 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.383
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 3.362
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.808
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 3.525
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.899
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.778
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.240
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 3.272
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.852
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 3.046
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.662
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.480
Epoch: 197/10000 | Epoch Time: 0.113 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.658
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 3.694
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 4.011
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.647
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 1.781
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 3.487
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 4.415
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 3.862
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 1.995
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.057
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.090
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.425
Epoch: 198/10000 | Epoch Time: 0.122 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 3.234
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.250
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 3.800
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.155
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 3.625
TRAINING: | Iteration [6/12] | Loss 0.24 | Norm 5.000
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 2.825
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.412
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 2.945
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 4.360
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 3.732
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.945
Epoch: 199/10000 | Epoch Time: 0.118 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 2.899
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.815
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.812
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.672
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.183
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 2.590
TRAINING: | Iteration [7/12] | Loss 0.21 | Norm 4.419
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.700
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.317
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 1.366
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.013
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.222
Epoch: 200/10000 | Epoch Time: 0.102 seconds
Saving Model
Preparation of Training Data time: 19.694 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 3.131
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.278
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.350
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.835
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.262
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 2.399
TRAINING: | Iteration [7/12] | Loss 0.15 | Norm 2.390
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.323
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.665
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.053
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.580
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.770
Epoch: 201/10000 | Epoch Time: 0.109 seconds
TRAINING: | Iteration [1/12] | Loss 0.14 | Norm 2.535
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 2.170
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.446
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.725
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.805
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.038
TRAINING: | Iteration [7/12] | Loss 0.14 | Norm 2.298
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 1.703
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.036
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 5.000
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.535
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 0.718
Epoch: 202/10000 | Epoch Time: 0.096 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.316
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 2.527
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 2.685
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.102
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.567
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.249
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 2.581
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.878
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.431
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.587
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 2.804
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 2.403
Epoch: 203/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.792
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 4.745
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.079
TRAINING: | Iteration [4/12] | Loss 0.14 | Norm 3.696
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.650
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.796
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 3.388
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.401
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.892
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 3.092
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 2.243
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 2.368
Epoch: 204/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 0.966
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.545
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.912
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 3.278
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.507
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.628
TRAINING: | Iteration [7/12] | Loss 0.23 | Norm 4.590
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.857
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.105
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.405
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.818
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.924
Epoch: 205/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.459
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 0.650
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 3.241
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.947
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 3.456
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.993
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.543
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 2.362
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 4.622
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 2.115
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.192
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.184
Epoch: 206/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 2.109
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.457
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.657
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 2.912
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.978
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.528
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 2.149
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 1.729
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 1.162
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.319
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 1.705
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.883
Epoch: 207/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.572
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.841
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.465
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 3.851
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.232
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.688
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.961
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.996
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 1.679
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.776
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.290
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.822
Epoch: 208/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 2.409
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 1.609
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 4.339
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.353
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 0.982
TRAINING: | Iteration [6/12] | Loss 0.18 | Norm 2.517
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 3.172
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 2.569
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.717
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.170
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.191
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 2.819
Epoch: 209/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 1.397
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.604
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 4.177
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 4.012
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.880
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 3.838
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 1.340
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.274
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 1.865
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.718
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.743
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.457
Epoch: 210/10000 | Epoch Time: 0.093 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.759
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.927
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.307
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 2.822
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 0.921
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.374
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.458
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 1.945
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.087
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 2.927
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 0.983
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 2.363
Epoch: 211/10000 | Epoch Time: 0.095 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.477
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 0.802
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.506
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.322
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.398
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.006
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.350
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 1.864
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.348
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.711
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.509
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.079
Epoch: 212/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 3.299
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 1.938
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 3.676
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.482
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.099
TRAINING: | Iteration [6/12] | Loss 0.19 | Norm 3.563
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.279
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 2.687
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.358
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 0.866
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.466
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 2.270
Epoch: 213/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 1.886
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.446
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.041
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.230
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.538
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 1.816
TRAINING: | Iteration [7/12] | Loss 0.17 | Norm 3.939
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.393
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 0.877
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 2.330
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 5.000
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.983
Epoch: 214/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 1.829
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.232
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 3.234
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 3.581
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 3.007
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 3.351
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 2.196
TRAINING: | Iteration [8/12] | Loss 0.17 | Norm 2.911
TRAINING: | Iteration [9/12] | Loss 0.14 | Norm 5.000
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.239
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 2.456
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 2.787
Epoch: 215/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.007
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.885
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.630
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 3.731
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 2.358
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.919
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 2.303
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 3.378
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 3.019
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 2.852
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 2.241
Epoch: 216/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 2.554
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 2.263
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.803
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.927
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.397
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 1.042
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 2.338
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.835
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 2.705
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.402
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 2.350
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 3.728
Epoch: 217/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.042
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 2.371
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.169
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 3.521
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.344
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 2.033
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 2.236
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.909
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 2.662
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 1.689
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.913
TRAINING: | Iteration [12/12] | Loss 0.18 | Norm 2.632
Epoch: 218/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.064
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 2.902
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 1.936
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.430
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 2.238
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 4.167
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.710
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 3.712
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 0.986
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.182
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.877
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.355
Epoch: 219/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.730
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 2.412
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 3.090
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.157
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.596
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 0.934
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.441
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 2.148
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.491
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 3.630
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.607
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 0.996
Epoch: 220/10000 | Epoch Time: 0.093 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 1.318
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 4.057
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.756
TRAINING: | Iteration [4/12] | Loss 0.19 | Norm 3.170
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 3.478
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 4.083
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 2.143
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.472
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 0.921
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 3.339
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 2.710
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 3.236
Epoch: 221/10000 | Epoch Time: 0.095 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.869
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.138
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 0.895
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 3.247
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 1.612
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 2.195
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 2.296
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.512
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.288
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 1.975
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 3.391
TRAINING: | Iteration [12/12] | Loss 0.16 | Norm 5.000
Epoch: 222/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 0.756
TRAINING: | Iteration [2/12] | Loss 0.16 | Norm 4.860
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.389
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.055
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 0.813
TRAINING: | Iteration [6/12] | Loss 0.18 | Norm 3.904
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 2.106
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.816
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.077
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 0.768
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.534
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.857
Epoch: 223/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.131
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.753
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 3.896
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.523
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 4.719
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 3.263
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.857
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 2.006
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.328
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.415
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 2.175
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.425
Epoch: 224/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 3.447
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.384
TRAINING: | Iteration [3/12] | Loss 0.17 | Norm 2.839
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.076
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 1.969
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.388
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.333
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 3.357
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 2.145
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.520
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 3.665
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.664
Epoch: 225/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.14 | Norm 2.654
TRAINING: | Iteration [2/12] | Loss 0.14 | Norm 3.122
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 2.186
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 3.194
TRAINING: | Iteration [5/12] | Loss 0.15 | Norm 2.097
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 0.711
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.606
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.603
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.010
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.609
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 2.192
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 3.086
Epoch: 226/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 1.097
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.339
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.409
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 2.099
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 2.607
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 2.359
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.520
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.402
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 3.363
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.447
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 2.305
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.159
Epoch: 227/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.14 | Norm 3.862
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.435
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.213
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 3.464
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 1.808
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 2.125
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.303
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.015
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 2.529
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.776
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 2.624
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 0.916
Epoch: 228/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.507
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.537
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 2.957
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.967
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.593
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 3.434
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.076
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 3.276
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.168
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 1.840
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 3.542
TRAINING: | Iteration [12/12] | Loss 0.15 | Norm 2.529
Epoch: 229/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 2.617
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.067
TRAINING: | Iteration [3/12] | Loss 0.16 | Norm 4.149
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 2.578
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 3.856
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.052
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.535
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 2.353
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.359
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.672
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.821
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 2.046
Epoch: 230/10000 | Epoch Time: 0.095 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 3.628
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 2.143
TRAINING: | Iteration [3/12] | Loss 0.04 | Norm 0.764
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.547
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.891
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.588
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.734
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 2.004
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.618
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.060
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.168
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.607
Epoch: 231/10000 | Epoch Time: 0.095 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 1.677
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.348
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.959
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 2.084
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 4.089
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 3.453
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 1.740
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 2.380
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.578
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 3.143
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 2.714
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 1.757
Epoch: 232/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.200
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 3.207
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 3.164
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 1.982
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.020
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 3.020
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.325
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.324
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 1.519
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 3.776
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 3.855
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.787
Epoch: 233/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 4.223
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 4.131
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.997
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 2.371
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.146
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.135
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 3.474
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 3.950
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 2.417
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.789
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.738
TRAINING: | Iteration [12/12] | Loss 0.16 | Norm 5.000
Epoch: 234/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 1.831
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 0.848
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 3.137
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.889
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 3.137
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 2.896
TRAINING: | Iteration [7/12] | Loss 0.14 | Norm 4.733
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.479
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 3.736
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 4.879
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.685
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 2.183
Epoch: 235/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 2.304
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.433
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.340
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 0.951
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.143
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 4.548
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.950
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 3.227
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 2.070
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.254
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 3.500
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.802
Epoch: 236/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.084
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.696
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.419
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 3.397
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 2.536
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 3.723
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 1.134
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 0.815
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.630
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.594
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.507
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 3.752
Epoch: 237/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 3.767
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.823
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 4.494
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 5.000
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.992
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.082
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 3.163
TRAINING: | Iteration [8/12] | Loss 0.16 | Norm 4.648
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.814
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 3.213
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 2.049
TRAINING: | Iteration [12/12] | Loss 0.15 | Norm 2.918
Epoch: 238/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 3.562
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 3.271
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 3.409
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 3.009
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 0.704
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.106
TRAINING: | Iteration [7/12] | Loss 0.16 | Norm 4.569
TRAINING: | Iteration [8/12] | Loss 0.17 | Norm 5.000
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.447
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 3.597
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.310
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.694
Epoch: 239/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 4.883
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 1.829
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.290
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.208
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.770
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.196
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 2.051
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 3.791
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.652
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.293
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.436
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.229
Epoch: 240/10000 | Epoch Time: 0.094 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.664
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 1.863
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.974
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.793
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 1.873
TRAINING: | Iteration [6/12] | Loss 0.16 | Norm 4.709
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 2.203
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 1.593
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 4.213
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 5.000
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 3.002
TRAINING: | Iteration [12/12] | Loss 0.17 | Norm 3.137
Epoch: 241/10000 | Epoch Time: 0.095 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 2.606
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 4.366
TRAINING: | Iteration [3/12] | Loss 0.14 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 5.000
TRAINING: | Iteration [5/12] | Loss 0.15 | Norm 5.000
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.662
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 4.162
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 5.000
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 5.000
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 1.767
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.569
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.622
Epoch: 242/10000 | Epoch Time: 0.095 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.471
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 2.221
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 3.805
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 1.968
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 2.204
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.436
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 2.159
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.941
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.663
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 3.162
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 2.217
TRAINING: | Iteration [12/12] | Loss 0.29 | Norm 4.148
Epoch: 243/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.826
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 3.216
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.428
TRAINING: | Iteration [4/12] | Loss 0.18 | Norm 5.000
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 1.359
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.397
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 2.753
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.348
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 4.353
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 4.698
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.111
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 3.179
Epoch: 244/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.616
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 2.055
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 4.551
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.203
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 2.206
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.349
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.319
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.608
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.480
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 2.590
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.527
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 3.145
Epoch: 245/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.459
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.543
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.872
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 2.679
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.605
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.271
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 2.928
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 2.892
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 2.072
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 3.465
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.319
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 2.601
Epoch: 246/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 1.708
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 3.734
TRAINING: | Iteration [3/12] | Loss 0.16 | Norm 4.584
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 5.000
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 3.056
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.622
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 3.030
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 3.171
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 3.222
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 4.940
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.946
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 2.188
Epoch: 247/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.667
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.003
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.211
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 2.345
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.523
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 1.679
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 2.608
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.551
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.309
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.058
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 2.811
Epoch: 248/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.775
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.586
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 2.141
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 3.688
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 1.814
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.792
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.007
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 5.000
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 5.000
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.186
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 3.320
Epoch: 249/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.662
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 2.220
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 3.280
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 2.709
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 3.165
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 1.467
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 1.596
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.402
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.139
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 4.810
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 4.481
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 2.770
Epoch: 250/10000 | Epoch Time: 0.094 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 3.332
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 4.626
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.245
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.337
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.380
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 2.102
TRAINING: | Iteration [7/12] | Loss 0.13 | Norm 3.611
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.588
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.731
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.100
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 2.457
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 0.911
Epoch: 251/10000 | Epoch Time: 0.095 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.625
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.733
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.702
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 3.736
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.722
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.757
TRAINING: | Iteration [7/12] | Loss 0.14 | Norm 2.517
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 2.278
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 2.217
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.383
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 3.543
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 3.253
Epoch: 252/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 2.733
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.600
TRAINING: | Iteration [3/12] | Loss 0.15 | Norm 4.563
TRAINING: | Iteration [4/12] | Loss 0.15 | Norm 4.342
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 2.498
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.941
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.840
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.141
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.778
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 5.000
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 3.291
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.055
Epoch: 253/10000 | Epoch Time: 0.095 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 0.939
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.902
TRAINING: | Iteration [3/12] | Loss 0.15 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 4.206
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 4.154
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.688
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.651
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 3.008
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 1.968
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 3.244
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.455
TRAINING: | Iteration [12/12] | Loss 0.29 | Norm 3.975
Epoch: 254/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.418
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 3.620
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 4.968
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 3.374
TRAINING: | Iteration [5/12] | Loss 0.15 | Norm 3.556
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 0.887
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 2.777
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.892
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 4.811
TRAINING: | Iteration [10/12] | Loss 0.15 | Norm 5.000
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.658
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 2.024
Epoch: 255/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.730
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 4.388
TRAINING: | Iteration [3/12] | Loss 0.16 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 3.161
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.260
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.322
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.809
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.323
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 2.793
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.230
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 2.678
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 0.623
Epoch: 256/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.876
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.407
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 2.073
TRAINING: | Iteration [4/12] | Loss 0.15 | Norm 5.000
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.695
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 2.051
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 2.914
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.307
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.926
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.444
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.451
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 2.173
Epoch: 257/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.026
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.405
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 2.403
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.459
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 2.785
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 3.198
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.591
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.730
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.403
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 4.468
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.163
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 1.276
Epoch: 258/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.113
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.737
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 3.149
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.278
TRAINING: | Iteration [5/12] | Loss 0.14 | Norm 2.871
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.100
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.161
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.895
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 3.278
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 1.998
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.532
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 3.762
Epoch: 259/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 2.039
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.086
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 0.543
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 3.965
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.678
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.862
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 2.002
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 2.577
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 0.660
TRAINING: | Iteration [10/12] | Loss 0.16 | Norm 2.133
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 1.766
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.289
Epoch: 260/10000 | Epoch Time: 0.094 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 1.702
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 0.943
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.789
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 1.607
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.628
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.238
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.351
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.496
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.241
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 2.213
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.684
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 2.213
Epoch: 261/10000 | Epoch Time: 0.095 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.652
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.803
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 3.259
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.928
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 3.710
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.492
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.237
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.497
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 3.709
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 2.337
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 2.792
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 2.241
Epoch: 262/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 3.596
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 1.118
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.355
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 1.918
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.500
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 3.365
TRAINING: | Iteration [7/12] | Loss 0.14 | Norm 2.492
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.603
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 2.347
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.175
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.104
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 5.000
Epoch: 263/10000 | Epoch Time: 0.095 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 4.672
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.426
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.140
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.595
TRAINING: | Iteration [5/12] | Loss 0.22 | Norm 5.000
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 5.000
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 2.478
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.996
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 2.706
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.902
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 2.240
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 3.797
Epoch: 264/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 3.184
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.893
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 3.834
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 2.824
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 2.118
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 3.805
TRAINING: | Iteration [7/12] | Loss 0.17 | Norm 5.000
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 3.281
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 2.514
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 3.701
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 3.353
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 3.001
Epoch: 265/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 3.155
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.722
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.097
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 3.141
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.052
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 4.267
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 3.163
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.519
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.960
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.981
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.397
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 3.307
Epoch: 266/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.446
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.503
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.725
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 2.330
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.332
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 2.176
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.800
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 4.043
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.898
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 0.687
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 3.920
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 4.464
Epoch: 267/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 3.837
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.233
TRAINING: | Iteration [3/12] | Loss 0.14 | Norm 2.505
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.442
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 2.788
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 4.739
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 4.708
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 2.084
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.763
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.568
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 3.914
TRAINING: | Iteration [12/12] | Loss 0.16 | Norm 3.877
Epoch: 268/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 4.376
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 3.009
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.404
TRAINING: | Iteration [4/12] | Loss 0.16 | Norm 2.236
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 3.404
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.987
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 0.993
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.770
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 1.330
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.077
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 0.939
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 1.817
Epoch: 269/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 0.885
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.529
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.125
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.405
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.852
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.117
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.754
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.233
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 1.900
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.939
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 3.400
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 3.025
Epoch: 270/10000 | Epoch Time: 0.095 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.04 | Norm 1.262
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 3.359
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.937
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 2.172
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.518
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.714
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.108
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.561
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 3.385
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 2.144
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.674
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 3.130
Epoch: 271/10000 | Epoch Time: 0.096 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.660
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.152
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.791
TRAINING: | Iteration [4/12] | Loss 0.15 | Norm 4.238
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 2.589
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.984
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.098
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.694
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 2.298
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 4.131
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.101
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 3.892
Epoch: 272/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 0.827
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.519
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 2.480
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 3.405
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.730
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 1.676
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.779
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 3.969
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.368
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 2.110
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.747
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 2.700
Epoch: 273/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.425
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 0.973
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.980
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.696
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.736
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.721
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 1.107
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 1.540
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 2.836
TRAINING: | Iteration [10/12] | Loss 0.18 | Norm 5.000
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 3.351
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 3.350
Epoch: 274/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.771
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 3.031
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 3.956
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 4.339
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 3.624
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 0.781
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.340
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 0.620
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 3.058
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 3.673
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 3.520
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.659
Epoch: 275/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.184
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.937
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.430
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.910
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 3.645
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.320
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.314
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.523
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.347
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 3.711
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.923
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 4.509
Epoch: 276/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.156
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.185
TRAINING: | Iteration [3/12] | Loss 0.14 | Norm 2.692
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 5.000
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 5.000
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 4.882
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 0.944
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 3.033
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.991
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.728
TRAINING: | Iteration [11/12] | Loss 0.22 | Norm 4.134
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.953
Epoch: 277/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 3.064
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.522
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 2.676
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.960
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.990
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.989
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 0.929
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.518
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.866
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.541
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 4.824
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 2.519
Epoch: 278/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.931
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.517
TRAINING: | Iteration [3/12] | Loss 0.04 | Norm 0.353
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.292
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.030
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.669
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 0.978
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 3.032
TRAINING: | Iteration [9/12] | Loss 0.04 | Norm 0.682
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 1.587
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 2.533
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.189
Epoch: 279/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 3.750
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.750
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 2.674
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.941
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 2.423
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 0.832
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 1.594
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.613
TRAINING: | Iteration [9/12] | Loss 0.17 | Norm 2.786
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 3.466
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.963
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.788
Epoch: 280/10000 | Epoch Time: 0.093 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.285
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 1.892
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 4.403
TRAINING: | Iteration [4/12] | Loss 0.17 | Norm 5.000
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 0.976
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 2.175
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 2.636
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 4.590
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 2.264
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.471
TRAINING: | Iteration [11/12] | Loss 0.21 | Norm 2.574
TRAINING: | Iteration [12/12] | Loss 0.17 | Norm 2.419
Epoch: 281/10000 | Epoch Time: 0.095 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.531
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 3.990
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 4.506
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.408
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 1.338
TRAINING: | Iteration [6/12] | Loss 0.14 | Norm 3.699
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 2.074
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.664
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 2.739
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.437
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.477
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.483
Epoch: 282/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.724
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.996
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.721
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.275
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 2.216
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.103
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.164
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.208
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 0.943
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.063
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.391
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.241
Epoch: 283/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.367
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.714
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.025
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.460
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 2.006
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.661
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.705
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.208
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.876
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 1.593
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.037
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 2.295
Epoch: 284/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.776
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.078
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 0.891
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.132
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.877
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.566
TRAINING: | Iteration [7/12] | Loss 0.15 | Norm 2.360
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 2.137
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.992
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 2.273
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.489
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 3.639
Epoch: 285/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.673
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 1.486
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.581
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 1.458
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.618
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.114
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 1.037
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.793
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 1.939
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.324
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 2.023
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.719
Epoch: 286/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 3.655
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 0.676
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 3.454
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.161
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.476
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 3.727
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 2.139
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 4.445
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.321
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 3.222
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.323
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 2.223
Epoch: 287/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.356
TRAINING: | Iteration [2/12] | Loss 0.15 | Norm 3.226
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 2.373
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 1.433
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 0.989
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.660
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.180
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 2.268
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 2.260
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.060
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.484
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.115
Epoch: 288/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 3.120
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.724
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 0.808
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 2.145
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.737
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.821
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 0.977
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.474
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 2.637
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.813
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.263
TRAINING: | Iteration [12/12] | Loss 0.17 | Norm 3.800
Epoch: 289/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 0.920
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 3.053
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.038
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.151
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.134
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.771
TRAINING: | Iteration [7/12] | Loss 0.04 | Norm 0.823
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.074
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.250
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 3.878
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.137
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 2.834
Epoch: 290/10000 | Epoch Time: 0.093 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.14 | Norm 3.825
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 3.095
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.304
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 3.975
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 3.565
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.242
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.112
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 3.794
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.768
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 3.157
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 3.496
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 3.080
Epoch: 291/10000 | Epoch Time: 0.095 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.165
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.709
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 4.443
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.342
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 2.188
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.747
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.837
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 3.045
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 3.598
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.982
TRAINING: | Iteration [11/12] | Loss 0.28 | Norm 5.000
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 2.880
Epoch: 292/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.15 | Norm 2.447
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.688
TRAINING: | Iteration [3/12] | Loss 0.23 | Norm 4.591
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 1.942
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 2.328
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 2.147
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 1.631
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.908
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.514
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.677
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 0.788
TRAINING: | Iteration [12/12] | Loss 0.04 | Norm 1.541
Epoch: 293/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.853
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.832
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.503
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.734
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.307
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 1.185
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.451
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 2.661
TRAINING: | Iteration [9/12] | Loss 0.04 | Norm 0.638
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.112
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 3.378
TRAINING: | Iteration [12/12] | Loss 0.15 | Norm 5.000
Epoch: 294/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.981
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 3.403
TRAINING: | Iteration [3/12] | Loss 0.14 | Norm 4.147
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 5.000
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.577
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 3.742
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 3.172
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 3.469
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 2.987
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 3.590
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.564
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.899
Epoch: 295/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 4.105
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 3.684
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.262
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 3.362
TRAINING: | Iteration [5/12] | Loss 0.15 | Norm 3.100
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 4.100
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 2.437
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 2.627
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 2.545
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.243
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.869
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 3.028
Epoch: 296/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.04 | Norm 1.327
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 3.468
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.620
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.048
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 1.329
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.966
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 2.040
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.157
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 0.757
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 0.671
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 2.585
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 1.666
Epoch: 297/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 0.663
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.040
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.893
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 3.020
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.508
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 3.488
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.331
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.072
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 4.048
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.022
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.158
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 4.223
Epoch: 298/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.586
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 3.971
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 2.557
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.601
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 1.905
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.174
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.997
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.601
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.893
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.708
TRAINING: | Iteration [11/12] | Loss 0.15 | Norm 2.506
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 1.019
Epoch: 299/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.422
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.491
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 3.664
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 2.418
TRAINING: | Iteration [5/12] | Loss 0.19 | Norm 3.047
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 2.314
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 1.311
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.654
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 1.903
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.558
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.195
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 3.516
Epoch: 300/10000 | Epoch Time: 0.093 seconds
Saving Model
Preparation of Training Data time: 47.846 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.842
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.909
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 2.357
TRAINING: | Iteration [4/12] | Loss 0.14 | Norm 2.754
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.104
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 4.314
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.878
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 0.814
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.276
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.149
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 3.321
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.411
Epoch: 301/10000 | Epoch Time: 0.114 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.712
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 3.159
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 1.692
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.521
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.983
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.300
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.982
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 3.110
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 2.329
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.633
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.857
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 4.585
Epoch: 302/10000 | Epoch Time: 0.107 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 3.351
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.872
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.790
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.838
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.119
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 2.487
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.492
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.306
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 2.004
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.583
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 2.265
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.772
Epoch: 303/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.251
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.004
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.169
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.644
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.359
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.177
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 3.800
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.504
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.555
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.601
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.011
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 2.171
Epoch: 304/10000 | Epoch Time: 0.114 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.658
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 4.350
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.270
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 0.859
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.330
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.219
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 3.222
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 0.594
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 1.843
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.157
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 1.223
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 1.672
Epoch: 305/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.274
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.011
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 3.145
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 2.271
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.837
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 2.848
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 0.734
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 0.823
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.413
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 1.441
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 2.133
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.957
Epoch: 306/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.870
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.898
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.990
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 3.836
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.103
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 1.386
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 3.457
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.927
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.796
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.268
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 3.101
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.863
Epoch: 307/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 3.683
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 4.848
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 3.147
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.610
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.861
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.576
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 1.570
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.691
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.440
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.612
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 0.803
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 2.419
Epoch: 308/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.161
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 2.522
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.411
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.264
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.470
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 2.092
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 0.883
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.403
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.140
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.813
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 2.889
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 2.482
Epoch: 309/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 2.630
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.866
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.444
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 3.440
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.694
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.786
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.818
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.486
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.102
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.196
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.521
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.892
Epoch: 310/10000 | Epoch Time: 0.101 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.657
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.255
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.005
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 2.888
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 0.968
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.999
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 2.628
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.574
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.400
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.325
TRAINING: | Iteration [11/12] | Loss 0.17 | Norm 3.150
TRAINING: | Iteration [12/12] | Loss 0.19 | Norm 4.664
Epoch: 311/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.604
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 4.273
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.049
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.027
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 2.194
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.388
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.305
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.673
TRAINING: | Iteration [9/12] | Loss 0.15 | Norm 3.940
TRAINING: | Iteration [10/12] | Loss 0.04 | Norm 0.973
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 1.530
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.548
Epoch: 312/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 3.161
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 5.000
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 3.763
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 2.187
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 3.278
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 4.429
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 3.754
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.722
TRAINING: | Iteration [9/12] | Loss 0.15 | Norm 5.000
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.595
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 5.000
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.827
Epoch: 313/10000 | Epoch Time: 0.117 seconds
TRAINING: | Iteration [1/12] | Loss 0.29 | Norm 5.000
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.040
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 2.360
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.600
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.343
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.740
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 3.766
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 3.355
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.697
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.170
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.089
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.200
Epoch: 314/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.670
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 0.959
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 2.806
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.529
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 1.642
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 2.797
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 2.420
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.886
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 4.961
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 4.084
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 3.569
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 2.244
Epoch: 315/10000 | Epoch Time: 0.116 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 4.554
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 4.819
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 3.023
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.227
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 2.672
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.879
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 2.804
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 2.483
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 5.000
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.552
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 2.986
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.307
Epoch: 316/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 3.779
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 2.714
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 3.056
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 2.299
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.856
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.359
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.668
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.251
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 1.077
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 1.497
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.885
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 0.942
Epoch: 317/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.011
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 1.011
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.732
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.087
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.790
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 2.754
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 2.096
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 4.197
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 3.707
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 0.955
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 1.462
TRAINING: | Iteration [12/12] | Loss 0.17 | Norm 3.047
Epoch: 318/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.270
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.513
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.181
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 2.515
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.380
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.126
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.505
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.225
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 2.515
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.766
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.029
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 1.589
Epoch: 319/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 3.844
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 2.635
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 2.550
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.344
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.795
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 2.030
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 1.412
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.016
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 0.835
TRAINING: | Iteration [10/12] | Loss 0.15 | Norm 2.558
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.425
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 3.079
Epoch: 320/10000 | Epoch Time: 0.100 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.392
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.721
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.955
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 0.852
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.345
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.426
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.545
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 2.609
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.159
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.578
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.214
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.632
Epoch: 321/10000 | Epoch Time: 0.106 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 2.320
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.732
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.352
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.470
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 2.525
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.738
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.631
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 3.191
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.510
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 1.908
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.669
TRAINING: | Iteration [12/12] | Loss 0.20 | Norm 5.000
Epoch: 322/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.117
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 2.202
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 3.859
TRAINING: | Iteration [5/12] | Loss 0.22 | Norm 3.591
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.847
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.802
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.962
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.496
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.548
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.134
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.890
Epoch: 323/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.15 | Norm 2.601
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 2.494
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.539
TRAINING: | Iteration [4/12] | Loss 0.15 | Norm 3.466
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.797
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 2.428
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.518
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.398
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.250
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.004
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 2.419
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 2.002
Epoch: 324/10000 | Epoch Time: 0.100 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.882
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.701
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 2.049
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.111
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 2.632
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 1.090
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.190
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 2.927
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.971
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.813
TRAINING: | Iteration [11/12] | Loss 0.14 | Norm 5.000
TRAINING: | Iteration [12/12] | Loss 0.15 | Norm 5.000
Epoch: 325/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.964
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 2.439
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.798
TRAINING: | Iteration [4/12] | Loss 0.17 | Norm 5.000
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 4.013
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.048
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.311
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.306
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.110
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.958
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.426
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 3.936
Epoch: 326/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.839
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 3.697
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 2.693
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 0.702
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 3.619
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.718
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.122
TRAINING: | Iteration [8/12] | Loss 0.04 | Norm 1.354
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 2.263
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 2.668
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.754
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 2.632
Epoch: 327/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 0.638
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.768
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.900
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 3.717
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.887
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 3.084
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.327
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.232
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 3.485
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 3.107
TRAINING: | Iteration [11/12] | Loss 0.15 | Norm 2.531
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.026
Epoch: 328/10000 | Epoch Time: 0.105 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 2.369
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 2.187
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.815
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.585
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.971
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 0.988
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.431
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 2.241
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.605
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 4.369
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 2.466
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.418
Epoch: 329/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 1.660
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 2.201
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 1.941
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.198
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.509
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 2.618
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.423
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.462
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.347
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.482
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.809
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 2.537
Epoch: 330/10000 | Epoch Time: 0.102 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.296
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 2.944
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 3.514
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 2.532
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 1.368
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 5.000
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 3.106
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 1.062
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.970
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.137
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.359
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 2.331
Epoch: 331/10000 | Epoch Time: 0.106 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 2.725
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.107
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 2.031
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 4.108
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 2.740
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.237
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.534
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 2.068
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.674
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.060
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 2.224
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.626
Epoch: 332/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.147
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 1.834
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.029
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 0.846
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 0.898
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.074
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.034
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.795
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.340
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.923
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.905
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 3.044
Epoch: 333/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 1.380
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.398
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.259
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 3.510
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.698
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.365
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 1.195
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.188
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.584
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 4.424
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 0.705
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 2.259
Epoch: 334/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.874
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 3.024
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 0.949
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.569
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 4.007
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.206
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 2.691
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.977
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.472
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.287
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.551
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 0.700
Epoch: 335/10000 | Epoch Time: 0.116 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.734
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.211
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.957
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.593
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.652
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 1.782
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 0.614
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 1.507
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.587
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 2.856
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 2.924
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 2.468
Epoch: 336/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 4.375
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.759
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 4.308
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 3.081
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 1.304
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 0.909
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 3.164
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.993
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 4.672
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 2.143
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.728
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.574
Epoch: 337/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.955
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.356
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 3.087
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 3.018
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 2.039
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.598
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 2.352
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 3.482
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 3.597
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 3.924
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.697
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 3.184
Epoch: 338/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 3.112
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 3.354
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 3.472
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.381
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.772
TRAINING: | Iteration [6/12] | Loss 0.04 | Norm 2.058
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.843
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 4.909
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 2.394
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 1.295
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 1.836
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 1.696
Epoch: 339/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 3.995
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 4.372
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 3.220
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.710
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 4.201
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 4.878
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 2.575
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.729
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.438
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 3.239
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 2.287
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.296
Epoch: 340/10000 | Epoch Time: 0.104 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.853
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.822
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 0.857
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 1.662
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.246
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.249
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 2.738
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.011
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 1.368
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 1.678
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.569
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.319
Epoch: 341/10000 | Epoch Time: 0.106 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.580
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 2.121
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 3.137
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.290
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.421
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.801
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.680
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 1.477
TRAINING: | Iteration [9/12] | Loss 0.17 | Norm 2.664
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.199
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.850
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.523
Epoch: 342/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 2.620
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 3.935
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.360
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 2.321
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.072
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 1.716
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 1.005
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.520
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 5.000
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 0.684
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 3.144
TRAINING: | Iteration [12/12] | Loss 0.16 | Norm 4.583
Epoch: 343/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 3.116
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.716
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 3.183
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.952
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 0.963
TRAINING: | Iteration [6/12] | Loss 0.19 | Norm 3.671
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 3.893
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.199
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 4.829
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 1.212
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 3.024
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 1.516
Epoch: 344/10000 | Epoch Time: 0.100 seconds
TRAINING: | Iteration [1/12] | Loss 0.18 | Norm 3.933
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 2.444
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 0.930
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 2.116
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.235
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 2.263
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.826
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.523
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 2.208
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.426
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 0.826
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.611
Epoch: 345/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.187
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 2.333
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 2.306
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.133
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 2.025
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 1.859
TRAINING: | Iteration [7/12] | Loss 0.04 | Norm 0.899
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 1.915
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.625
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 3.019
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 4.357
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.753
Epoch: 346/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 2.318
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.368
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 3.606
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.142
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 3.060
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 3.447
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 2.995
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.778
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 2.962
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.447
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 2.724
TRAINING: | Iteration [12/12] | Loss 0.16 | Norm 3.048
Epoch: 347/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.538
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 4.475
TRAINING: | Iteration [3/12] | Loss 0.14 | Norm 3.023
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 3.553
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 2.012
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 3.440
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 2.630
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.707
TRAINING: | Iteration [9/12] | Loss 0.23 | Norm 3.268
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 2.158
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 2.780
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.128
Epoch: 348/10000 | Epoch Time: 0.105 seconds
TRAINING: | Iteration [1/12] | Loss 0.27 | Norm 5.000
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 2.203
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 2.127
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 3.767
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 3.127
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 0.804
TRAINING: | Iteration [7/12] | Loss 0.15 | Norm 3.334
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.732
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.988
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 2.968
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.808
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.236
Epoch: 349/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.701
TRAINING: | Iteration [2/12] | Loss 0.15 | Norm 4.999
TRAINING: | Iteration [3/12] | Loss 0.15 | Norm 3.567
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.237
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 0.991
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 0.888
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 3.113
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 3.407
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 2.334
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 0.968
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 1.053
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.800
Epoch: 350/10000 | Epoch Time: 0.103 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 1.202
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.554
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 3.164
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.534
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 3.704
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.266
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 1.720
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.010
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 3.311
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 3.196
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.938
TRAINING: | Iteration [12/12] | Loss 0.16 | Norm 2.479
Epoch: 351/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.441
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 1.411
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.395
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.743
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.253
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.396
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.840
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.564
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.640
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 3.417
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.667
TRAINING: | Iteration [12/12] | Loss 0.18 | Norm 4.744
Epoch: 352/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 2.074
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.754
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.508
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 2.235
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.237
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.322
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.478
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.671
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 2.321
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.796
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 2.723
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 0.681
Epoch: 353/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.730
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.354
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 3.141
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 0.943
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.122
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 1.699
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 3.030
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 0.961
TRAINING: | Iteration [9/12] | Loss 0.17 | Norm 3.129
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.350
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 5.000
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 2.686
Epoch: 354/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.143
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.961
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 4.047
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.938
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.280
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.529
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.251
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.488
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 1.158
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 3.748
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 2.240
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 3.074
Epoch: 355/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 2.010
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 3.286
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.493
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 3.854
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 4.883
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 0.978
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 2.214
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 1.099
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 3.684
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 3.182
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.363
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 4.138
Epoch: 356/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.650
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.361
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.553
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 4.760
TRAINING: | Iteration [5/12] | Loss 0.17 | Norm 4.846
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.256
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 2.483
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.259
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 4.236
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 4.164
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 4.818
TRAINING: | Iteration [12/12] | Loss 0.25 | Norm 3.965
Epoch: 357/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.962
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 3.764
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 3.135
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 3.839
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.565
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 1.483
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 5.000
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 3.282
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 4.308
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.890
TRAINING: | Iteration [12/12] | Loss 0.04 | Norm 1.914
Epoch: 358/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.261
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 3.278
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.206
TRAINING: | Iteration [4/12] | Loss 0.19 | Norm 5.000
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.959
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.568
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 2.332
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 3.826
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 0.868
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.458
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.118
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 3.440
Epoch: 359/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 0.805
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.235
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.848
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.239
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 0.936
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 3.347
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 1.469
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.844
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.373
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.693
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.256
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.510
Epoch: 360/10000 | Epoch Time: 0.100 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.024
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.205
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.305
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.169
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 1.741
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 3.185
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.105
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 0.963
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 2.611
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.057
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 3.598
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 4.062
Epoch: 361/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 2.296
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 2.148
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 1.337
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.160
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 3.367
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.285
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.833
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.873
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 3.152
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 1.762
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.128
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.951
Epoch: 362/10000 | Epoch Time: 0.100 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.093
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 4.406
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.090
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.919
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.774
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 3.025
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 3.456
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 3.495
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 1.985
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 3.247
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.552
TRAINING: | Iteration [12/12] | Loss 0.20 | Norm 4.251
Epoch: 363/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.04 | Norm 0.731
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 2.111
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 1.531
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.007
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 1.787
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 3.835
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 3.533
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.551
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 0.802
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 3.266
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 1.734
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 5.000
Epoch: 364/10000 | Epoch Time: 0.100 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.805
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.555
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 2.610
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 2.271
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 2.111
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.632
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.693
TRAINING: | Iteration [8/12] | Loss 0.17 | Norm 2.626
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 3.035
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 0.929
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 1.664
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 3.923
Epoch: 365/10000 | Epoch Time: 0.100 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.298
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.729
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.410
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.465
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.364
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 3.960
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 3.066
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.459
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.917
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.385
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 5.000
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 5.000
Epoch: 366/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.553
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 4.094
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 3.373
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 3.169
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.600
TRAINING: | Iteration [7/12] | Loss 0.19 | Norm 3.839
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.646
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 3.849
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 4.032
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 1.692
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 1.544
Epoch: 367/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.461
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 2.421
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 3.799
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 2.632
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 2.059
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 2.007
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.665
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 3.251
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 5.000
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 4.046
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 1.628
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.772
Epoch: 368/10000 | Epoch Time: 0.115 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.606
TRAINING: | Iteration [2/12] | Loss 0.14 | Norm 5.000
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 4.299
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 2.628
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 0.764
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.905
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.673
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.784
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 2.829
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.415
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.652
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 0.750
Epoch: 369/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.254
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 2.948
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.330
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.736
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 2.198
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.505
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.020
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.578
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 3.133
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.466
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.581
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 1.670
Epoch: 370/10000 | Epoch Time: 0.102 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.036
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 3.281
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.273
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.306
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 2.781
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 1.203
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 2.064
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.079
TRAINING: | Iteration [9/12] | Loss 0.04 | Norm 0.503
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.569
TRAINING: | Iteration [11/12] | Loss 0.04 | Norm 0.523
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 2.186
Epoch: 371/10000 | Epoch Time: 0.108 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 2.287
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 2.261
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.388
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.270
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.330
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.287
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 4.575
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 3.970
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 2.808
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 3.386
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 2.289
TRAINING: | Iteration [12/12] | Loss 0.19 | Norm 3.823
Epoch: 372/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 3.868
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.249
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 3.156
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 2.071
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 3.322
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 1.611
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 2.193
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.030
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.528
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 2.308
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 1.818
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 3.401
Epoch: 373/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.460
TRAINING: | Iteration [2/12] | Loss 0.15 | Norm 3.468
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.646
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 3.651
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 3.387
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.587
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.988
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.635
TRAINING: | Iteration [9/12] | Loss 0.16 | Norm 5.000
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 4.417
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 1.523
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.387
Epoch: 374/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.105
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 4.772
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.859
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 4.422
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 1.517
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 2.703
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 4.117
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 2.652
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 3.794
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.652
TRAINING: | Iteration [11/12] | Loss 0.14 | Norm 2.495
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.975
Epoch: 375/10000 | Epoch Time: 0.099 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.352
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 4.315
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.562
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.944
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.676
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 2.003
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 2.594
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.679
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 4.617
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 2.272
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.502
TRAINING: | Iteration [12/12] | Loss 0.17 | Norm 3.194
Epoch: 376/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.457
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.776
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.903
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 1.532
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 1.820
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.565
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.678
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.189
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.369
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.823
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 1.286
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 3.825
Epoch: 377/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 4.419
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.720
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.482
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.593
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.841
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 2.772
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 0.857
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.752
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.118
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 0.929
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 2.375
TRAINING: | Iteration [12/12] | Loss 0.04 | Norm 0.712
Epoch: 378/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.952
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 3.084
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 2.800
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.261
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.719
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 3.487
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 2.079
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 4.855
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.652
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.373
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 3.314
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 2.320
Epoch: 379/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.614
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 0.772
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.595
TRAINING: | Iteration [4/12] | Loss 0.14 | Norm 3.040
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.256
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.936
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.946
TRAINING: | Iteration [8/12] | Loss 0.04 | Norm 1.437
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 1.878
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.706
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.932
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 2.570
Epoch: 380/10000 | Epoch Time: 0.101 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.352
TRAINING: | Iteration [2/12] | Loss 0.04 | Norm 0.701
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.991
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 1.910
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.617
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.982
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 2.330
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.065
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 3.731
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 2.696
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.439
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.808
Epoch: 381/10000 | Epoch Time: 0.121 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.886
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 3.498
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 2.404
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 3.235
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 3.321
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 2.714
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.385
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.863
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 2.758
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.931
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 3.433
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 2.158
Epoch: 382/10000 | Epoch Time: 0.100 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.974
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.634
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 2.414
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 3.741
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.095
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 0.840
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.136
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 2.184
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 2.217
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 3.106
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.147
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.274
Epoch: 383/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.447
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.349
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 3.135
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.907
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 0.884
TRAINING: | Iteration [6/12] | Loss 0.17 | Norm 2.847
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.478
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 2.619
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.680
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 3.431
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.043
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.589
Epoch: 384/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 3.335
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 3.258
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 1.749
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.755
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.804
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.257
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.083
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.424
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 3.591
TRAINING: | Iteration [10/12] | Loss 0.17 | Norm 3.823
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.363
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 1.927
Epoch: 385/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 5.000
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 4.871
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 4.200
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.897
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 3.393
TRAINING: | Iteration [6/12] | Loss 0.14 | Norm 5.000
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 5.000
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 3.839
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.749
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.069
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 4.144
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 3.775
Epoch: 386/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 5.000
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 3.651
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 3.113
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.690
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 3.115
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.996
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 2.468
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.563
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.392
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.279
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 4.575
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.815
Epoch: 387/10000 | Epoch Time: 0.115 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.180
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.687
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.049
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.318
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.442
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.520
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.936
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.093
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.602
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.491
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.325
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 2.637
Epoch: 388/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.762
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 3.169
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 2.443
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.033
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.263
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 3.088
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.130
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 2.377
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 1.058
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.882
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.084
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 5.000
Epoch: 389/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 2.738
TRAINING: | Iteration [2/12] | Loss 0.14 | Norm 2.508
TRAINING: | Iteration [3/12] | Loss 0.17 | Norm 3.315
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.273
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 2.146
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 2.912
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 3.797
TRAINING: | Iteration [8/12] | Loss 0.04 | Norm 1.027
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.261
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.820
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 2.738
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.992
Epoch: 390/10000 | Epoch Time: 0.104 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.234
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.852
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.153
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.572
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 3.526
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.362
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 0.648
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.356
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.096
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.503
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 3.423
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 2.100
Epoch: 391/10000 | Epoch Time: 0.105 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.686
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.575
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 3.262
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.679
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.118
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.232
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.151
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.763
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.121
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 0.650
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 2.678
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.768
Epoch: 392/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.894
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.049
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.539
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 2.766
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 2.812
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.113
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 2.344
TRAINING: | Iteration [8/12] | Loss 0.19 | Norm 3.526
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 3.004
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.121
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 2.487
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 2.805
Epoch: 393/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.718
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.077
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 3.672
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.858
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 0.778
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 2.719
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.394
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 3.499
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.720
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 2.269
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.042
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.875
Epoch: 394/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.500
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.991
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.437
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 1.757
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 0.811
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 2.288
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 2.111
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.176
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.306
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.261
TRAINING: | Iteration [11/12] | Loss 0.04 | Norm 0.432
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 1.937
Epoch: 395/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 0.744
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.940
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.822
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 1.268
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 1.988
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.563
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.333
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 2.364
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.435
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.798
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 2.499
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.200
Epoch: 396/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 0.882
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.257
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.557
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 1.136
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 2.233
TRAINING: | Iteration [6/12] | Loss 0.04 | Norm 0.847
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.513
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 2.609
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 0.613
TRAINING: | Iteration [10/12] | Loss 0.16 | Norm 2.757
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 1.827
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 0.818
Epoch: 397/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.14 | Norm 2.137
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 2.554
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.894
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 3.054
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.638
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.771
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.520
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 1.193
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.015
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.375
TRAINING: | Iteration [11/12] | Loss 0.16 | Norm 3.067
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 2.171
Epoch: 398/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.710
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 0.789
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.614
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 2.143
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.078
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 3.602
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 2.896
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.100
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.474
TRAINING: | Iteration [10/12] | Loss 0.16 | Norm 3.951
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 4.489
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 1.198
Epoch: 399/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 3.167
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 2.996
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.962
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 2.022
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.681
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 3.511
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.874
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.396
TRAINING: | Iteration [9/12] | Loss 0.17 | Norm 2.993
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 3.469
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 3.422
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.457
Epoch: 400/10000 | Epoch Time: 0.102 seconds
Saving Model
Preparation of Training Data time: 64.109 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.242
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 2.031
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.676
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.746
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.978
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 0.899
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.269
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.552
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.963
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 2.247
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.942
TRAINING: | Iteration [12/12] | Loss 0.15 | Norm 2.726
Epoch: 401/10000 | Epoch Time: 0.132 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.317
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.765
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 2.195
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 2.089
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 1.255
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 0.971
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.539
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.754
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.519
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.558
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.076
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.720
Epoch: 402/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.388
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.179
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 3.197
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 2.731
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.500
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 0.602
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.415
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.558
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 4.170
TRAINING: | Iteration [10/12] | Loss 0.15 | Norm 4.475
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.062
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 2.091
Epoch: 403/10000 | Epoch Time: 0.120 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 2.482
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.004
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 3.138
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.385
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 1.015
TRAINING: | Iteration [6/12] | Loss 0.03 | Norm 0.971
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 3.246
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.751
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 1.360
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.524
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.558
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 1.960
Epoch: 404/10000 | Epoch Time: 0.116 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.374
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 0.730
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.428
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.564
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 3.388
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 2.808
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 3.451
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 1.571
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 3.830
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 3.919
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.839
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 2.321
Epoch: 405/10000 | Epoch Time: 0.119 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.700
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.668
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 3.006
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 4.430
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 3.616
TRAINING: | Iteration [6/12] | Loss 0.17 | Norm 4.399
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 4.668
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 3.332
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 4.276
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.137
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 2.580
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 2.586
Epoch: 406/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.921
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 3.508
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.487
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 2.915
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 2.918
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.086
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.103
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.210
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.617
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.122
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 1.724
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.939
Epoch: 407/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.257
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.595
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 2.132
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.380
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.845
TRAINING: | Iteration [6/12] | Loss 0.20 | Norm 4.532
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.565
TRAINING: | Iteration [8/12] | Loss 0.15 | Norm 2.784
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.965
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 5.000
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 4.074
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 2.334
Epoch: 408/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.229
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 2.786
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 2.840
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 2.906
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 3.303
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 2.146
TRAINING: | Iteration [7/12] | Loss 0.15 | Norm 3.419
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 3.099
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 4.127
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.707
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 2.163
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.394
Epoch: 409/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.857
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.008
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 1.273
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.628
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.407
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.021
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 3.689
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 3.302
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.566
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.164
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 2.556
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 0.655
Epoch: 410/10000 | Epoch Time: 0.104 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 3.901
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.715
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.674
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.425
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.232
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.547
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 5.000
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 2.788
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.956
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.753
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.823
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 3.457
Epoch: 411/10000 | Epoch Time: 0.106 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.844
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 2.669
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 1.109
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.788
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 0.660
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 3.413
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 2.622
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.256
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 3.529
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.212
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 1.731
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.468
Epoch: 412/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 3.331
TRAINING: | Iteration [2/12] | Loss 0.04 | Norm 1.021
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 1.297
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.824
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.861
TRAINING: | Iteration [6/12] | Loss 0.22 | Norm 2.874
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 2.462
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.479
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.114
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.145
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.259
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.545
Epoch: 413/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.036
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.938
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.862
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.335
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.489
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.363
TRAINING: | Iteration [7/12] | Loss 0.13 | Norm 2.631
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 3.634
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.590
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.892
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 0.786
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 1.071
Epoch: 414/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.14 | Norm 2.178
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 3.657
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.904
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.689
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 2.031
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.748
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.792
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.968
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 3.870
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.727
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 2.072
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.605
Epoch: 415/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 3.633
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.373
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 2.607
TRAINING: | Iteration [4/12] | Loss 0.04 | Norm 0.824
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 1.620
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 3.019
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 3.180
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 3.060
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 2.288
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.249
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.980
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 5.000
Epoch: 416/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 4.738
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.283
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 1.011
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.531
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.413
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.782
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 2.616
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.091
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.842
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 2.427
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.545
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 2.542
Epoch: 417/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.311
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 2.608
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.296
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.449
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 0.956
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.251
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 2.836
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.663
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.143
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.347
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.550
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.680
Epoch: 418/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 2.606
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.209
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 0.983
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.347
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.201
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.764
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.303
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.209
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.119
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.638
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 0.953
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.524
Epoch: 419/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.091
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 3.926
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 2.389
TRAINING: | Iteration [4/12] | Loss 0.04 | Norm 1.410
TRAINING: | Iteration [5/12] | Loss 0.04 | Norm 1.634
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.077
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.737
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 3.284
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 2.032
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.312
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 3.279
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.316
Epoch: 420/10000 | Epoch Time: 0.103 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 4.048
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 2.897
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.159
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.341
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 3.448
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 5.000
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.961
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.736
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.532
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.552
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.958
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 3.875
Epoch: 421/10000 | Epoch Time: 0.105 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.687
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 3.264
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 3.783
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 4.472
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 3.392
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 0.891
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 2.391
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 0.936
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 1.249
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.553
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.371
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 1.745
Epoch: 422/10000 | Epoch Time: 0.116 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 1.052
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 2.719
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 1.476
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 3.091
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.978
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.571
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 1.307
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 0.918
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 3.041
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 2.116
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.530
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 1.426
Epoch: 423/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.959
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 3.002
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.364
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 1.312
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 0.529
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 0.897
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 3.040
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.692
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.120
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 2.186
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.439
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 2.246
Epoch: 424/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.294
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.281
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 1.967
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 2.285
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 2.244
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 1.942
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.120
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 1.244
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.623
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 1.456
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 2.790
TRAINING: | Iteration [12/12] | Loss 0.04 | Norm 0.798
Epoch: 425/10000 | Epoch Time: 0.106 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 0.810
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 1.535
TRAINING: | Iteration [3/12] | Loss 0.04 | Norm 1.254
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.749
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.585
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.945
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.745
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.640
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 2.694
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.910
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.645
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 1.301
Epoch: 426/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.985
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 3.775
TRAINING: | Iteration [3/12] | Loss 0.04 | Norm 0.744
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.520
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.822
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 0.580
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.996
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 3.345
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 2.376
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.504
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 1.567
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.967
Epoch: 427/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.619
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 0.901
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.827
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 1.965
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 2.346
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.290
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.277
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 1.193
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.832
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.677
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.058
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 2.308
Epoch: 428/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.628
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.905
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 3.252
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 3.737
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.932
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 1.645
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.561
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 2.848
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.643
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 2.984
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.646
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 0.717
Epoch: 429/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.368
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.845
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.988
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 2.621
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 2.477
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.877
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.976
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 0.741
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 2.664
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 3.318
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.724
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.402
Epoch: 430/10000 | Epoch Time: 0.101 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 1.025
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 0.810
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.628
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.927
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 1.690
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 2.171
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.443
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 1.557
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 0.998
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.722
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.746
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.862
Epoch: 431/10000 | Epoch Time: 0.105 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.189
TRAINING: | Iteration [2/12] | Loss 0.03 | Norm 0.964
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 2.708
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.524
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 3.086
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 3.216
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 3.107
TRAINING: | Iteration [8/12] | Loss 0.25 | Norm 3.703
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.447
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.931
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 2.684
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 2.486
Epoch: 432/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 0.748
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 1.427
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.156
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.947
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 1.975
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.280
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.920
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.644
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 2.519
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.873
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.225
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 0.946
Epoch: 433/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.010
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 1.002
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.703
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 0.795
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 1.893
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 2.215
TRAINING: | Iteration [7/12] | Loss 0.04 | Norm 2.142
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 3.569
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 3.054
TRAINING: | Iteration [10/12] | Loss 0.17 | Norm 3.213
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 1.996
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 3.367
Epoch: 434/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.831
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.794
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.353
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 0.950
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.294
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 2.404
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 3.635
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 3.335
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 1.930
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.643
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 1.990
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 5.000
Epoch: 435/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.14 | Norm 4.594
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.543
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.851
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 0.874
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 2.857
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.703
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 4.137
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.012
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.272
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 0.934
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 2.817
TRAINING: | Iteration [12/12] | Loss 0.22 | Norm 5.000
Epoch: 436/10000 | Epoch Time: 0.114 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.108
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.832
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.081
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.418
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 2.514
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 3.353
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 3.983
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.882
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.080
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 0.909
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.061
TRAINING: | Iteration [12/12] | Loss 0.15 | Norm 5.000
Epoch: 437/10000 | Epoch Time: 0.100 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.615
TRAINING: | Iteration [2/12] | Loss 0.14 | Norm 2.327
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.288
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 4.877
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 1.280
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.726
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 2.746
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.774
TRAINING: | Iteration [9/12] | Loss 0.16 | Norm 2.359
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.215
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.225
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.938
Epoch: 438/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.551
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 3.286
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 3.374
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.239
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 0.627
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 1.420
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.926
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.992
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 2.352
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.719
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 2.228
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.202
Epoch: 439/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.856
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 3.078
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.938
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.663
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 2.012
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 0.853
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.400
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 2.166
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 2.303
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.612
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.157
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 2.787
Epoch: 440/10000 | Epoch Time: 0.101 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 3.973
TRAINING: | Iteration [2/12] | Loss 0.04 | Norm 0.912
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 2.908
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 1.382
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 3.236
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 3.695
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 2.701
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.565
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.823
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 4.976
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 4.105
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 1.472
Epoch: 441/10000 | Epoch Time: 0.107 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 2.094
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.787
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 4.509
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.985
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.731
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 1.984
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 4.795
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 1.938
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 0.964
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 2.438
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.646
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.126
Epoch: 442/10000 | Epoch Time: 0.118 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 2.197
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 3.209
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 2.297
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.630
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 1.897
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 2.289
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 3.028
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.587
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.851
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 0.713
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 2.048
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.547
Epoch: 443/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.734
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.283
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.957
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 2.843
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.129
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 1.759
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 5.000
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.500
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.569
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 1.823
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 1.741
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 2.929
Epoch: 444/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 2.372
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.829
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.650
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.379
TRAINING: | Iteration [5/12] | Loss 0.15 | Norm 2.516
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.861
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.881
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 1.207
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 1.115
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.062
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 1.363
TRAINING: | Iteration [12/12] | Loss 0.04 | Norm 0.465
Epoch: 445/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 1.635
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.697
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 0.847
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.309
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 2.184
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 1.435
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.280
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.474
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 2.285
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 2.581
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.106
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.586
Epoch: 446/10000 | Epoch Time: 0.100 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.014
TRAINING: | Iteration [2/12] | Loss 0.16 | Norm 3.249
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 3.241
TRAINING: | Iteration [4/12] | Loss 0.04 | Norm 1.846
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.891
TRAINING: | Iteration [6/12] | Loss 0.04 | Norm 1.109
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.770
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.464
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.759
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 2.636
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.419
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.742
Epoch: 447/10000 | Epoch Time: 0.117 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.679
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 1.264
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.555
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 0.921
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.194
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 1.511
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.542
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 2.163
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 3.526
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.652
TRAINING: | Iteration [11/12] | Loss 0.16 | Norm 3.217
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.465
Epoch: 448/10000 | Epoch Time: 0.118 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 3.267
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.902
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.494
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 2.135
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 3.021
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 3.401
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.135
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 1.471
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.425
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 2.200
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 3.406
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 3.545
Epoch: 449/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.966
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 2.308
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 2.386
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 2.391
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.320
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 2.213
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.545
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.591
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.693
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 3.502
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 2.668
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 2.574
Epoch: 450/10000 | Epoch Time: 0.102 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.144
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.383
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 3.328
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.443
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 1.570
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.327
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.798
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 1.405
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.033
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 1.236
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 2.774
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.824
Epoch: 451/10000 | Epoch Time: 0.106 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 1.597
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.858
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 1.280
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.254
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.465
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.822
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.626
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.366
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.443
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.888
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 0.954
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.660
Epoch: 452/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 2.122
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.328
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 2.470
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 1.641
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 2.427
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 1.856
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.459
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 3.234
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.626
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.923
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.644
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 2.418
Epoch: 453/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.693
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 2.961
TRAINING: | Iteration [3/12] | Loss 0.16 | Norm 2.558
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 3.746
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 2.591
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.480
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.330
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.471
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.171
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.130
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.681
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 1.321
Epoch: 454/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 3.103
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.973
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 0.593
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.228
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.781
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 1.233
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.716
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.707
TRAINING: | Iteration [9/12] | Loss 0.04 | Norm 1.182
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.696
TRAINING: | Iteration [11/12] | Loss 0.18 | Norm 2.929
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.253
Epoch: 455/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.622
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.260
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.167
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 3.675
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 1.623
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.871
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.752
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 3.902
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.208
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.828
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.870
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 2.092
Epoch: 456/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.770
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.566
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 1.415
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.046
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.853
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 1.365
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 3.871
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 2.090
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 4.441
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.194
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.496
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.669
Epoch: 457/10000 | Epoch Time: 0.116 seconds
TRAINING: | Iteration [1/12] | Loss 0.04 | Norm 0.494
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 0.920
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 1.796
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.912
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 2.954
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 3.178
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.613
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 2.674
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 1.598
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 2.040
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 3.893
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 1.213
Epoch: 458/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.647
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.250
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 0.922
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.260
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 2.699
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 1.783
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.917
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.592
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 2.175
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.152
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 1.065
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.682
Epoch: 459/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.131
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 1.750
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 2.717
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.979
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.570
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.273
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.564
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.224
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 0.802
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 1.204
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.403
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 0.708
Epoch: 460/10000 | Epoch Time: 0.100 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.098
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.105
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 1.768
TRAINING: | Iteration [4/12] | Loss 0.04 | Norm 1.066
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 1.332
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.851
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.652
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.688
TRAINING: | Iteration [9/12] | Loss 0.04 | Norm 0.768
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.908
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 0.818
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.257
Epoch: 461/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.580
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.522
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 2.293
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.412
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.363
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 0.961
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.267
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 0.845
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 2.584
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.393
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.758
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.420
Epoch: 462/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.735
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 1.162
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 1.198
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.844
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.431
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.302
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.294
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.194
TRAINING: | Iteration [9/12] | Loss 0.17 | Norm 5.000
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 0.723
TRAINING: | Iteration [11/12] | Loss 0.16 | Norm 4.410
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.261
Epoch: 463/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.172
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.215
TRAINING: | Iteration [3/12] | Loss 0.04 | Norm 1.231
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.171
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.880
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.433
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 2.169
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.605
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 1.369
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.766
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.360
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.471
Epoch: 464/10000 | Epoch Time: 0.100 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.836
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.253
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.737
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.257
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.263
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 2.440
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 2.013
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.114
TRAINING: | Iteration [9/12] | Loss 0.04 | Norm 1.693
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.081
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.654
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 2.615
Epoch: 465/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.333
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 3.137
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 1.088
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 2.213
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 2.063
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.685
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.758
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 2.902
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.410
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.840
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.842
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.036
Epoch: 466/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 1.453
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.969
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 3.092
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 1.112
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.816
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.350
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.365
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.703
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 4.236
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 2.165
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.314
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.510
Epoch: 467/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 2.604
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 0.425
TRAINING: | Iteration [3/12] | Loss 0.15 | Norm 3.282
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 2.604
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.377
TRAINING: | Iteration [6/12] | Loss 0.14 | Norm 2.688
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 2.611
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.636
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 2.439
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 3.052
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 3.048
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 2.631
Epoch: 468/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.588
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 3.764
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 2.981
TRAINING: | Iteration [4/12] | Loss 0.04 | Norm 1.131
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.691
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.071
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 3.704
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.922
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 3.263
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.631
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 0.751
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 3.085
Epoch: 469/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 3.049
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 2.361
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 3.201
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.721
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.621
TRAINING: | Iteration [6/12] | Loss 0.04 | Norm 0.600
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 2.016
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.303
TRAINING: | Iteration [9/12] | Loss 0.14 | Norm 2.315
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 0.572
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 2.546
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.350
Epoch: 470/10000 | Epoch Time: 0.104 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.04 | Norm 0.784
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 1.281
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 2.358
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.805
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.252
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.655
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 2.521
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.388
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.727
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.188
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 2.328
TRAINING: | Iteration [12/12] | Loss 0.15 | Norm 3.753
Epoch: 471/10000 | Epoch Time: 0.105 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.749
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 0.819
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.473
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.431
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.778
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.445
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 2.029
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.438
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.745
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.844
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 3.169
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 3.301
Epoch: 472/10000 | Epoch Time: 0.113 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 1.858
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.038
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 2.204
TRAINING: | Iteration [4/12] | Loss 0.14 | Norm 5.000
TRAINING: | Iteration [5/12] | Loss 0.15 | Norm 4.066
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 2.080
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.483
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.622
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 5.000
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 3.700
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 1.133
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.765
Epoch: 473/10000 | Epoch Time: 0.120 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.071
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.742
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.321
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.756
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 2.536
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.799
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.618
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.556
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.848
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 2.386
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.374
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 2.322
Epoch: 474/10000 | Epoch Time: 0.117 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 1.662
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 2.277
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 2.503
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.544
TRAINING: | Iteration [5/12] | Loss 0.15 | Norm 2.630
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 2.149
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.372
TRAINING: | Iteration [8/12] | Loss 0.04 | Norm 1.175
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.674
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.783
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.868
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 3.205
Epoch: 475/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.625
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.362
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.750
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 0.966
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.753
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.474
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 1.292
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.855
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.176
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 0.907
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 0.882
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 0.761
Epoch: 476/10000 | Epoch Time: 0.105 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 2.408
TRAINING: | Iteration [2/12] | Loss 0.04 | Norm 0.781
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 1.642
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.727
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 1.079
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 1.564
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 1.719
TRAINING: | Iteration [8/12] | Loss 0.04 | Norm 1.458
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.385
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 1.308
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.959
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 2.905
Epoch: 477/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.783
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 3.179
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 2.801
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 1.358
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 2.136
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 2.860
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 1.299
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 2.972
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.216
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.957
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.100
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.623
Epoch: 478/10000 | Epoch Time: 0.106 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.975
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 1.597
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 1.121
TRAINING: | Iteration [4/12] | Loss 0.04 | Norm 0.955
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.036
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.589
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.564
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 2.993
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.954
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.545
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.793
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 2.010
Epoch: 479/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.893
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.446
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.314
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.536
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.253
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 0.918
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 3.582
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.912
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 0.974
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 3.199
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 3.395
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.286
Epoch: 480/10000 | Epoch Time: 0.104 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 4.472
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.495
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.351
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 1.437
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 2.383
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 1.407
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.206
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 2.202
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.498
TRAINING: | Iteration [10/12] | Loss 0.04 | Norm 0.823
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 0.754
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.549
Epoch: 481/10000 | Epoch Time: 0.106 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.761
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.595
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 2.195
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.251
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 1.144
TRAINING: | Iteration [6/12] | Loss 0.24 | Norm 3.987
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 1.695
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.855
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 0.932
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 2.544
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.208
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 1.164
Epoch: 482/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 2.853
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 1.791
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.630
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.249
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.794
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.104
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 2.409
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 2.283
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 1.374
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 2.208
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 2.777
TRAINING: | Iteration [12/12] | Loss 0.04 | Norm 2.081
Epoch: 483/10000 | Epoch Time: 0.108 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 3.261
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 0.931
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.758
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.956
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 3.451
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.381
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 0.989
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 1.523
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 2.230
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 2.813
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 1.245
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.763
Epoch: 484/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.384
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.060
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.357
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.798
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.767
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 3.370
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 2.342
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.134
TRAINING: | Iteration [9/12] | Loss 0.04 | Norm 0.899
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.264
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 0.497
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.755
Epoch: 485/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.765
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 0.929
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.023
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.834
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 1.816
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 2.098
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.659
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.308
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.295
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 2.142
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.746
TRAINING: | Iteration [12/12] | Loss 0.19 | Norm 3.841
Epoch: 486/10000 | Epoch Time: 0.115 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 1.008
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.326
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.494
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.650
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 1.739
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.125
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 2.325
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 0.828
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.758
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.212
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.430
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 0.934
Epoch: 487/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.715
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.037
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 2.813
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 2.498
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 2.400
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 2.151
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.835
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.974
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.525
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.626
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 3.478
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.242
Epoch: 488/10000 | Epoch Time: 0.118 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 1.444
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 3.107
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 2.194
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.059
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.883
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.017
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 2.625
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.081
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 2.706
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.333
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 0.853
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 3.633
Epoch: 489/10000 | Epoch Time: 0.114 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.419
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 3.614
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.531
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 0.721
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 2.472
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 3.542
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 2.728
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.270
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.782
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 2.286
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 2.985
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 2.005
Epoch: 490/10000 | Epoch Time: 0.103 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.919
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.334
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.265
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.692
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.569
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.133
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.717
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.588
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 2.239
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 1.470
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.450
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.557
Epoch: 491/10000 | Epoch Time: 0.106 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.044
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.728
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 3.070
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.890
TRAINING: | Iteration [5/12] | Loss 0.15 | Norm 2.929
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 2.068
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 0.978
TRAINING: | Iteration [8/12] | Loss 0.04 | Norm 0.862
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 2.925
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 2.057
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 0.756
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 1.097
Epoch: 492/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.773
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.931
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 2.691
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 1.433
TRAINING: | Iteration [5/12] | Loss 0.04 | Norm 0.666
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 3.299
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 2.562
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.527
TRAINING: | Iteration [9/12] | Loss 0.04 | Norm 0.615
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.200
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.761
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.496
Epoch: 493/10000 | Epoch Time: 0.118 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 0.719
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 0.837
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.298
TRAINING: | Iteration [4/12] | Loss 0.04 | Norm 1.946
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.307
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.440
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.738
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 2.618
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 0.920
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.241
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.509
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.555
Epoch: 494/10000 | Epoch Time: 0.106 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.357
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.135
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.764
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.103
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.697
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 3.769
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 1.612
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.259
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.615
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.813
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.162
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 3.350
Epoch: 495/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 0.976
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.780
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.197
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.821
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 1.163
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 3.182
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.909
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 1.986
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.556
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.646
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.939
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 3.227
Epoch: 496/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.239
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 2.833
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.925
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 2.013
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 2.235
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 2.405
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.567
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.433
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 2.173
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 0.969
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 2.533
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 3.138
Epoch: 497/10000 | Epoch Time: 0.118 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.615
TRAINING: | Iteration [2/12] | Loss 0.19 | Norm 3.003
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.544
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 2.707
TRAINING: | Iteration [5/12] | Loss 0.17 | Norm 3.007
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 2.874
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 1.054
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 0.612
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.143
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 1.918
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 3.063
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.865
Epoch: 498/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.489
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 2.384
TRAINING: | Iteration [3/12] | Loss 0.17 | Norm 4.217
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.886
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 0.884
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.951
TRAINING: | Iteration [7/12] | Loss 0.13 | Norm 3.782
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 2.609
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.897
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 2.460
TRAINING: | Iteration [11/12] | Loss 0.20 | Norm 3.088
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.847
Epoch: 499/10000 | Epoch Time: 0.116 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 1.523
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 3.588
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.498
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.595
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.043
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 2.526
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.501
TRAINING: | Iteration [8/12] | Loss 0.04 | Norm 1.628
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 3.344
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.078
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.604
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 2.205
Epoch: 500/10000 | Epoch Time: 0.105 seconds
Saving Model
Preparation of Training Data time: 49.355 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.367
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 2.083
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.623
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.106
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 3.999
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 3.043
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 1.067
TRAINING: | Iteration [8/12] | Loss 0.04 | Norm 0.413
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.564
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.426
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 2.494
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 3.269
Epoch: 501/10000 | Epoch Time: 0.109 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 3.179
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.499
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.172
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 4.294
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.259
TRAINING: | Iteration [6/12] | Loss 0.04 | Norm 0.945
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 2.250
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 2.968
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.420
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.497
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 2.109
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 2.988
Epoch: 502/10000 | Epoch Time: 0.096 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 2.100
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.212
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 2.220
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 0.941
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 1.566
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.540
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.523
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 2.825
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 0.950
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 2.414
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 3.288
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.766
Epoch: 503/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.04 | Norm 0.788
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 2.074
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.463
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.403
TRAINING: | Iteration [5/12] | Loss 0.04 | Norm 1.219
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.511
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 2.268
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.530
TRAINING: | Iteration [9/12] | Loss 0.16 | Norm 3.012
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.787
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 1.355
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.314
Epoch: 504/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.201
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.321
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 4.031
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 1.099
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 1.830
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 1.662
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.441
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.566
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.077
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 0.811
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.954
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.024
Epoch: 505/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.14 | Norm 2.828
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 2.333
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.193
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 2.677
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 0.758
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 1.930
TRAINING: | Iteration [7/12] | Loss 0.14 | Norm 3.691
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 3.268
TRAINING: | Iteration [9/12] | Loss 0.16 | Norm 2.901
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 0.994
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 1.383
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.332
Epoch: 506/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.16 | Norm 3.030
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.912
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 0.992
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.253
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 1.640
TRAINING: | Iteration [6/12] | Loss 0.04 | Norm 0.494
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.588
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 1.338
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 0.776
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.545
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 1.886
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.367
Epoch: 507/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.368
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.093
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.342
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.512
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.842
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 2.581
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.339
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 3.251
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.767
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.662
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.293
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.713
Epoch: 508/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 2.671
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.686
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 3.811
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.210
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.975
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 1.005
TRAINING: | Iteration [7/12] | Loss 0.15 | Norm 3.390
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 2.244
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 2.673
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 2.232
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 2.024
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 2.208
Epoch: 509/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 1.663
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.698
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 0.973
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 1.820
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.306
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 3.067
TRAINING: | Iteration [7/12] | Loss 0.13 | Norm 3.637
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.048
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 2.168
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 3.136
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.384
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.511
Epoch: 510/10000 | Epoch Time: 0.092 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.026
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.950
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 2.116
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 3.245
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 0.773
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 2.728
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 3.329
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.855
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.629
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.154
TRAINING: | Iteration [11/12] | Loss 0.14 | Norm 2.527
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 2.276
Epoch: 511/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 1.399
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 2.184
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 2.145
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.518
TRAINING: | Iteration [5/12] | Loss 0.15 | Norm 2.554
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.582
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 2.284
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.774
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.575
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.495
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 0.976
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.059
Epoch: 512/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.190
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 3.093
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.988
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.943
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 1.761
TRAINING: | Iteration [6/12] | Loss 0.15 | Norm 2.557
TRAINING: | Iteration [7/12] | Loss 0.13 | Norm 4.552
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.859
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 2.583
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 2.408
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.793
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.447
Epoch: 513/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.359
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 2.076
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.245
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.993
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.233
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 3.466
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 1.499
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.430
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 2.629
TRAINING: | Iteration [10/12] | Loss 0.16 | Norm 3.746
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 2.138
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 2.352
Epoch: 514/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 2.047
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 3.766
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 1.737
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 2.998
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 0.740
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.311
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 1.327
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.902
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.762
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.437
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 2.779
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 3.133
Epoch: 515/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.04 | Norm 1.819
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 2.400
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 2.421
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 3.405
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 4.263
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.942
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 3.409
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.055
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 4.842
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.608
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.043
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.396
Epoch: 516/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 2.872
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 2.117
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 3.568
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 0.785
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 2.716
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 4.204
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 0.958
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.368
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 0.777
TRAINING: | Iteration [10/12] | Loss 0.15 | Norm 3.800
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 2.221
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 4.397
Epoch: 517/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.639
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 0.593
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 2.555
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 2.267
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 2.009
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.227
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.853
TRAINING: | Iteration [9/12] | Loss 0.14 | Norm 3.399
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 3.320
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 0.769
TRAINING: | Iteration [12/12] | Loss 0.19 | Norm 3.631
Epoch: 518/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 3.419
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 2.235
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.473
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 0.707
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 0.970
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.762
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 1.453
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 0.964
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.947
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 2.418
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.585
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 0.847
Epoch: 519/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 1.098
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.429
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.603
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.009
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.702
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.349
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.054
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.299
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 2.059
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.386
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.982
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.833
Epoch: 520/10000 | Epoch Time: 0.092 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.04 | Norm 0.365
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.797
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 0.998
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.678
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 2.326
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 2.091
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 0.973
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 2.179
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 3.714
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.763
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.371
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 3.698
Epoch: 521/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 2.043
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.336
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.449
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 1.654
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.602
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.357
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 2.837
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.492
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 2.418
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 1.129
TRAINING: | Iteration [11/12] | Loss 0.04 | Norm 0.722
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.603
Epoch: 522/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.699
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 1.041
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 1.645
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.604
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.676
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.965
TRAINING: | Iteration [7/12] | Loss 0.14 | Norm 2.747
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 1.150
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.604
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 2.508
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.920
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 3.844
Epoch: 523/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 1.508
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.723
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.704
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.435
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 2.419
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 1.511
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 0.966
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 2.318
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.299
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 1.109
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 3.195
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 2.916
Epoch: 524/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 1.582
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 3.177
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 3.035
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.722
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 2.863
TRAINING: | Iteration [6/12] | Loss 0.14 | Norm 3.208
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 2.897
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 4.991
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 5.000
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 4.125
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.937
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.194
Epoch: 525/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 5.000
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 4.896
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 3.569
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.873
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 2.377
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 3.312
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 3.630
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 4.566
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.464
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.137
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 1.425
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 3.766
Epoch: 526/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 2.558
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 2.059
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.550
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.451
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 2.251
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.851
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 3.067
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.446
TRAINING: | Iteration [9/12] | Loss 0.04 | Norm 0.882
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.585
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 2.300
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 2.999
Epoch: 527/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.977
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.712
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 3.100
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.158
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 2.656
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 4.030
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 2.199
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 2.673
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.721
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 0.666
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.716
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 2.338
Epoch: 528/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 1.355
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.755
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 1.957
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 3.149
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 3.963
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 3.440
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.410
TRAINING: | Iteration [8/12] | Loss 0.04 | Norm 0.660
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.328
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 4.372
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 2.067
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.739
Epoch: 529/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 1.415
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 1.104
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.428
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.538
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 2.687
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 3.080
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 3.193
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 3.517
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 1.262
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.411
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 3.601
TRAINING: | Iteration [12/12] | Loss 0.04 | Norm 1.224
Epoch: 530/10000 | Epoch Time: 0.092 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.461
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 0.873
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.410
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.762
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.857
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.351
TRAINING: | Iteration [7/12] | Loss 0.04 | Norm 1.045
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 4.259
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 3.541
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.043
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.509
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 3.150
Epoch: 531/10000 | Epoch Time: 0.095 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 3.549
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.903
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.058
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 0.435
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.280
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.261
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 3.581
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 2.114
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 1.561
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 3.068
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 3.316
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 3.214
Epoch: 532/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.695
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 4.291
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.656
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.412
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.547
TRAINING: | Iteration [6/12] | Loss 0.04 | Norm 0.940
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 2.208
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 0.803
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.936
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.483
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.192
TRAINING: | Iteration [12/12] | Loss 0.17 | Norm 2.980
Epoch: 533/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.369
TRAINING: | Iteration [2/12] | Loss 0.04 | Norm 0.625
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.975
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.299
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 1.286
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 0.647
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 0.856
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 1.328
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.355
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.479
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 0.719
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 0.992
Epoch: 534/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.860
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 2.279
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.416
TRAINING: | Iteration [4/12] | Loss 0.04 | Norm 1.383
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 2.443
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 2.521
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 1.029
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.651
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.466
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.662
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 1.745
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.476
Epoch: 535/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 2.493
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 0.599
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 0.963
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 2.345
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 1.123
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.737
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 2.241
TRAINING: | Iteration [8/12] | Loss 0.04 | Norm 0.744
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 2.624
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.185
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.582
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.188
Epoch: 536/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.668
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.459
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.561
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 3.204
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 4.553
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.818
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 2.490
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.578
TRAINING: | Iteration [9/12] | Loss 0.17 | Norm 4.021
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 0.857
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.466
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.126
Epoch: 537/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 0.850
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.477
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 1.413
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 1.981
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.695
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.499
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.947
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.141
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.479
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.894
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.600
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.176
Epoch: 538/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.881
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.445
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.536
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 2.433
TRAINING: | Iteration [5/12] | Loss 0.04 | Norm 0.474
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.456
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.971
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.031
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.614
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 0.534
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 2.844
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.443
Epoch: 539/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.761
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 2.678
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 1.680
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 2.813
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 1.148
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 1.046
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 1.515
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.425
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 0.705
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.807
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.463
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.335
Epoch: 540/10000 | Epoch Time: 0.092 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.528
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.450
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.665
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.380
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 2.555
TRAINING: | Iteration [6/12] | Loss 0.04 | Norm 1.106
TRAINING: | Iteration [7/12] | Loss 0.20 | Norm 3.175
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.680
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.203
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.685
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 0.815
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 3.258
Epoch: 541/10000 | Epoch Time: 0.096 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 2.439
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 0.776
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 2.777
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.478
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.554
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.743
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 3.156
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.093
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.925
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.975
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 1.129
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.528
Epoch: 542/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.303
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 0.776
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.529
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.115
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.274
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.299
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.337
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 3.508
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.466
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 1.571
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 3.121
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 3.766
Epoch: 543/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.486
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.127
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 3.453
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.984
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.167
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.834
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 2.280
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 2.012
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.750
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.630
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 2.600
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.731
Epoch: 544/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.233
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 5.000
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 2.396
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 0.640
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 2.435
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.965
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 2.200
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.201
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 2.166
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 2.203
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 2.956
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.669
Epoch: 545/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.946
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.387
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.732
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 0.746
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.564
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.662
TRAINING: | Iteration [7/12] | Loss 0.04 | Norm 1.089
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 1.638
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 2.852
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 2.443
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.487
TRAINING: | Iteration [12/12] | Loss 0.04 | Norm 1.060
Epoch: 546/10000 | Epoch Time: 0.095 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.960
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 2.146
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.121
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.744
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 2.465
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.597
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 0.773
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.803
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 2.464
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 1.298
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 1.390
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 1.338
Epoch: 547/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 2.121
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.227
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 2.205
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 2.225
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 1.776
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.192
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 0.780
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 1.239
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.039
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 0.564
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.433
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.489
Epoch: 548/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.092
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.057
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 1.517
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.692
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 1.182
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.840
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.373
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 0.602
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 1.921
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 3.279
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.955
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 3.082
Epoch: 549/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 1.782
TRAINING: | Iteration [2/12] | Loss 0.16 | Norm 2.714
TRAINING: | Iteration [3/12] | Loss 0.04 | Norm 0.650
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 0.816
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.316
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 0.996
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.340
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 0.814
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 0.842
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 2.856
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 2.316
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 3.127
Epoch: 550/10000 | Epoch Time: 0.093 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.04 | Norm 0.852
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.323
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 1.383
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 2.082
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.902
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.400
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 1.426
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 4.422
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 3.832
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 1.410
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.265
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.958
Epoch: 551/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.966
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.818
TRAINING: | Iteration [3/12] | Loss 0.04 | Norm 0.718
TRAINING: | Iteration [4/12] | Loss 0.04 | Norm 1.028
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.102
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 3.030
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 2.399
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.834
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.921
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 2.543
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 3.251
TRAINING: | Iteration [12/12] | Loss 0.23 | Norm 4.852
Epoch: 552/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 4.096
TRAINING: | Iteration [2/12] | Loss 0.14 | Norm 4.614
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 0.618
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 2.450
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.847
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 3.108
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.933
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 0.990
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.933
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.739
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 2.598
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.655
Epoch: 553/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.594
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.091
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.061
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 3.010
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 0.595
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.106
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.473
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 0.875
TRAINING: | Iteration [9/12] | Loss 0.04 | Norm 0.829
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.280
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.499
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 3.739
Epoch: 554/10000 | Epoch Time: 0.117 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.454
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 0.687
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.024
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 4.900
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.322
TRAINING: | Iteration [6/12] | Loss 0.04 | Norm 0.704
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 3.209
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.947
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.300
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.603
TRAINING: | Iteration [11/12] | Loss 0.15 | Norm 3.138
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 0.971
Epoch: 555/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.705
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.938
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.917
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.730
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 1.055
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 2.734
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 2.844
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.792
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 2.835
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.055
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 3.051
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 2.121
Epoch: 556/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.18 | Norm 3.985
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.109
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.152
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 3.063
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.822
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.833
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.466
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.497
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.681
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 2.411
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 2.033
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 1.254
Epoch: 557/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 3.102
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.834
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 2.297
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.803
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.303
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.455
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 1.204
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 2.649
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.510
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.706
TRAINING: | Iteration [11/12] | Loss 0.19 | Norm 2.919
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.062
Epoch: 558/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.950
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 2.514
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 2.116
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.764
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.344
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 1.329
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.420
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 5.000
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.596
TRAINING: | Iteration [10/12] | Loss 0.15 | Norm 3.371
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.353
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 2.993
Epoch: 559/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.469
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 1.541
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 0.952
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.121
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 0.902
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 2.081
TRAINING: | Iteration [7/12] | Loss 0.04 | Norm 1.021
TRAINING: | Iteration [8/12] | Loss 0.04 | Norm 0.899
TRAINING: | Iteration [9/12] | Loss 0.03 | Norm 0.766
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 3.558
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 0.931
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 2.924
Epoch: 560/10000 | Epoch Time: 0.115 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.974
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 3.416
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.712
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 1.967
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 3.936
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 3.963
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 3.916
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.312
TRAINING: | Iteration [9/12] | Loss 0.15 | Norm 2.611
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.700
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 2.490
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 2.507
Epoch: 561/10000 | Epoch Time: 0.117 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 2.819
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.471
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 3.116
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 2.487
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.527
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.262
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.121
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.700
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.479
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 2.459
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.783
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 0.680
Epoch: 562/10000 | Epoch Time: 0.115 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.202
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 2.433
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.345
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.112
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.459
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 1.520
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 2.303
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 0.629
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 0.783
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.659
TRAINING: | Iteration [11/12] | Loss 0.14 | Norm 4.861
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 4.405
Epoch: 563/10000 | Epoch Time: 0.116 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.582
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 2.036
TRAINING: | Iteration [3/12] | Loss 0.20 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 5.000
TRAINING: | Iteration [5/12] | Loss 0.16 | Norm 5.000
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 3.244
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 1.636
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 3.419
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 3.163
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 5.000
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 2.783
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.658
Epoch: 564/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 3.004
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 3.787
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.392
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.178
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 2.198
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 2.600
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 0.609
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.602
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.892
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 1.448
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 3.274
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.989
Epoch: 565/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.681
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.177
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 3.045
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.154
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.802
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.076
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.691
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 2.054
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.921
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.634
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 1.807
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 2.572
Epoch: 566/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.767
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.255
TRAINING: | Iteration [3/12] | Loss 0.16 | Norm 3.275
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 2.222
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.125
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.821
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 2.225
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.474
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 2.248
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.354
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.366
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.835
Epoch: 567/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.252
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 1.725
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.380
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 2.403
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.884
TRAINING: | Iteration [6/12] | Loss 0.04 | Norm 0.877
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 3.494
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.874
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 2.928
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.264
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 3.084
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 3.406
Epoch: 568/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.040
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.960
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 4.268
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.416
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 3.386
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.139
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.711
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 2.965
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 2.064
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.564
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 2.622
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 2.874
Epoch: 569/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.04 | Norm 0.839
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.884
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.901
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 2.741
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 2.640
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 2.961
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 0.867
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 3.536
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 2.987
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 2.076
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 2.317
TRAINING: | Iteration [12/12] | Loss 0.04 | Norm 0.924
Epoch: 570/10000 | Epoch Time: 0.105 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 2.985
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.640
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.673
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 1.182
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.131
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.275
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 2.153
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.957
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 0.980
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.759
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.209
TRAINING: | Iteration [12/12] | Loss 0.15 | Norm 3.439
Epoch: 571/10000 | Epoch Time: 0.165 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 1.286
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 1.963
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 2.492
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 2.638
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 1.102
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 1.440
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.309
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.914
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 2.395
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.134
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 0.728
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.925
Epoch: 572/10000 | Epoch Time: 0.158 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 1.823
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.475
TRAINING: | Iteration [3/12] | Loss 0.04 | Norm 0.758
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.432
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.963
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 3.017
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.981
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 1.289
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 3.334
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.248
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.275
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 2.174
Epoch: 573/10000 | Epoch Time: 0.106 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 3.165
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 3.407
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.900
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 1.515
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.496
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 0.996
TRAINING: | Iteration [7/12] | Loss 0.21 | Norm 4.160
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.529
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.517
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.484
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 2.621
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 3.746
Epoch: 574/10000 | Epoch Time: 0.106 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 2.490
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 2.550
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.721
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 1.566
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.697
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 1.075
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 2.017
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.374
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.243
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.586
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 0.821
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 3.141
Epoch: 575/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.18 | Norm 3.176
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.611
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.460
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.294
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.353
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.622
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.490
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 3.131
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 1.215
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.369
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 2.970
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 3.626
Epoch: 576/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.555
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 5.000
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.108
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.536
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 3.955
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 3.480
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 3.200
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.615
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 3.018
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 3.066
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 3.015
TRAINING: | Iteration [12/12] | Loss 0.15 | Norm 5.000
Epoch: 577/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 1.565
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 3.242
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 3.418
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 5.000
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 4.236
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.225
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.819
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 2.466
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 5.000
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 5.000
TRAINING: | Iteration [11/12] | Loss 0.29 | Norm 4.761
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 2.880
Epoch: 578/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.972
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.599
TRAINING: | Iteration [3/12] | Loss 0.14 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 4.019
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.271
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.242
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.048
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 2.168
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.543
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.530
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 2.294
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.866
Epoch: 579/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 1.783
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 2.344
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 2.205
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.597
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 2.223
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 1.944
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 1.472
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.810
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.815
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 2.003
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.514
TRAINING: | Iteration [12/12] | Loss 0.16 | Norm 5.000
Epoch: 580/10000 | Epoch Time: 0.104 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 0.937
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 2.030
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 0.892
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 3.171
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.801
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 2.138
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.257
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.371
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.684
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 1.060
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 3.567
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 1.659
Epoch: 581/10000 | Epoch Time: 0.108 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.675
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.589
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 0.678
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.261
TRAINING: | Iteration [5/12] | Loss 0.04 | Norm 1.305
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.432
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 1.131
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 2.342
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 2.325
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 3.388
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 3.227
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 2.538
Epoch: 582/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.867
TRAINING: | Iteration [2/12] | Loss 0.04 | Norm 0.440
TRAINING: | Iteration [3/12] | Loss 0.04 | Norm 0.657
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 1.089
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.071
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.846
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.824
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.232
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.709
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 2.466
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.246
TRAINING: | Iteration [12/12] | Loss 0.04 | Norm 0.964
Epoch: 583/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 1.772
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 1.049
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.702
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 0.665
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.756
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.963
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.955
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 1.276
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.685
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.718
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 1.036
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.956
Epoch: 584/10000 | Epoch Time: 0.106 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 3.830
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 0.909
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.418
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 0.743
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 1.786
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 3.437
TRAINING: | Iteration [7/12] | Loss 0.13 | Norm 2.536
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.044
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 0.949
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.658
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 2.037
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 2.006
Epoch: 585/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 1.939
TRAINING: | Iteration [2/12] | Loss 0.04 | Norm 1.283
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 2.187
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.174
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.350
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.543
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.622
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.740
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 1.801
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 2.605
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 0.488
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 1.221
Epoch: 586/10000 | Epoch Time: 0.121 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.535
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 1.906
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.461
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 1.474
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.546
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.505
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 2.734
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.900
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.602
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.547
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 1.218
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.712
Epoch: 587/10000 | Epoch Time: 0.171 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 0.584
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.618
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 2.419
TRAINING: | Iteration [4/12] | Loss 0.04 | Norm 0.711
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.035
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.129
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 2.845
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.577
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 0.997
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.267
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 4.787
TRAINING: | Iteration [12/12] | Loss 0.20 | Norm 4.585
Epoch: 588/10000 | Epoch Time: 0.118 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 0.865
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.330
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.821
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 3.076
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 4.018
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 3.405
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.778
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.563
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 2.312
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 3.507
TRAINING: | Iteration [11/12] | Loss 0.16 | Norm 3.540
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 2.689
Epoch: 589/10000 | Epoch Time: 0.119 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 2.905
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 1.903
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 2.353
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 0.586
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.046
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.583
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 2.491
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.656
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.098
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 1.945
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.254
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 3.396
Epoch: 590/10000 | Epoch Time: 0.102 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 1.048
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 1.016
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 2.097
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 1.624
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 1.299
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 2.336
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.350
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.628
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.721
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 1.725
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.882
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.648
Epoch: 591/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.358
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.674
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 1.895
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 1.854
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.581
TRAINING: | Iteration [6/12] | Loss 0.04 | Norm 0.961
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.267
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 0.701
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.899
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.082
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 1.693
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 2.337
Epoch: 592/10000 | Epoch Time: 0.106 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 0.847
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 2.072
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.258
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 2.605
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 2.467
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.540
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.257
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 0.836
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.919
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.211
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 2.094
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 4.048
Epoch: 593/10000 | Epoch Time: 0.119 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 0.951
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.444
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.349
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.789
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 1.227
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.265
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.708
TRAINING: | Iteration [8/12] | Loss 0.04 | Norm 1.602
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 2.675
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 1.928
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 2.149
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.691
Epoch: 594/10000 | Epoch Time: 0.106 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.276
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 1.396
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.258
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 1.329
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 0.822
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.003
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.537
TRAINING: | Iteration [8/12] | Loss 0.17 | Norm 2.990
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.984
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.010
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 3.240
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.698
Epoch: 595/10000 | Epoch Time: 0.119 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 0.932
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.709
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.416
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 2.267
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.485
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.080
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.531
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 3.066
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 2.515
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.584
TRAINING: | Iteration [11/12] | Loss 0.20 | Norm 3.911
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 1.971
Epoch: 596/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.04 | Norm 1.439
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 2.076
TRAINING: | Iteration [3/12] | Loss 0.04 | Norm 1.242
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 2.237
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.707
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 0.508
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 2.241
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.454
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 3.315
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 1.795
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 1.481
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.753
Epoch: 597/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 3.776
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.458
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.030
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.363
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 2.370
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.603
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.670
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.480
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.022
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.555
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.354
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 1.182
Epoch: 598/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.20 | Norm 3.408
TRAINING: | Iteration [2/12] | Loss 0.04 | Norm 1.120
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.871
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 1.994
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 2.496
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.694
TRAINING: | Iteration [7/12] | Loss 0.04 | Norm 0.579
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 2.140
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.776
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.795
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 3.315
TRAINING: | Iteration [12/12] | Loss 0.04 | Norm 1.613
Epoch: 599/10000 | Epoch Time: 0.105 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 2.565
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.806
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.731
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 3.006
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.388
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 3.038
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.849
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.418
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 2.919
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 1.245
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 1.008
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.753
Epoch: 600/10000 | Epoch Time: 0.106 seconds
Saving Model
Preparation of Training Data time: 24.943 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 3.110
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.732
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 1.902
TRAINING: | Iteration [4/12] | Loss 0.04 | Norm 1.605
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 2.339
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 3.283
TRAINING: | Iteration [7/12] | Loss 0.04 | Norm 1.208
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 1.564
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.787
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.905
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.146
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 1.006
Epoch: 601/10000 | Epoch Time: 0.114 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 1.272
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 2.784
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.718
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.518
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 1.025
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 1.104
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 1.244
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.945
TRAINING: | Iteration [9/12] | Loss 0.04 | Norm 0.910
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.032
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 2.360
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.749
Epoch: 602/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.438
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.861
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.592
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.858
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.917
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.544
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.068
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 3.603
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.409
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.603
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.145
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 1.019
Epoch: 603/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.120
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 0.931
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 2.077
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.458
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.836
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 2.098
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.795
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.511
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 2.300
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 0.713
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.294
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 3.282
Epoch: 604/10000 | Epoch Time: 0.115 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 1.432
TRAINING: | Iteration [2/12] | Loss 0.04 | Norm 0.898
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 1.179
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 2.015
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.939
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 2.021
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 2.186
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.592
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.820
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.091
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 0.983
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 2.539
Epoch: 605/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.04 | Norm 0.744
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 3.265
TRAINING: | Iteration [3/12] | Loss 0.04 | Norm 0.864
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.539
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.959
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.477
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.603
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.721
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 2.655
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.256
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.747
TRAINING: | Iteration [12/12] | Loss 0.17 | Norm 3.787
Epoch: 606/10000 | Epoch Time: 0.116 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.511
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 2.317
TRAINING: | Iteration [3/12] | Loss 0.15 | Norm 3.163
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.195
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.359
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.584
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 2.727
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.229
TRAINING: | Iteration [9/12] | Loss 0.21 | Norm 3.454
TRAINING: | Iteration [10/12] | Loss 0.04 | Norm 0.694
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 2.132
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.478
Epoch: 607/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 0.689
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.293
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 1.658
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.843
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.347
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.202
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 1.162
TRAINING: | Iteration [8/12] | Loss 0.04 | Norm 1.281
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 2.345
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.627
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 1.313
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.720
Epoch: 608/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 1.199
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 0.866
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 0.693
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.275
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 2.566
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 1.562
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.084
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 1.295
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.718
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.638
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 0.887
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 3.468
Epoch: 609/10000 | Epoch Time: 0.099 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 0.684
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.778
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 2.573
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 2.255
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 2.277
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 0.995
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 2.803
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 2.395
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.839
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 1.159
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 1.024
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.657
Epoch: 610/10000 | Epoch Time: 0.116 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 2.563
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 2.925
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.582
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.532
TRAINING: | Iteration [5/12] | Loss 0.04 | Norm 1.140
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.897
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 2.149
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.418
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 0.947
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.061
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.385
TRAINING: | Iteration [12/12] | Loss 0.04 | Norm 1.014
Epoch: 611/10000 | Epoch Time: 0.105 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.906
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 2.074
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.928
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 2.216
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 2.517
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.861
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 1.414
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.683
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 2.597
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 2.013
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 2.567
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 1.860
Epoch: 612/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.04 | Norm 0.968
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 0.729
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.491
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 1.489
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.546
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.774
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.479
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.903
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 1.248
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.178
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.050
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.745
Epoch: 613/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 0.913
TRAINING: | Iteration [2/12] | Loss 0.04 | Norm 0.734
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.232
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.593
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.310
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 2.350
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.182
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.794
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.617
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.105
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.234
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 2.774
Epoch: 614/10000 | Epoch Time: 0.105 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 1.090
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.309
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.229
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.788
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.174
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.813
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.938
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 2.571
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 2.401
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.634
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.943
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.804
Epoch: 615/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.927
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 3.508
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.807
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 2.237
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 2.501
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 3.350
TRAINING: | Iteration [7/12] | Loss 0.15 | Norm 3.616
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 0.610
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 2.345
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 1.179
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.198
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.666
Epoch: 616/10000 | Epoch Time: 0.100 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 2.765
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 2.029
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 0.935
TRAINING: | Iteration [4/12] | Loss 0.04 | Norm 0.714
TRAINING: | Iteration [5/12] | Loss 0.15 | Norm 2.548
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.828
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.490
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.735
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.719
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 0.953
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.413
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 0.820
Epoch: 617/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.719
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.361
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 2.618
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.128
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 2.680
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.239
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 0.935
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.023
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.852
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.990
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.646
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.929
Epoch: 618/10000 | Epoch Time: 0.106 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 3.197
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 0.802
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 0.963
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 2.245
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.674
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 3.639
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.309
TRAINING: | Iteration [8/12] | Loss 0.04 | Norm 1.352
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 0.619
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 4.258
TRAINING: | Iteration [11/12] | Loss 0.14 | Norm 2.692
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.464
Epoch: 619/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.321
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 2.184
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 0.675
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.498
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.382
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 1.225
TRAINING: | Iteration [7/12] | Loss 0.14 | Norm 3.081
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.473
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 1.390
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 2.331
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.198
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.449
Epoch: 620/10000 | Epoch Time: 0.117 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.672
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 1.951
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 3.231
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.140
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.118
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 1.242
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 2.611
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.722
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 2.093
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.240
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 1.540
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 1.987
Epoch: 621/10000 | Epoch Time: 0.119 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.469
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 2.575
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 2.477
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.708
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 2.705
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.469
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.801
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 2.981
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.918
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 3.647
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 1.209
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.139
Epoch: 622/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.690
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 1.723
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 2.219
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 1.902
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 1.763
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.740
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 2.049
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.594
TRAINING: | Iteration [9/12] | Loss 0.15 | Norm 3.897
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 0.880
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.222
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.936
Epoch: 623/10000 | Epoch Time: 0.115 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 4.069
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.638
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 3.632
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.719
TRAINING: | Iteration [5/12] | Loss 0.15 | Norm 2.993
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 2.501
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 4.637
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.257
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.464
TRAINING: | Iteration [10/12] | Loss 0.16 | Norm 3.757
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 2.524
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 2.157
Epoch: 624/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.19 | Norm 5.000
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.712
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 2.460
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.200
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.637
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 4.568
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.265
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.526
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.561
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.853
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 1.402
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.636
Epoch: 625/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 0.746
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 0.705
TRAINING: | Iteration [3/12] | Loss 0.04 | Norm 1.029
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.527
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.446
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 1.157
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.617
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 1.768
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 1.193
TRAINING: | Iteration [10/12] | Loss 0.20 | Norm 4.725
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.423
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 2.507
Epoch: 626/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 3.783
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 1.210
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.173
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.723
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 0.884
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.678
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 1.466
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.427
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 0.848
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 2.301
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 2.386
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 3.205
Epoch: 627/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 2.383
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 3.229
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 3.997
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 3.528
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.145
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 3.940
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.144
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.028
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 2.641
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.124
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.412
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 1.517
Epoch: 628/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 1.721
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.452
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 1.129
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.824
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.924
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.047
TRAINING: | Iteration [7/12] | Loss 0.14 | Norm 3.267
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.621
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 2.905
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.643
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 1.798
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 1.086
Epoch: 629/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 1.077
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 0.472
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 1.220
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 2.826
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 1.356
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 1.655
TRAINING: | Iteration [7/12] | Loss 0.15 | Norm 3.483
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 2.699
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.003
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.357
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 2.374
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 2.797
Epoch: 630/10000 | Epoch Time: 0.103 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 3.097
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.676
TRAINING: | Iteration [3/12] | Loss 0.15 | Norm 3.041
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.606
TRAINING: | Iteration [5/12] | Loss 0.20 | Norm 3.678
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 2.115
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.350
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.179
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 1.655
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.666
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 2.217
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 1.296
Epoch: 631/10000 | Epoch Time: 0.097 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.634
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.742
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 3.752
TRAINING: | Iteration [4/12] | Loss 0.04 | Norm 1.263
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.757
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.525
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 1.891
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.973
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 4.677
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 3.291
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.939
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 4.625
Epoch: 632/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.18 | Norm 4.190
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 4.037
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 0.602
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.847
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 3.931
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 3.703
TRAINING: | Iteration [7/12] | Loss 0.13 | Norm 2.554
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.260
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.254
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.846
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 2.620
TRAINING: | Iteration [12/12] | Loss 0.15 | Norm 3.142
Epoch: 633/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 1.894
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.136
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 2.074
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.073
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 0.687
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 1.783
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.728
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.210
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 1.025
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.489
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 2.897
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.252
Epoch: 634/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.04 | Norm 0.531
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 2.161
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 3.242
TRAINING: | Iteration [4/12] | Loss 0.15 | Norm 2.652
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.894
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.660
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.768
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 2.247
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 2.301
TRAINING: | Iteration [10/12] | Loss 0.22 | Norm 3.174
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.246
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 2.064
Epoch: 635/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.799
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.896
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.713
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.838
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.664
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.672
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 2.046
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 0.941
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 2.222
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 0.963
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 2.278
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 3.249
Epoch: 636/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 0.964
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 0.871
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 1.683
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.480
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 2.259
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.305
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 2.542
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 4.160
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 3.394
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 3.587
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 1.552
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 1.844
Epoch: 637/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 2.468
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 4.020
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 2.342
TRAINING: | Iteration [4/12] | Loss 0.14 | Norm 3.005
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 1.345
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 3.753
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 2.580
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 2.491
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.009
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 1.736
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.591
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.141
Epoch: 638/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.14 | Norm 3.632
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.910
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.430
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.547
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 2.031
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.389
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.400
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 2.370
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.402
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.816
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 2.379
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.489
Epoch: 639/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 1.063
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.511
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.056
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 0.894
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.666
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.671
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 0.625
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.815
TRAINING: | Iteration [9/12] | Loss 0.18 | Norm 3.137
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 1.202
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.592
TRAINING: | Iteration [12/12] | Loss 0.04 | Norm 1.243
Epoch: 640/10000 | Epoch Time: 0.093 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 0.710
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 0.860
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.312
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 1.106
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.498
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 0.656
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.702
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.676
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.029
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.853
TRAINING: | Iteration [11/12] | Loss 0.15 | Norm 2.712
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 0.959
Epoch: 641/10000 | Epoch Time: 0.095 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.902
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.300
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.445
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.489
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.287
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 0.904
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.826
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.266
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.384
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 1.584
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 2.690
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 1.163
Epoch: 642/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.04 | Norm 0.565
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 1.208
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 2.706
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 1.090
TRAINING: | Iteration [5/12] | Loss 0.17 | Norm 3.291
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.258
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 0.861
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 2.222
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 2.081
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.092
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 1.483
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 2.970
Epoch: 643/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 0.965
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 1.185
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 1.298
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 2.541
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.103
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.135
TRAINING: | Iteration [7/12] | Loss 0.13 | Norm 3.090
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 0.774
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.823
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.421
TRAINING: | Iteration [11/12] | Loss 0.23 | Norm 3.743
TRAINING: | Iteration [12/12] | Loss 0.16 | Norm 4.131
Epoch: 644/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.685
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 2.007
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.991
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.185
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.699
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.528
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 2.089
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.461
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 2.905
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.909
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 2.455
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.828
Epoch: 645/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.700
TRAINING: | Iteration [2/12] | Loss 0.16 | Norm 2.979
TRAINING: | Iteration [3/12] | Loss 0.16 | Norm 3.586
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 3.410
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 1.094
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.613
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 0.913
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 3.249
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.891
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.553
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 2.060
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 1.455
Epoch: 646/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 2.321
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.731
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 2.624
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 2.174
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 2.214
TRAINING: | Iteration [6/12] | Loss 0.04 | Norm 0.990
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.132
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 2.931
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 3.820
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 2.764
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.505
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 2.071
Epoch: 647/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 3.833
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 1.397
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.171
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 1.156
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 1.721
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.671
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.471
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.953
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 2.189
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.537
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 3.265
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 4.151
Epoch: 648/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.411
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 2.618
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.975
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 3.357
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.659
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.107
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 1.083
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 3.032
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 4.784
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.144
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 0.568
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.057
Epoch: 649/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.358
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 3.458
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 1.400
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.473
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 2.068
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.481
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.740
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.959
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 2.495
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.584
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 0.556
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.083
Epoch: 650/10000 | Epoch Time: 0.093 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 2.304
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.774
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 0.768
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.131
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.864
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.679
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.361
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.115
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 2.244
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 2.772
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 2.255
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 3.039
Epoch: 651/10000 | Epoch Time: 0.095 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.905
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.962
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.758
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 2.614
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 2.040
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.534
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 2.569
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.846
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.941
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.471
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 0.787
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.479
Epoch: 652/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.635
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.350
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 0.915
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 1.929
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.404
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.539
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.328
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 2.257
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 3.078
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.604
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.653
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.470
Epoch: 653/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.636
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 0.826
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.790
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.300
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.892
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.679
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.462
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.131
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.091
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.876
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.449
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 0.756
Epoch: 654/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.449
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 2.728
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.655
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 0.997
TRAINING: | Iteration [5/12] | Loss 0.19 | Norm 3.206
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.441
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.459
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 2.469
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.872
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.746
TRAINING: | Iteration [11/12] | Loss 0.29 | Norm 5.000
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 1.257
Epoch: 655/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 2.411
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.624
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 1.189
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.700
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 2.696
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 0.920
TRAINING: | Iteration [7/12] | Loss 0.13 | Norm 2.849
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.782
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 0.962
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 3.090
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 2.476
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 3.444
Epoch: 656/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 2.085
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 2.434
TRAINING: | Iteration [3/12] | Loss 0.18 | Norm 3.322
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 3.243
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 1.119
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.579
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 3.076
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 0.954
TRAINING: | Iteration [9/12] | Loss 0.18 | Norm 4.472
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.051
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 1.804
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 1.404
Epoch: 657/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 0.839
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 1.992
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 2.723
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.705
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 2.426
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.771
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.650
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.413
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.458
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 0.891
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 3.288
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 0.854
Epoch: 658/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 2.316
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.461
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.692
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.639
TRAINING: | Iteration [5/12] | Loss 0.14 | Norm 2.225
TRAINING: | Iteration [6/12] | Loss 0.15 | Norm 2.595
TRAINING: | Iteration [7/12] | Loss 0.17 | Norm 4.070
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 1.039
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 1.371
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.255
TRAINING: | Iteration [11/12] | Loss 0.04 | Norm 1.037
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.785
Epoch: 659/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 1.585
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.402
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.901
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.919
TRAINING: | Iteration [5/12] | Loss 0.04 | Norm 1.321
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.021
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 0.828
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 0.865
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 0.926
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 2.150
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.654
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.841
Epoch: 660/10000 | Epoch Time: 0.094 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.420
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.971
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.223
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.385
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.605
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.382
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.299
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 2.692
TRAINING: | Iteration [9/12] | Loss 0.04 | Norm 0.888
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 0.489
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 0.918
TRAINING: | Iteration [12/12] | Loss 0.04 | Norm 1.037
Epoch: 661/10000 | Epoch Time: 0.095 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.150
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.929
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.499
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 0.736
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.527
TRAINING: | Iteration [6/12] | Loss 0.14 | Norm 2.479
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 1.109
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 2.141
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.298
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 2.504
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.718
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.698
Epoch: 662/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 1.289
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 3.146
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 2.303
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.904
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.413
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.947
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.984
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.556
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 2.156
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 4.121
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.688
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 1.677
Epoch: 663/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.04 | Norm 0.679
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.901
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.741
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 2.135
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.406
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.988
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 0.899
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.470
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.185
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.488
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.517
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.334
Epoch: 664/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.04 | Norm 0.828
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.128
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.161
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.361
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.930
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.627
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 2.150
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 0.868
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.920
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.235
TRAINING: | Iteration [11/12] | Loss 0.04 | Norm 0.679
TRAINING: | Iteration [12/12] | Loss 0.15 | Norm 2.689
Epoch: 665/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.344
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.488
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.808
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.209
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.540
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.879
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.174
TRAINING: | Iteration [8/12] | Loss 0.04 | Norm 0.953
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 2.202
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 0.725
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 2.449
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.464
Epoch: 666/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.482
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 2.274
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 3.463
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.964
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.550
TRAINING: | Iteration [6/12] | Loss 0.14 | Norm 3.016
TRAINING: | Iteration [7/12] | Loss 0.04 | Norm 2.034
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 2.145
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 2.155
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.797
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 0.847
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 2.499
Epoch: 667/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.025
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.497
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 0.898
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.420
TRAINING: | Iteration [5/12] | Loss 0.16 | Norm 3.795
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 3.009
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 0.859
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.125
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.156
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 0.630
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.483
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 3.092
Epoch: 668/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.553
TRAINING: | Iteration [2/12] | Loss 0.04 | Norm 1.416
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.230
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 0.809
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.545
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 0.917
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.099
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.220
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.430
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.126
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.463
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 0.993
Epoch: 669/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 2.028
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 2.152
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.991
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.207
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 2.404
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 1.683
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 0.869
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.670
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.296
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.514
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.763
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 1.841
Epoch: 670/10000 | Epoch Time: 0.094 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 0.827
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.963
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.601
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.362
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 0.519
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.541
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 2.278
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 0.683
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 0.779
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 2.528
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.311
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.962
Epoch: 671/10000 | Epoch Time: 0.095 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 1.062
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.060
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 2.520
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.929
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.335
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 1.917
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.867
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 2.666
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 0.689
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 1.222
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.380
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 1.158
Epoch: 672/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.138
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 0.949
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.420
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.764
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.455
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 1.391
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.240
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.944
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.442
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 0.749
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.330
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.532
Epoch: 673/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 3.399
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.351
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.638
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 0.935
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.558
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 1.231
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.068
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.762
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 0.871
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.706
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.032
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.545
Epoch: 674/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 0.988
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.616
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 0.946
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.054
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.215
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 2.087
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 0.610
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.763
TRAINING: | Iteration [9/12] | Loss 0.04 | Norm 0.725
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.589
TRAINING: | Iteration [11/12] | Loss 0.27 | Norm 3.916
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.986
Epoch: 675/10000 | Epoch Time: 0.096 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 3.087
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 3.030
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.651
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.378
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 1.759
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 2.174
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.405
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.263
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.052
TRAINING: | Iteration [10/12] | Loss 0.18 | Norm 2.867
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 2.933
TRAINING: | Iteration [12/12] | Loss 0.15 | Norm 4.324
Epoch: 676/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.276
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.403
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 2.001
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.737
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 2.784
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.324
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.535
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 1.067
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 2.203
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 3.427
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 5.000
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 3.761
Epoch: 677/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 0.529
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 4.967
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 3.443
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 3.859
TRAINING: | Iteration [5/12] | Loss 0.14 | Norm 3.026
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 2.887
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 4.173
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.568
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 4.369
TRAINING: | Iteration [10/12] | Loss 0.17 | Norm 3.450
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.488
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 3.441
Epoch: 678/10000 | Epoch Time: 0.097 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.896
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 2.814
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.933
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.558
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.810
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.999
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.689
TRAINING: | Iteration [8/12] | Loss 0.16 | Norm 3.374
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.707
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.533
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.024
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.292
Epoch: 679/10000 | Epoch Time: 0.108 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.549
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 2.475
TRAINING: | Iteration [3/12] | Loss 0.19 | Norm 3.660
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 1.836
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.710
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.510
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.194
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.512
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.105
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.316
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.903
TRAINING: | Iteration [12/12] | Loss 0.16 | Norm 3.212
Epoch: 680/10000 | Epoch Time: 0.108 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 3.136
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.949
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 2.358
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.713
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.202
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 3.058
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 3.073
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 0.958
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 2.136
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.854
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.130
TRAINING: | Iteration [12/12] | Loss 0.16 | Norm 3.599
Epoch: 681/10000 | Epoch Time: 0.096 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.670
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 2.385
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.111
TRAINING: | Iteration [4/12] | Loss 0.16 | Norm 4.297
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 2.343
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.722
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.232
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 2.785
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 1.426
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.489
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 1.985
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 2.995
Epoch: 682/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.275
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 0.674
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 2.603
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.906
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.233
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.796
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 2.115
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 1.446
TRAINING: | Iteration [9/12] | Loss 0.04 | Norm 0.961
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 1.088
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.931
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.654
Epoch: 683/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 4.194
TRAINING: | Iteration [2/12] | Loss 0.14 | Norm 3.788
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.545
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 2.136
TRAINING: | Iteration [5/12] | Loss 0.16 | Norm 2.749
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 2.259
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.536
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 2.955
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 1.055
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.707
TRAINING: | Iteration [11/12] | Loss 0.27 | Norm 4.002
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.991
Epoch: 684/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.012
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.747
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 2.800
TRAINING: | Iteration [4/12] | Loss 0.04 | Norm 0.834
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.904
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.678
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.434
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.477
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.800
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.759
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.105
TRAINING: | Iteration [12/12] | Loss 0.24 | Norm 4.316
Epoch: 685/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.15 | Norm 4.025
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 2.432
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.468
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 2.041
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 2.218
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 3.099
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 0.587
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 1.784
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.486
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.592
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.808
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.924
Epoch: 686/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 0.940
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 2.597
TRAINING: | Iteration [3/12] | Loss 0.17 | Norm 3.727
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.320
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.404
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.360
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 2.031
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 1.020
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.291
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 2.699
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 1.936
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.937
Epoch: 687/10000 | Epoch Time: 0.096 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.175
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 1.413
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.327
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 1.020
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.466
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.799
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.677
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.045
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 2.774
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.651
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 0.863
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 2.921
Epoch: 688/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 2.560
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.684
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.074
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.493
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 3.587
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 2.946
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 3.246
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.579
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 3.360
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 1.023
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.869
TRAINING: | Iteration [12/12] | Loss 0.21 | Norm 3.658
Epoch: 689/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.740
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.535
TRAINING: | Iteration [3/12] | Loss 0.20 | Norm 3.899
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 0.853
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.448
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 0.696
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.225
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.147
TRAINING: | Iteration [9/12] | Loss 0.15 | Norm 3.151
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.167
TRAINING: | Iteration [11/12] | Loss 0.19 | Norm 3.242
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.511
Epoch: 690/10000 | Epoch Time: 0.093 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 3.067
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 3.024
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 0.686
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 2.059
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.259
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.257
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.068
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 2.364
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.494
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.710
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 3.207
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.523
Epoch: 691/10000 | Epoch Time: 0.095 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.337
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 2.446
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 3.219
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.805
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.127
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.528
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 2.218
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.077
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 3.066
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 0.888
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 0.809
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 4.184
Epoch: 692/10000 | Epoch Time: 0.095 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 3.434
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.020
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 0.853
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.431
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 3.355
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 3.954
TRAINING: | Iteration [7/12] | Loss 0.04 | Norm 2.107
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 3.389
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 1.030
TRAINING: | Iteration [10/12] | Loss 0.21 | Norm 4.342
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 2.147
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.535
Epoch: 693/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.761
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 3.308
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.985
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 4.239
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 2.235
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.842
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 3.674
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.594
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.578
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.998
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.382
TRAINING: | Iteration [12/12] | Loss 0.15 | Norm 3.997
Epoch: 694/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.231
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 0.977
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.104
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 2.920
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 2.300
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 3.474
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.091
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 2.919
TRAINING: | Iteration [9/12] | Loss 0.04 | Norm 0.895
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.886
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.996
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.522
Epoch: 695/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 0.883
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 2.167
TRAINING: | Iteration [3/12] | Loss 0.15 | Norm 3.096
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 2.513
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.402
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 0.647
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.129
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.673
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.137
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 1.670
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.409
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.352
Epoch: 696/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.368
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.683
TRAINING: | Iteration [3/12] | Loss 0.26 | Norm 3.692
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 2.807
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.924
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.530
TRAINING: | Iteration [7/12] | Loss 0.18 | Norm 2.978
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.072
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 3.803
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.426
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.176
TRAINING: | Iteration [12/12] | Loss 0.04 | Norm 1.227
Epoch: 697/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 1.644
TRAINING: | Iteration [2/12] | Loss 0.14 | Norm 2.764
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.330
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.836
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 1.224
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.481
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.346
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.375
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.233
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.056
TRAINING: | Iteration [11/12] | Loss 0.15 | Norm 2.896
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 4.098
Epoch: 698/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.039
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 3.263
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.996
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 2.298
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 3.957
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.092
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.002
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.888
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 2.149
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.339
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 0.990
TRAINING: | Iteration [12/12] | Loss 0.04 | Norm 1.559
Epoch: 699/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 2.227
TRAINING: | Iteration [2/12] | Loss 0.04 | Norm 0.544
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 1.628
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.890
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 1.034
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.741
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 3.167
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 2.472
TRAINING: | Iteration [9/12] | Loss 0.04 | Norm 0.852
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 3.182
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.044
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.924
Epoch: 700/10000 | Epoch Time: 0.093 seconds
Saving Model
Preparation of Training Data time: 19.293 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.408
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.578
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 2.677
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.216
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.615
TRAINING: | Iteration [6/12] | Loss 0.14 | Norm 3.272
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 2.420
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 0.897
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 0.942
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 0.975
TRAINING: | Iteration [11/12] | Loss 0.18 | Norm 2.968
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 3.466
Epoch: 701/10000 | Epoch Time: 0.115 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 0.851
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.004
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.018
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 2.113
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 2.256
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 2.342
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 2.133
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.401
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.402
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.247
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 2.457
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.314
Epoch: 702/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.577
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.469
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.142
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 3.159
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 2.094
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 1.737
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.815
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.471
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 3.175
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 2.913
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.416
TRAINING: | Iteration [12/12] | Loss 0.17 | Norm 3.518
Epoch: 703/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 2.181
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 2.335
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 2.414
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.525
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 1.944
TRAINING: | Iteration [6/12] | Loss 0.15 | Norm 2.519
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 3.409
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.442
TRAINING: | Iteration [9/12] | Loss 0.28 | Norm 4.267
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.325
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.446
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 1.545
Epoch: 704/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 3.981
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 2.526
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 1.479
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.930
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 2.910
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.918
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 2.017
TRAINING: | Iteration [8/12] | Loss 0.18 | Norm 3.722
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.943
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 3.067
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 2.813
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 1.554
Epoch: 705/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.18 | Norm 3.161
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.670
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.265
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.697
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.965
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 0.890
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.914
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 2.691
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.377
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 0.866
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.861
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.115
Epoch: 706/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 3.927
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.932
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 1.588
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.972
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.779
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.213
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.950
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.004
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.702
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 3.549
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.472
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 2.242
Epoch: 707/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.008
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.400
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.197
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 3.470
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.190
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.449
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.453
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 1.120
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 0.868
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 3.068
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.803
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.148
Epoch: 708/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.780
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.220
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 1.758
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.633
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.050
TRAINING: | Iteration [6/12] | Loss 0.04 | Norm 1.143
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 2.965
TRAINING: | Iteration [8/12] | Loss 0.04 | Norm 1.573
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.808
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.030
TRAINING: | Iteration [11/12] | Loss 0.20 | Norm 3.259
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.167
Epoch: 709/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.627
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.814
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.191
TRAINING: | Iteration [4/12] | Loss 0.25 | Norm 4.082
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.120
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.182
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 2.590
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 2.120
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.801
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.622
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 2.518
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 2.901
Epoch: 710/10000 | Epoch Time: 0.093 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.093
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.178
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.238
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.584
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 2.680
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.578
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.807
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 2.326
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 0.707
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 0.813
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.611
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 2.634
Epoch: 711/10000 | Epoch Time: 0.098 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.557
TRAINING: | Iteration [2/12] | Loss 0.16 | Norm 3.019
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 2.335
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.365
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.680
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.753
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.904
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 2.165
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 3.334
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 4.065
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 3.527
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 3.884
Epoch: 712/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 0.429
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.142
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.748
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.207
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.631
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 2.286
TRAINING: | Iteration [7/12] | Loss 0.21 | Norm 4.081
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.521
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 2.530
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 1.661
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.787
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 4.261
Epoch: 713/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.786
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 2.130
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 1.253
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 2.197
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.651
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 2.671
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 0.887
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.770
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.777
TRAINING: | Iteration [10/12] | Loss 0.04 | Norm 0.997
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 3.729
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 3.564
Epoch: 714/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.053
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.712
TRAINING: | Iteration [3/12] | Loss 0.14 | Norm 4.930
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.810
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.091
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.747
TRAINING: | Iteration [7/12] | Loss 0.13 | Norm 2.998
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.109
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 1.111
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.010
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 2.870
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.721
Epoch: 715/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 1.331
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.434
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 2.639
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.604
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 1.648
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.624
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 2.638
TRAINING: | Iteration [8/12] | Loss 0.04 | Norm 1.500
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.751
TRAINING: | Iteration [10/12] | Loss 0.24 | Norm 4.221
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.242
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.479
Epoch: 716/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.270
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.765
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.735
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 0.852
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 2.988
TRAINING: | Iteration [6/12] | Loss 0.04 | Norm 1.435
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 2.150
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.170
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 1.268
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 2.339
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.627
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.828
Epoch: 717/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 2.622
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.297
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.608
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 2.258
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.368
TRAINING: | Iteration [6/12] | Loss 0.15 | Norm 3.098
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.006
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.545
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.031
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 3.372
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 2.048
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.959
Epoch: 718/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 1.118
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 3.437
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 3.907
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 0.608
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 0.907
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 3.419
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 2.389
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 2.633
TRAINING: | Iteration [9/12] | Loss 0.24 | Norm 3.416
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 2.849
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 2.876
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.208
Epoch: 719/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 2.638
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.546
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.109
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.762
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 2.491
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.097
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.102
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 3.087
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 2.039
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.421
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.101
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.078
Epoch: 720/10000 | Epoch Time: 0.094 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.838
TRAINING: | Iteration [2/12] | Loss 0.04 | Norm 1.139
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.858
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 2.791
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.646
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 1.397
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 1.072
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.923
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.727
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.711
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.670
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.301
Epoch: 721/10000 | Epoch Time: 0.097 seconds
TRAINING: | Iteration [1/12] | Loss 0.14 | Norm 2.391
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 0.263
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.694
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 0.746
TRAINING: | Iteration [5/12] | Loss 0.14 | Norm 2.871
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 1.000
TRAINING: | Iteration [7/12] | Loss 0.04 | Norm 0.687
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.364
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.915
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.451
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 1.057
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.312
Epoch: 722/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 3.115
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.810
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.636
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.520
TRAINING: | Iteration [5/12] | Loss 0.14 | Norm 2.424
TRAINING: | Iteration [6/12] | Loss 0.24 | Norm 4.198
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.211
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.693
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 1.387
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.946
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.346
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 1.032
Epoch: 723/10000 | Epoch Time: 0.096 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.530
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 1.266
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.822
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.148
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.552
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.437
TRAINING: | Iteration [7/12] | Loss 0.14 | Norm 3.150
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.478
TRAINING: | Iteration [9/12] | Loss 0.04 | Norm 1.610
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 2.008
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.034
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 2.372
Epoch: 724/10000 | Epoch Time: 0.095 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.335
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 2.199
TRAINING: | Iteration [3/12] | Loss 0.17 | Norm 3.835
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.565
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.446
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 2.427
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 1.211
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.570
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.868
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.336
TRAINING: | Iteration [11/12] | Loss 0.16 | Norm 3.001
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.908
Epoch: 725/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 3.309
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 3.826
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.861
TRAINING: | Iteration [4/12] | Loss 0.17 | Norm 3.279
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.725
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.200
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.665
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.213
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 2.159
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 1.846
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 1.128
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 3.317
Epoch: 726/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.811
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.674
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.264
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 1.546
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.532
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.656
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.159
TRAINING: | Iteration [8/12] | Loss 0.04 | Norm 1.097
TRAINING: | Iteration [9/12] | Loss 0.19 | Norm 3.214
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 1.751
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 3.999
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 2.327
Epoch: 727/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 1.731
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 3.286
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.253
TRAINING: | Iteration [4/12] | Loss 0.04 | Norm 1.713
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 2.545
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 0.618
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 3.105
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.928
TRAINING: | Iteration [9/12] | Loss 0.04 | Norm 0.478
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.967
TRAINING: | Iteration [11/12] | Loss 0.16 | Norm 3.371
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.804
Epoch: 728/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.14 | Norm 3.638
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.959
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.675
TRAINING: | Iteration [4/12] | Loss 0.15 | Norm 2.748
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.876
TRAINING: | Iteration [6/12] | Loss 0.04 | Norm 2.403
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 1.082
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.432
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.041
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.801
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.704
TRAINING: | Iteration [12/12] | Loss 0.04 | Norm 0.629
Epoch: 729/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.203
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 3.047
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.756
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 0.531
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.114
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.873
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 1.792
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 2.199
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 0.845
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 2.152
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.264
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.871
Epoch: 730/10000 | Epoch Time: 0.094 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.716
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 3.571
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.941
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.626
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 3.847
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 2.303
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.791
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.494
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 2.858
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.922
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.890
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.791
Epoch: 731/10000 | Epoch Time: 0.095 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.013
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 1.346
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.384
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 3.152
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 1.260
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.547
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.865
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.763
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 3.112
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.277
TRAINING: | Iteration [11/12] | Loss 0.14 | Norm 2.646
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 1.329
Epoch: 732/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.270
TRAINING: | Iteration [2/12] | Loss 0.16 | Norm 3.371
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.229
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.062
TRAINING: | Iteration [5/12] | Loss 0.14 | Norm 2.962
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 2.311
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 2.210
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.613
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.326
TRAINING: | Iteration [10/12] | Loss 0.04 | Norm 0.833
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 2.110
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 2.101
Epoch: 733/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.717
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 0.963
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.278
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 2.343
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 0.748
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.428
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.247
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.939
TRAINING: | Iteration [9/12] | Loss 0.15 | Norm 3.457
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.134
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 0.946
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 2.301
Epoch: 734/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.240
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.128
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 3.902
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 0.960
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.351
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.871
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 4.028
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 3.325
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.435
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.918
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.568
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 2.482
Epoch: 735/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.379
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.472
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.844
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 3.129
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 2.489
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 3.027
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 3.276
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.782
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 2.056
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 3.039
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.750
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.188
Epoch: 736/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.661
TRAINING: | Iteration [2/12] | Loss 0.14 | Norm 2.539
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.453
TRAINING: | Iteration [5/12] | Loss 0.14 | Norm 4.085
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 2.709
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.420
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.891
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 2.368
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.348
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 2.078
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 3.240
Epoch: 737/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 2.442
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 3.266
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.061
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 2.617
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.721
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.148
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 3.388
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 2.771
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.354
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 2.327
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.917
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.534
Epoch: 738/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.085
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 0.646
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.344
TRAINING: | Iteration [4/12] | Loss 0.04 | Norm 1.503
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.569
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.643
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.505
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.066
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.472
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 2.265
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 0.920
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.533
Epoch: 739/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.936
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.248
TRAINING: | Iteration [3/12] | Loss 0.15 | Norm 3.275
TRAINING: | Iteration [4/12] | Loss 0.04 | Norm 1.014
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 0.882
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.470
TRAINING: | Iteration [7/12] | Loss 0.04 | Norm 0.599
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 0.915
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.072
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.333
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 1.933
TRAINING: | Iteration [12/12] | Loss 0.18 | Norm 3.526
Epoch: 740/10000 | Epoch Time: 0.094 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.259
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.771
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.438
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.298
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.098
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.118
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 2.643
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.036
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 2.366
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 1.451
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 2.681
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.969
Epoch: 741/10000 | Epoch Time: 0.099 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.743
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.610
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 1.945
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 4.463
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 2.411
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 1.374
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 2.812
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 2.609
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 4.111
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 3.258
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 1.988
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.295
Epoch: 742/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.522
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.176
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.957
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.241
TRAINING: | Iteration [5/12] | Loss 0.14 | Norm 3.620
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 3.016
TRAINING: | Iteration [7/12] | Loss 0.18 | Norm 4.781
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 3.011
TRAINING: | Iteration [9/12] | Loss 0.24 | Norm 3.994
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 1.039
TRAINING: | Iteration [11/12] | Loss 0.31 | Norm 4.311
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.515
Epoch: 743/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 0.974
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.578
TRAINING: | Iteration [3/12] | Loss 0.04 | Norm 1.125
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 0.747
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 1.525
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.363
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.013
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.795
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.424
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.395
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.077
TRAINING: | Iteration [12/12] | Loss 0.28 | Norm 4.451
Epoch: 744/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 1.966
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.814
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.149
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 1.928
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.231
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 3.103
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.214
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.234
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.737
TRAINING: | Iteration [10/12] | Loss 0.04 | Norm 0.854
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 2.781
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.961
Epoch: 745/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.098
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 3.215
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.364
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.698
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 1.639
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.350
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.546
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 1.460
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.313
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.579
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.526
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.822
Epoch: 746/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.516
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.588
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 2.483
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.447
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 2.282
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.690
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.960
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 1.804
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.610
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 2.738
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 2.818
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 0.627
Epoch: 747/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.379
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.112
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 3.254
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 0.681
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 2.569
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.290
TRAINING: | Iteration [7/12] | Loss 0.14 | Norm 3.128
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 0.843
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.621
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.749
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 4.725
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 2.484
Epoch: 748/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.126
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.510
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.209
TRAINING: | Iteration [4/12] | Loss 0.17 | Norm 3.487
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.652
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 4.031
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.833
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 3.348
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 3.520
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 3.694
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 2.258
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 3.418
Epoch: 749/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.531
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 2.303
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.936
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.203
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.877
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 3.225
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.964
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 3.184
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 1.387
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 0.770
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.661
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.510
Epoch: 750/10000 | Epoch Time: 0.094 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 3.240
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 2.667
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.034
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.505
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 3.284
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.868
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 1.761
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.126
TRAINING: | Iteration [9/12] | Loss 0.15 | Norm 3.481
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 2.682
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.560
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.742
Epoch: 751/10000 | Epoch Time: 0.096 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.354
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.376
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.320
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.723
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.670
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 2.446
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 2.604
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.149
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.352
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.208
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.175
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.785
Epoch: 752/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.209
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.535
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.780
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 0.705
TRAINING: | Iteration [5/12] | Loss 0.14 | Norm 3.598
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 0.999
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 0.808
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.398
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.457
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 1.041
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.668
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 2.549
Epoch: 753/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.18 | Norm 4.118
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.996
TRAINING: | Iteration [3/12] | Loss 0.04 | Norm 0.638
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.134
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 3.491
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.840
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 1.988
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 1.451
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 2.211
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 2.131
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 3.009
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 2.211
Epoch: 754/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 0.809
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.438
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.836
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.255
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 2.131
TRAINING: | Iteration [6/12] | Loss 0.19 | Norm 4.491
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.392
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 2.624
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.180
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 0.938
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 2.086
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.080
Epoch: 755/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 2.395
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.576
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.248
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 3.733
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.214
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 2.923
TRAINING: | Iteration [7/12] | Loss 0.17 | Norm 3.954
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 3.412
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 2.739
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.380
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 2.291
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 0.984
Epoch: 756/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 1.749
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 1.006
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.691
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 2.302
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 0.921
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.310
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 2.083
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.168
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 3.999
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.244
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.641
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 1.272
Epoch: 757/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 2.687
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.117
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.228
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 2.740
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 1.313
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 1.804
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.589
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 3.606
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.561
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.837
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 2.012
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.961
Epoch: 758/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.634
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.829
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 2.102
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.898
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 0.879
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 2.476
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 0.790
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.420
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 0.912
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 0.771
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.465
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.880
Epoch: 759/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 2.083
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.344
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 0.717
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.390
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.057
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.961
TRAINING: | Iteration [7/12] | Loss 0.14 | Norm 2.704
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 3.935
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 0.995
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.902
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.408
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.509
Epoch: 760/10000 | Epoch Time: 0.094 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.674
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 2.794
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 3.089
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.135
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 1.244
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.072
TRAINING: | Iteration [7/12] | Loss 0.13 | Norm 3.583
TRAINING: | Iteration [8/12] | Loss 0.16 | Norm 3.230
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.578
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.580
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.473
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 0.896
Epoch: 761/10000 | Epoch Time: 0.098 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 1.610
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.489
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.162
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.597
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 1.506
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.523
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 0.937
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.340
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 1.828
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.931
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.285
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 3.305
Epoch: 762/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.285
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.564
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 1.196
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 2.442
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.820
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 2.851
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.375
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 2.378
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 2.270
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 3.812
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 3.153
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 0.996
Epoch: 763/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.23 | Norm 4.448
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.180
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 2.526
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 3.281
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 4.294
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.367
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 4.142
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 4.523
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.428
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.684
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 1.692
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.873
Epoch: 764/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 3.539
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.901
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 2.411
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 2.091
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 0.713
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 0.983
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 3.039
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.202
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.886
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 3.298
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.904
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.770
Epoch: 765/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 0.789
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 3.162
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 3.817
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.242
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 2.351
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.572
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 2.810
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.575
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.355
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.691
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.493
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 0.733
Epoch: 766/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.330
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.777
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.956
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.530
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 3.027
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 4.173
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 2.614
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.790
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 2.085
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 2.913
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.525
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.357
Epoch: 767/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.411
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.487
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.853
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.158
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.946
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 1.745
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 2.215
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 3.605
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.555
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 2.251
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.088
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.380
Epoch: 768/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.14 | Norm 5.000
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 3.088
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.954
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 0.704
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 2.393
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 5.000
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 3.603
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 3.138
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 2.071
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 2.610
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 2.800
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 3.355
Epoch: 769/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 3.587
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 5.000
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 3.689
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.358
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.422
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 3.404
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 5.000
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 3.200
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.983
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 1.458
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.490
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 4.210
Epoch: 770/10000 | Epoch Time: 0.094 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 3.611
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.393
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 0.989
TRAINING: | Iteration [4/12] | Loss 0.14 | Norm 2.525
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.206
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 3.036
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.249
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.845
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.276
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.740
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 3.573
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 3.540
Epoch: 771/10000 | Epoch Time: 0.096 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 3.689
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 0.985
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 1.652
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.377
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.376
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 3.083
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 2.433
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 3.004
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 2.254
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 3.571
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 3.539
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.930
Epoch: 772/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 3.251
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 3.210
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.723
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 4.378
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 2.735
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.146
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 5.000
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.112
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 1.828
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 3.779
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.079
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.343
Epoch: 773/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.096
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 3.729
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.682
TRAINING: | Iteration [4/12] | Loss 0.15 | Norm 4.032
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 4.941
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 3.199
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.982
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.273
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 3.459
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 3.842
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 2.186
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.839
Epoch: 774/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 0.561
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 3.594
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 4.466
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.961
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.393
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 1.474
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.880
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 4.255
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 2.927
TRAINING: | Iteration [10/12] | Loss 0.04 | Norm 0.654
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 3.152
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.540
Epoch: 775/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 0.980
TRAINING: | Iteration [2/12] | Loss 0.16 | Norm 5.000
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 2.195
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 3.470
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 3.186
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 4.901
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 3.501
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 3.253
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 3.086
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 3.307
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 3.324
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.834
Epoch: 776/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 1.685
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 1.530
TRAINING: | Iteration [3/12] | Loss 0.17 | Norm 2.988
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.292
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 0.966
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 0.624
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 1.058
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.877
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 0.750
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.703
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.248
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.177
Epoch: 777/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.142
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 2.516
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.102
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.833
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.702
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 4.158
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 2.677
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.782
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.106
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.324
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 3.199
TRAINING: | Iteration [12/12] | Loss 0.16 | Norm 2.714
Epoch: 778/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.829
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 2.132
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 3.688
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.988
TRAINING: | Iteration [5/12] | Loss 0.19 | Norm 5.000
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 3.510
TRAINING: | Iteration [7/12] | Loss 0.13 | Norm 2.875
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 2.633
TRAINING: | Iteration [9/12] | Loss 0.15 | Norm 5.000
TRAINING: | Iteration [10/12] | Loss 0.16 | Norm 5.000
TRAINING: | Iteration [11/12] | Loss 0.18 | Norm 4.448
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 1.102
Epoch: 779/10000 | Epoch Time: 0.095 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.118
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 2.587
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 3.321
TRAINING: | Iteration [4/12] | Loss 0.14 | Norm 4.033
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.532
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.352
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 2.353
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 4.950
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 1.041
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 3.294
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.460
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 1.723
Epoch: 780/10000 | Epoch Time: 0.094 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 3.019
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 3.225
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.021
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 3.147
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 3.002
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.151
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 2.033
TRAINING: | Iteration [8/12] | Loss 0.23 | Norm 4.505
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 1.385
TRAINING: | Iteration [10/12] | Loss 0.16 | Norm 2.757
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.319
TRAINING: | Iteration [12/12] | Loss 0.16 | Norm 3.514
Epoch: 781/10000 | Epoch Time: 0.098 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 3.527
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.822
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.284
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.626
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.505
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 2.271
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.711
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.460
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.990
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 2.075
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.763
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 1.656
Epoch: 782/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.620
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.040
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 2.374
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 3.146
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.693
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.339
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.842
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.662
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.479
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 2.145
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 2.542
TRAINING: | Iteration [12/12] | Loss 0.15 | Norm 3.108
Epoch: 783/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 1.554
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 0.936
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 1.075
TRAINING: | Iteration [4/12] | Loss 0.14 | Norm 3.722
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.471
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.364
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 1.619
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.775
TRAINING: | Iteration [9/12] | Loss 0.04 | Norm 0.779
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 2.695
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.305
TRAINING: | Iteration [12/12] | Loss 0.16 | Norm 2.922
Epoch: 784/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.755
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.845
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 2.189
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.289
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.111
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.440
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 0.819
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.317
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.067
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 1.512
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.753
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.778
Epoch: 785/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.081
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.182
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.776
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.294
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.697
TRAINING: | Iteration [6/12] | Loss 0.15 | Norm 2.801
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.297
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 0.690
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 3.024
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.710
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 0.863
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 3.706
Epoch: 786/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.855
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.624
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.542
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.613
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.722
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.728
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 1.891
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.864
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 2.512
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.552
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 0.963
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.019
Epoch: 787/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 2.736
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.281
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 3.299
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 0.919
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.082
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 0.881
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 1.721
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.711
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 0.443
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.651
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.801
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 3.035
Epoch: 788/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.750
TRAINING: | Iteration [2/12] | Loss 0.04 | Norm 0.560
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 0.986
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.429
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 1.185
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.361
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 1.904
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.610
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.369
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 1.112
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 0.662
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 3.270
Epoch: 789/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.616
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 0.984
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 2.240
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.564
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.832
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 2.441
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.923
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.726
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.883
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.297
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.176
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 1.182
Epoch: 790/10000 | Epoch Time: 0.094 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.342
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.169
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 0.921
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 0.925
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.856
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.224
TRAINING: | Iteration [7/12] | Loss 0.04 | Norm 1.574
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.194
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 1.747
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.232
TRAINING: | Iteration [11/12] | Loss 0.14 | Norm 2.827
TRAINING: | Iteration [12/12] | Loss 0.16 | Norm 2.975
Epoch: 791/10000 | Epoch Time: 0.095 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 1.888
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 0.878
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 2.086
TRAINING: | Iteration [4/12] | Loss 0.17 | Norm 2.904
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.899
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.573
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 0.998
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 0.930
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 0.787
TRAINING: | Iteration [10/12] | Loss 0.15 | Norm 3.274
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 0.907
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 1.445
Epoch: 792/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 0.622
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 3.110
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.297
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.035
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.914
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 3.298
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 2.055
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.840
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 1.906
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 4.251
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 2.294
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 0.937
Epoch: 793/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.332
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 2.428
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.685
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.386
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.559
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.144
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.915
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 2.468
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 2.441
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.749
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 1.850
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 1.283
Epoch: 794/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 2.508
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 1.765
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.956
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.656
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.890
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.366
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.726
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 0.935
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 2.773
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.459
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 0.779
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 2.488
Epoch: 795/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 2.689
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 4.664
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.666
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 3.077
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.399
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.256
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 3.043
TRAINING: | Iteration [8/12] | Loss 0.21 | Norm 3.999
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.249
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.387
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.022
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.904
Epoch: 796/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.873
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.434
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 2.871
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.980
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.962
TRAINING: | Iteration [6/12] | Loss 0.15 | Norm 2.753
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.550
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.584
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 0.882
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 2.301
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 2.507
TRAINING: | Iteration [12/12] | Loss 0.16 | Norm 3.209
Epoch: 797/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.349
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 0.806
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 4.236
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 2.525
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 3.502
TRAINING: | Iteration [6/12] | Loss 0.15 | Norm 3.782
TRAINING: | Iteration [7/12] | Loss 0.23 | Norm 3.867
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.744
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.487
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 3.162
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.609
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 2.410
Epoch: 798/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.557
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.501
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 3.667
TRAINING: | Iteration [4/12] | Loss 0.16 | Norm 2.915
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 3.217
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 0.511
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.738
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.300
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 1.912
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 3.543
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.398
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 2.507
Epoch: 799/10000 | Epoch Time: 0.119 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.814
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 0.782
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 2.171
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.190
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 3.182
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.298
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.926
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.712
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 2.903
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.883
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.228
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.253
Epoch: 800/10000 | Epoch Time: 0.103 seconds
Saving Model
Preparation of Training Data time: 51.332 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.988
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.743
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 2.175
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 3.272
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 2.880
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 2.966
TRAINING: | Iteration [7/12] | Loss 0.04 | Norm 1.025
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.320
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 2.326
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 1.578
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 3.636
TRAINING: | Iteration [12/12] | Loss 0.20 | Norm 4.426
Epoch: 801/10000 | Epoch Time: 0.117 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.940
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.839
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.764
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.955
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 3.135
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 0.747
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.035
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.185
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 2.469
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.782
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.031
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 1.251
Epoch: 802/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.446
TRAINING: | Iteration [2/12] | Loss 0.15 | Norm 3.255
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 2.709
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.137
TRAINING: | Iteration [5/12] | Loss 0.19 | Norm 3.146
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 3.132
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.470
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 3.423
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.876
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 1.312
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.091
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 1.957
Epoch: 803/10000 | Epoch Time: 0.116 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.755
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 0.965
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.547
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.273
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.795
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.423
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.903
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.334
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 2.810
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.653
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 0.936
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.374
Epoch: 804/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.04 | Norm 0.564
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.808
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.663
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 2.979
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.850
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.371
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 2.575
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.538
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 0.812
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.402
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.508
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 1.368
Epoch: 805/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 0.741
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 1.059
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.583
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.984
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 2.420
TRAINING: | Iteration [6/12] | Loss 0.17 | Norm 3.068
TRAINING: | Iteration [7/12] | Loss 0.04 | Norm 1.852
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.298
TRAINING: | Iteration [9/12] | Loss 0.26 | Norm 4.245
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 4.038
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.399
TRAINING: | Iteration [12/12] | Loss 0.15 | Norm 2.436
Epoch: 806/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 2.837
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 2.440
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.589
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 1.294
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.300
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 1.623
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.061
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 2.635
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 1.221
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 2.464
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.862
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.068
Epoch: 807/10000 | Epoch Time: 0.116 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.778
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.856
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 1.425
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.563
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 1.933
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.001
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 3.589
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.086
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 1.564
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 2.485
TRAINING: | Iteration [11/12] | Loss 0.04 | Norm 0.408
TRAINING: | Iteration [12/12] | Loss 0.26 | Norm 4.544
Epoch: 808/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 2.776
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.765
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 3.085
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.141
TRAINING: | Iteration [5/12] | Loss 0.14 | Norm 2.788
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.531
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 0.840
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.650
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.547
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.280
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.278
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.293
Epoch: 809/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.242
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 2.173
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.149
TRAINING: | Iteration [4/12] | Loss 0.14 | Norm 3.350
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 2.470
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.445
TRAINING: | Iteration [7/12] | Loss 0.22 | Norm 5.000
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.444
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 0.907
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 2.613
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.076
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.790
Epoch: 810/10000 | Epoch Time: 0.101 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.999
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 1.150
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.585
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 1.815
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 1.871
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.107
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.395
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.513
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 2.525
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 2.549
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.209
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 1.541
Epoch: 811/10000 | Epoch Time: 0.106 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.669
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.244
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.558
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 1.351
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 2.386
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.512
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.690
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.359
TRAINING: | Iteration [9/12] | Loss 0.17 | Norm 3.122
TRAINING: | Iteration [10/12] | Loss 0.17 | Norm 2.736
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 2.562
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 4.005
Epoch: 812/10000 | Epoch Time: 0.119 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 2.185
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.139
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.949
TRAINING: | Iteration [4/12] | Loss 0.14 | Norm 3.614
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.345
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 1.598
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 3.830
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 4.195
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 2.126
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 3.106
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 2.180
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.802
Epoch: 813/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 2.907
TRAINING: | Iteration [2/12] | Loss 0.14 | Norm 5.000
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.660
TRAINING: | Iteration [4/12] | Loss 0.17 | Norm 3.411
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.607
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.310
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.083
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 3.093
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.043
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 0.752
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 3.046
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.504
Epoch: 814/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 0.917
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 0.881
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 2.385
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.788
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.643
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 4.527
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 3.257
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.068
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 2.415
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.684
TRAINING: | Iteration [11/12] | Loss 0.15 | Norm 2.917
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 3.160
Epoch: 815/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.337
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.386
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 2.254
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 3.782
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.897
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 3.198
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.059
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.185
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 2.916
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.599
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.752
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 3.140
Epoch: 816/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.473
TRAINING: | Iteration [2/12] | Loss 0.14 | Norm 2.756
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 3.320
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 0.929
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.415
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 0.557
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.911
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.914
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 4.112
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.447
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.875
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 3.419
Epoch: 817/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.907
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.548
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.393
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.005
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 0.840
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.456
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 2.851
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.544
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 0.651
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.270
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 2.333
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 2.740
Epoch: 818/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.940
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.922
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 3.052
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 1.003
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.683
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.323
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 2.067
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 2.584
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 0.506
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 0.937
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 3.512
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 0.659
Epoch: 819/10000 | Epoch Time: 0.105 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.551
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.741
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.791
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 0.796
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.209
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.901
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.175
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 0.905
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 2.195
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 0.759
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.716
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 1.938
Epoch: 820/10000 | Epoch Time: 0.101 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.000
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 0.915
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.058
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 2.310
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 1.730
TRAINING: | Iteration [6/12] | Loss 0.22 | Norm 3.691
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 2.788
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.783
TRAINING: | Iteration [9/12] | Loss 0.20 | Norm 3.600
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 3.740
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 0.731
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.492
Epoch: 821/10000 | Epoch Time: 0.105 seconds
TRAINING: | Iteration [1/12] | Loss 0.14 | Norm 2.350
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.552
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 2.725
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 1.839
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.258
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 2.379
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 2.452
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.717
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.731
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.077
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 0.930
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 1.297
Epoch: 822/10000 | Epoch Time: 0.116 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.151
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.806
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.937
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.312
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.523
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.862
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 0.973
TRAINING: | Iteration [8/12] | Loss 0.04 | Norm 0.692
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 2.763
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.664
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.057
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.834
Epoch: 823/10000 | Epoch Time: 0.119 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.514
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 1.226
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.018
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.092
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.442
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 2.411
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 2.541
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.921
TRAINING: | Iteration [9/12] | Loss 0.15 | Norm 3.111
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.806
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 2.644
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 1.894
Epoch: 824/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.296
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.205
TRAINING: | Iteration [3/12] | Loss 0.14 | Norm 2.748
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.720
TRAINING: | Iteration [5/12] | Loss 0.15 | Norm 3.059
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.952
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.797
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.792
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.558
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.506
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.616
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.716
Epoch: 825/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.687
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 2.744
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 0.757
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.753
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.290
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 2.533
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.394
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.074
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 0.405
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 2.738
TRAINING: | Iteration [11/12] | Loss 0.14 | Norm 4.365
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.549
Epoch: 826/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.336
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 0.533
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 1.970
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.028
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 3.314
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.071
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 0.700
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.784
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.949
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.730
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 1.657
TRAINING: | Iteration [12/12] | Loss 0.30 | Norm 4.285
Epoch: 827/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.094
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 2.885
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 2.466
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.509
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 2.537
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 0.712
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 2.228
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.484
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 0.792
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 2.829
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.435
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 2.299
Epoch: 828/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 2.640
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 2.437
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.692
TRAINING: | Iteration [4/12] | Loss 0.21 | Norm 3.468
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 0.945
TRAINING: | Iteration [6/12] | Loss 0.14 | Norm 2.983
TRAINING: | Iteration [7/12] | Loss 0.16 | Norm 2.981
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.097
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.830
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.554
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.060
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 2.462
Epoch: 829/10000 | Epoch Time: 0.105 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.671
TRAINING: | Iteration [2/12] | Loss 0.14 | Norm 4.509
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.372
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.517
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.725
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.586
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.726
TRAINING: | Iteration [8/12] | Loss 0.17 | Norm 3.005
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 2.336
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.056
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 3.241
TRAINING: | Iteration [12/12] | Loss 0.18 | Norm 4.184
Epoch: 830/10000 | Epoch Time: 0.101 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 3.249
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.898
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 3.815
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 3.658
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.674
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.849
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 2.496
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 3.665
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 2.369
TRAINING: | Iteration [10/12] | Loss 0.17 | Norm 3.735
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 2.048
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.223
Epoch: 831/10000 | Epoch Time: 0.106 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.916
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 2.732
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 4.107
TRAINING: | Iteration [4/12] | Loss 0.15 | Norm 3.837
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 3.179
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.654
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 2.655
TRAINING: | Iteration [8/12] | Loss 0.21 | Norm 4.186
TRAINING: | Iteration [9/12] | Loss 0.16 | Norm 3.239
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.631
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.550
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.774
Epoch: 832/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 2.449
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.089
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.566
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 1.924
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.534
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.865
TRAINING: | Iteration [7/12] | Loss 0.15 | Norm 2.831
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.129
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 4.077
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 3.902
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.653
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.683
Epoch: 833/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.943
TRAINING: | Iteration [2/12] | Loss 0.20 | Norm 4.094
TRAINING: | Iteration [3/12] | Loss 0.20 | Norm 3.131
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.233
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.383
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.568
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.818
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.915
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.102
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 2.610
TRAINING: | Iteration [11/12] | Loss 0.14 | Norm 2.990
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 3.567
Epoch: 834/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.692
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.437
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.722
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.106
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 2.522
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.505
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.525
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.850
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.228
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.772
TRAINING: | Iteration [11/12] | Loss 0.16 | Norm 4.141
TRAINING: | Iteration [12/12] | Loss 0.23 | Norm 4.178
Epoch: 835/10000 | Epoch Time: 0.120 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 2.006
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.027
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.546
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 4.432
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 2.443
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.540
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.828
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 2.322
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.745
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.780
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.713
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 2.433
Epoch: 836/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 0.931
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.181
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 3.313
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.072
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.593
TRAINING: | Iteration [6/12] | Loss 0.23 | Norm 4.821
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 4.575
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.411
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 2.554
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.604
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 2.515
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.519
Epoch: 837/10000 | Epoch Time: 0.105 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 2.119
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.744
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 0.647
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 0.865
TRAINING: | Iteration [5/12] | Loss 0.14 | Norm 3.265
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 2.821
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 2.029
TRAINING: | Iteration [8/12] | Loss 0.20 | Norm 4.008
TRAINING: | Iteration [9/12] | Loss 0.18 | Norm 3.138
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.425
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.234
TRAINING: | Iteration [12/12] | Loss 0.17 | Norm 3.282
Epoch: 838/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.303
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 2.692
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.508
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 1.721
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.246
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.422
TRAINING: | Iteration [7/12] | Loss 0.14 | Norm 3.297
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.517
TRAINING: | Iteration [9/12] | Loss 0.19 | Norm 3.760
TRAINING: | Iteration [10/12] | Loss 0.18 | Norm 3.129
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.768
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 2.120
Epoch: 839/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 1.261
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.544
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 2.371
TRAINING: | Iteration [4/12] | Loss 0.22 | Norm 3.389
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.520
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.537
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 2.557
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.923
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.844
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 2.177
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.823
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.601
Epoch: 840/10000 | Epoch Time: 0.094 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 0.822
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 2.369
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 0.899
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 2.650
TRAINING: | Iteration [5/12] | Loss 0.19 | Norm 3.425
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.932
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 0.742
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 2.824
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 0.558
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.640
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.380
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.635
Epoch: 841/10000 | Epoch Time: 0.096 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.672
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 1.097
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 0.931
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.395
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.745
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.187
TRAINING: | Iteration [7/12] | Loss 0.14 | Norm 2.532
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 2.986
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.315
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 2.082
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 2.323
TRAINING: | Iteration [12/12] | Loss 0.15 | Norm 3.667
Epoch: 842/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.547
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.551
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.221
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.528
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.174
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.974
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.351
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 4.190
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 3.029
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 0.768
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 2.577
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 3.673
Epoch: 843/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.324
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.542
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.861
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.058
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 2.945
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 3.991
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 2.722
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.411
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.828
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 3.033
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 3.571
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.788
Epoch: 844/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 3.226
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 2.735
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.377
TRAINING: | Iteration [4/12] | Loss 0.14 | Norm 4.854
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.351
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.684
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.094
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.844
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.283
TRAINING: | Iteration [10/12] | Loss 0.19 | Norm 5.000
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 2.120
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 2.059
Epoch: 845/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.561
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 2.839
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 4.631
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 0.829
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.783
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.036
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 2.341
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.925
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 2.304
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 2.035
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.359
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.124
Epoch: 846/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.751
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 3.035
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 3.324
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.318
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 1.746
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.341
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 3.089
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.894
TRAINING: | Iteration [9/12] | Loss 0.17 | Norm 2.884
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.696
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 2.086
TRAINING: | Iteration [12/12] | Loss 0.16 | Norm 3.459
Epoch: 847/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.913
TRAINING: | Iteration [2/12] | Loss 0.17 | Norm 2.617
TRAINING: | Iteration [3/12] | Loss 0.18 | Norm 2.850
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.683
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 2.419
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 2.391
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.106
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 1.924
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 2.500
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.325
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.954
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.018
Epoch: 848/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.951
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.214
TRAINING: | Iteration [3/12] | Loss 0.15 | Norm 3.158
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.680
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.933
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 2.801
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 3.497
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 3.913
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.300
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.238
TRAINING: | Iteration [11/12] | Loss 0.20 | Norm 5.000
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 5.000
Epoch: 849/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 2.287
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.361
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.160
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 2.826
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.660
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.320
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 1.335
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.534
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.486
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 3.051
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.147
TRAINING: | Iteration [12/12] | Loss 0.18 | Norm 3.440
Epoch: 850/10000 | Epoch Time: 0.094 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 2.627
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.283
TRAINING: | Iteration [3/12] | Loss 0.20 | Norm 3.695
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.426
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.077
TRAINING: | Iteration [6/12] | Loss 0.17 | Norm 2.989
TRAINING: | Iteration [7/12] | Loss 0.14 | Norm 2.575
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.367
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 2.011
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.924
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 1.784
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.806
Epoch: 851/10000 | Epoch Time: 0.096 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.703
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 0.819
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.542
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.776
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 0.966
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 2.296
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 2.332
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.462
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 2.861
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 3.619
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.294
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 2.857
Epoch: 852/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.045
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 0.983
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 2.151
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 2.818
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.908
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 2.055
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 1.950
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 1.979
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.306
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.897
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 2.671
TRAINING: | Iteration [12/12] | Loss 0.20 | Norm 3.091
Epoch: 853/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.288
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.001
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.559
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.808
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 2.030
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.123
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 2.891
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 3.189
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 3.426
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 3.013
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 2.431
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 3.547
Epoch: 854/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.14 | Norm 3.826
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 2.819
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.551
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 4.786
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.170
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 2.767
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.431
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 3.197
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 3.833
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 2.004
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 2.546
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.858
Epoch: 855/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.840
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 2.737
TRAINING: | Iteration [3/12] | Loss 0.14 | Norm 3.165
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.438
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.450
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 2.871
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.653
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 2.436
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 3.841
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.774
TRAINING: | Iteration [11/12] | Loss 0.14 | Norm 3.603
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 3.012
Epoch: 856/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 0.726
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.477
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.775
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 0.853
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.015
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 2.469
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 1.678
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 3.193
TRAINING: | Iteration [9/12] | Loss 0.15 | Norm 3.934
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 4.338
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 0.901
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.788
Epoch: 857/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.703
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 0.720
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 3.995
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.498
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.503
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 0.903
TRAINING: | Iteration [7/12] | Loss 0.13 | Norm 2.474
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 2.980
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.282
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.881
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 2.139
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 3.776
Epoch: 858/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 2.848
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.993
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.312
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.461
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 2.754
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.237
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 0.652
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 0.823
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 2.380
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 3.352
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.785
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 0.683
Epoch: 859/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 0.874
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.016
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.272
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 3.003
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 1.626
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.435
TRAINING: | Iteration [7/12] | Loss 0.19 | Norm 2.738
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 3.074
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 2.510
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 2.257
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 1.947
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 3.237
Epoch: 860/10000 | Epoch Time: 0.094 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.897
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.726
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.238
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.118
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.439
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.279
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 1.576
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.245
TRAINING: | Iteration [9/12] | Loss 0.14 | Norm 4.330
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 4.343
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 2.294
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.823
Epoch: 861/10000 | Epoch Time: 0.096 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 3.100
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 3.192
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 3.318
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 3.105
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.473
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.433
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 2.687
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 4.758
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 2.260
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.777
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.650
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.211
Epoch: 862/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.16 | Norm 4.434
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 3.033
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 3.283
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 1.757
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 2.351
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 2.230
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.827
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 1.901
TRAINING: | Iteration [9/12] | Loss 0.24 | Norm 4.737
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.724
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 2.024
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.365
Epoch: 863/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.051
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 4.823
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.042
TRAINING: | Iteration [4/12] | Loss 0.18 | Norm 3.909
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 3.113
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 3.774
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 2.958
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.038
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.874
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.221
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.909
TRAINING: | Iteration [12/12] | Loss 0.20 | Norm 3.384
Epoch: 864/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.04 | Norm 0.894
TRAINING: | Iteration [2/12] | Loss 0.15 | Norm 5.000
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.716
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 1.821
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.558
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 2.229
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.756
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 0.968
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.343
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.720
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 2.189
TRAINING: | Iteration [12/12] | Loss 0.51 | Norm 5.000
Epoch: 865/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 1.871
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 2.071
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 1.275
TRAINING: | Iteration [4/12] | Loss 0.22 | Norm 4.850
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.150
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.273
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 2.495
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.058
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.601
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 0.947
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.075
TRAINING: | Iteration [12/12] | Loss 0.04 | Norm 0.862
Epoch: 866/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.808
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.531
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.078
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.302
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.254
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.787
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.118
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.424
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 2.699
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 1.683
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.951
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.447
Epoch: 867/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.906
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 0.659
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.585
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 0.931
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 1.940
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.478
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.418
TRAINING: | Iteration [8/12] | Loss 0.15 | Norm 3.179
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.402
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 1.918
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.378
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 2.282
Epoch: 868/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.459
TRAINING: | Iteration [2/12] | Loss 0.17 | Norm 2.740
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.513
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 1.448
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.732
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.097
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 2.100
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.418
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.931
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.841
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.369
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.132
Epoch: 869/10000 | Epoch Time: 0.095 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 2.627
TRAINING: | Iteration [2/12] | Loss 0.16 | Norm 3.370
TRAINING: | Iteration [3/12] | Loss 0.14 | Norm 2.296
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.146
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 2.754
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 2.695
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 2.738
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.733
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.938
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.485
TRAINING: | Iteration [11/12] | Loss 0.17 | Norm 3.838
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.722
Epoch: 870/10000 | Epoch Time: 0.094 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.575
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.304
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.131
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.982
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.020
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.063
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.456
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 2.442
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.543
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 2.485
TRAINING: | Iteration [11/12] | Loss 0.17 | Norm 3.582
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 2.477
Epoch: 871/10000 | Epoch Time: 0.097 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.195
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 0.495
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.149
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 3.757
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 0.364
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.586
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.610
TRAINING: | Iteration [8/12] | Loss 0.16 | Norm 3.321
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 3.476
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.794
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.123
TRAINING: | Iteration [12/12] | Loss 0.35 | Norm 4.816
Epoch: 872/10000 | Epoch Time: 0.095 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.810
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 1.734
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 3.107
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 1.362
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 3.117
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.854
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 2.496
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.033
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.709
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 3.113
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.015
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.017
Epoch: 873/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.14 | Norm 4.044
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 3.983
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 2.781
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.538
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.518
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.103
TRAINING: | Iteration [7/12] | Loss 0.19 | Norm 4.654
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.636
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.510
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.213
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 2.313
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 3.208
Epoch: 874/10000 | Epoch Time: 0.096 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.412
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 0.627
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 2.768
TRAINING: | Iteration [4/12] | Loss 0.18 | Norm 3.618
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 3.223
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.626
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 3.356
TRAINING: | Iteration [8/12] | Loss 0.16 | Norm 3.941
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.146
TRAINING: | Iteration [10/12] | Loss 0.17 | Norm 3.166
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.020
TRAINING: | Iteration [12/12] | Loss 0.17 | Norm 4.911
Epoch: 875/10000 | Epoch Time: 0.095 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.149
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 3.215
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 3.194
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.523
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 0.688
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 0.750
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 3.241
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.954
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 3.409
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 2.555
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 2.652
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.682
Epoch: 876/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.209
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 3.066
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 2.152
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 1.817
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.609
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 2.636
TRAINING: | Iteration [7/12] | Loss 0.13 | Norm 3.734
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 2.909
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.528
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.165
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.531
TRAINING: | Iteration [12/12] | Loss 0.18 | Norm 3.809
Epoch: 877/10000 | Epoch Time: 0.095 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 2.785
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.594
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.409
TRAINING: | Iteration [4/12] | Loss 0.14 | Norm 3.118
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 3.680
TRAINING: | Iteration [6/12] | Loss 0.17 | Norm 3.993
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 2.117
TRAINING: | Iteration [8/12] | Loss 0.16 | Norm 3.585
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.367
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 3.078
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 4.554
TRAINING: | Iteration [12/12] | Loss 0.34 | Norm 4.960
Epoch: 878/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 2.274
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 1.339
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 3.043
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 2.163
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.311
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.534
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.153
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.358
TRAINING: | Iteration [9/12] | Loss 0.23 | Norm 4.230
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 2.740
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.994
TRAINING: | Iteration [12/12] | Loss 0.05 | Norm 1.133
Epoch: 879/10000 | Epoch Time: 0.095 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.183
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 0.799
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.399
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 2.653
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 0.927
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 2.588
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.325
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.760
TRAINING: | Iteration [9/12] | Loss 0.21 | Norm 3.627
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.710
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 1.951
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.995
Epoch: 880/10000 | Epoch Time: 0.094 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.585
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.300
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.079
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.779
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.253
TRAINING: | Iteration [6/12] | Loss 0.17 | Norm 3.559
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 2.062
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.077
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 0.651
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.279
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.321
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 1.109
Epoch: 881/10000 | Epoch Time: 0.096 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 3.656
TRAINING: | Iteration [2/12] | Loss 0.17 | Norm 3.207
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 2.036
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.500
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 0.752
TRAINING: | Iteration [6/12] | Loss 0.16 | Norm 2.755
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.836
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 2.271
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.291
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 2.981
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 0.559
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.573
Epoch: 882/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.633
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.393
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.838
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.165
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.252
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 2.194
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 2.804
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 2.399
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.707
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 4.524
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 2.148
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 3.008
Epoch: 883/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 3.027
TRAINING: | Iteration [2/12] | Loss 0.15 | Norm 3.737
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 3.305
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.745
TRAINING: | Iteration [5/12] | Loss 0.23 | Norm 3.814
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 3.051
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 4.935
TRAINING: | Iteration [8/12] | Loss 0.18 | Norm 5.000
TRAINING: | Iteration [9/12] | Loss 0.18 | Norm 3.587
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 3.693
TRAINING: | Iteration [11/12] | Loss 0.15 | Norm 3.891
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 3.653
Epoch: 884/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 2.057
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.563
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 3.140
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 2.161
TRAINING: | Iteration [5/12] | Loss 0.23 | Norm 4.305
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.750
TRAINING: | Iteration [7/12] | Loss 0.20 | Norm 3.601
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.922
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 3.165
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.978
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 5.000
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 3.624
Epoch: 885/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.703
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.028
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 3.915
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 3.393
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.481
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 3.008
TRAINING: | Iteration [7/12] | Loss 0.17 | Norm 3.591
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 3.211
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.489
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.029
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 4.779
TRAINING: | Iteration [12/12] | Loss 0.24 | Norm 3.147
Epoch: 886/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.619
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.332
TRAINING: | Iteration [3/12] | Loss 0.14 | Norm 3.738
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 3.165
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.533
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.686
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 3.189
TRAINING: | Iteration [8/12] | Loss 0.18 | Norm 3.698
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.338
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.691
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.297
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 2.225
Epoch: 887/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 1.859
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.584
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.084
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 3.237
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.868
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 2.268
TRAINING: | Iteration [7/12] | Loss 0.27 | Norm 4.151
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 2.156
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.424
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.359
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 2.226
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 3.608
Epoch: 888/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.776
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.595
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 3.789
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 3.619
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.790
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.802
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.911
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.477
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.259
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.787
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.581
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 3.192
Epoch: 889/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.326
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.357
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 0.842
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 1.254
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.943
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.884
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 1.538
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 2.166
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 2.507
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.098
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.447
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.736
Epoch: 890/10000 | Epoch Time: 0.094 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.175
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.458
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.271
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 1.832
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 3.016
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.305
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.492
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 3.110
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 2.529
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.193
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 2.578
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 1.667
Epoch: 891/10000 | Epoch Time: 0.095 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.008
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 1.827
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 3.646
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.754
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.141
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.669
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 2.382
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 2.850
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 0.901
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 2.281
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 0.910
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 1.500
Epoch: 892/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 2.844
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 2.062
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 2.847
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 2.889
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 2.285
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.538
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.666
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 2.928
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.421
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 1.680
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.113
TRAINING: | Iteration [12/12] | Loss 0.20 | Norm 3.774
Epoch: 893/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.405
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.073
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 2.177
TRAINING: | Iteration [4/12] | Loss 0.17 | Norm 4.533
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.033
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.910
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.911
TRAINING: | Iteration [8/12] | Loss 0.23 | Norm 4.436
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.342
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 3.034
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 2.016
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 0.677
Epoch: 894/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 2.902
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.100
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 3.136
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 3.309
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.494
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.949
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.579
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.948
TRAINING: | Iteration [9/12] | Loss 0.16 | Norm 5.000
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 3.406
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 1.842
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.559
Epoch: 895/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.359
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 4.045
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.475
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.275
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 1.481
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 2.069
TRAINING: | Iteration [7/12] | Loss 0.14 | Norm 5.000
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.313
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 1.356
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.857
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.720
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.793
Epoch: 896/10000 | Epoch Time: 0.097 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 2.405
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.257
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.453
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 1.332
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 2.239
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.650
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.485
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.133
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 2.196
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 2.624
TRAINING: | Iteration [11/12] | Loss 0.21 | Norm 2.962
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.652
Epoch: 897/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 3.111
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 2.602
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.073
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.816
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.414
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.315
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.992
TRAINING: | Iteration [8/12] | Loss 0.34 | Norm 4.853
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.059
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.543
TRAINING: | Iteration [11/12] | Loss 0.18 | Norm 3.665
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 3.050
Epoch: 898/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.15 | Norm 3.710
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.697
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 2.353
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.016
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.590
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 2.388
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.762
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 2.751
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.282
TRAINING: | Iteration [10/12] | Loss 0.17 | Norm 3.416
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 2.044
TRAINING: | Iteration [12/12] | Loss 0.27 | Norm 4.209
Epoch: 899/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.397
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 2.204
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.556
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.668
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.296
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 2.326
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.353
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.232
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.487
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 0.765
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.012
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.111
Epoch: 900/10000 | Epoch Time: 0.094 seconds
Saving Model
Preparation of Training Data time: 10.248 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 0.692
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 0.909
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.519
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.672
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 2.896
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 3.031
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 3.883
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.604
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 1.613
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.899
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.496
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 0.739
Epoch: 901/10000 | Epoch Time: 0.106 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.690
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.586
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 2.698
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 0.999
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.247
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.412
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 2.848
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.348
TRAINING: | Iteration [9/12] | Loss 0.20 | Norm 3.694
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 1.732
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.850
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.534
Epoch: 902/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 2.015
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.581
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 3.056
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.268
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.047
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.277
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.738
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 0.819
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.274
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.882
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 2.297
TRAINING: | Iteration [12/12] | Loss 0.43 | Norm 5.000
Epoch: 903/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.954
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.992
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 1.089
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.742
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.180
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 2.690
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.808
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 0.812
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.007
TRAINING: | Iteration [10/12] | Loss 0.15 | Norm 2.982
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 0.907
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 3.272
Epoch: 904/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.14 | Norm 2.604
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.940
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.567
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.934
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.447
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.555
TRAINING: | Iteration [7/12] | Loss 0.13 | Norm 2.698
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.137
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.171
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 3.128
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.685
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 0.938
Epoch: 905/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.645
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 3.155
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 2.549
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 3.869
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.689
TRAINING: | Iteration [6/12] | Loss 0.14 | Norm 3.015
TRAINING: | Iteration [7/12] | Loss 0.16 | Norm 2.438
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.300
TRAINING: | Iteration [9/12] | Loss 0.22 | Norm 3.468
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 1.916
TRAINING: | Iteration [11/12] | Loss 0.19 | Norm 3.176
TRAINING: | Iteration [12/12] | Loss 0.19 | Norm 3.078
Epoch: 906/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 0.903
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 2.280
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 2.089
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.284
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 1.790
TRAINING: | Iteration [6/12] | Loss 0.14 | Norm 2.847
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.055
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.363
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.636
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.616
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.561
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 1.803
Epoch: 907/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 0.901
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 2.903
TRAINING: | Iteration [3/12] | Loss 0.14 | Norm 3.182
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.807
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 3.185
TRAINING: | Iteration [6/12] | Loss 0.17 | Norm 3.210
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 2.173
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.602
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 1.996
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 1.493
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.811
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.035
Epoch: 908/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 1.385
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.262
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 0.925
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.878
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 2.858
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.434
TRAINING: | Iteration [7/12] | Loss 0.14 | Norm 3.120
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 0.990
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.797
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.528
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.896
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 2.832
Epoch: 909/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.968
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.839
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 2.673
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 1.569
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.323
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 0.952
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.987
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.018
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.170
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.711
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.341
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.145
Epoch: 910/10000 | Epoch Time: 0.094 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 2.859
TRAINING: | Iteration [2/12] | Loss 0.17 | Norm 3.779
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 1.367
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 1.001
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.898
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 2.969
TRAINING: | Iteration [7/12] | Loss 0.05 | Norm 1.131
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 0.835
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 2.360
TRAINING: | Iteration [10/12] | Loss 0.16 | Norm 3.063
TRAINING: | Iteration [11/12] | Loss 0.21 | Norm 4.140
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.510
Epoch: 911/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 0.879
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.280
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 2.406
TRAINING: | Iteration [4/12] | Loss 0.16 | Norm 3.155
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 0.887
TRAINING: | Iteration [6/12] | Loss 0.18 | Norm 4.906
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 2.661
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.832
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 3.050
TRAINING: | Iteration [10/12] | Loss 0.18 | Norm 5.000
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.198
TRAINING: | Iteration [12/12] | Loss 0.17 | Norm 3.406
Epoch: 912/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.19 | Norm 3.832
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 4.281
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.727
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 3.836
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.914
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 0.892
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 2.324
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 3.748
TRAINING: | Iteration [9/12] | Loss 0.14 | Norm 2.965
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 3.146
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 0.706
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 2.059
Epoch: 913/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.523
TRAINING: | Iteration [2/12] | Loss 0.35 | Norm 5.000
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.761
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.408
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.749
TRAINING: | Iteration [6/12] | Loss 0.14 | Norm 2.852
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 2.750
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.818
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 2.094
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 0.894
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.908
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 2.634
Epoch: 914/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.232
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.143
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.111
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.042
TRAINING: | Iteration [5/12] | Loss 0.21 | Norm 3.977
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.135
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 2.253
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.382
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 3.946
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.717
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.548
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 0.849
Epoch: 915/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 1.009
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.907
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 2.797
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.803
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 0.948
TRAINING: | Iteration [6/12] | Loss 0.16 | Norm 2.658
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 3.036
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.245
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.555
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 3.226
TRAINING: | Iteration [11/12] | Loss 0.15 | Norm 3.364
TRAINING: | Iteration [12/12] | Loss 0.15 | Norm 5.000
Epoch: 916/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.384
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 3.472
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 2.973
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.118
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.120
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.957
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 4.125
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.630
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 2.032
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.932
TRAINING: | Iteration [11/12] | Loss 0.22 | Norm 3.739
TRAINING: | Iteration [12/12] | Loss 0.22 | Norm 5.000
Epoch: 917/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 4.727
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 2.100
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.285
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.906
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 1.546
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.882
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.455
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.064
TRAINING: | Iteration [9/12] | Loss 0.20 | Norm 4.306
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 3.064
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.146
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 1.500
Epoch: 918/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.894
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 3.129
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.157
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.354
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.303
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 2.616
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.781
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.543
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.362
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.935
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.955
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 0.985
Epoch: 919/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 3.077
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.206
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 1.888
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.196
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 0.609
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 0.895
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.392
TRAINING: | Iteration [8/12] | Loss 0.16 | Norm 2.913
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.640
TRAINING: | Iteration [10/12] | Loss 0.23 | Norm 4.306
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.950
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 2.350
Epoch: 920/10000 | Epoch Time: 0.093 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 2.978
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 2.116
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.569
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 2.015
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.446
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.704
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 1.343
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 3.337
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 2.023
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.888
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 2.145
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 1.996
Epoch: 921/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 1.069
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.629
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 3.264
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 3.463
TRAINING: | Iteration [5/12] | Loss 0.14 | Norm 2.420
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.610
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.680
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.908
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.762
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.488
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.425
TRAINING: | Iteration [12/12] | Loss 0.16 | Norm 3.327
Epoch: 922/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.752
TRAINING: | Iteration [2/12] | Loss 0.17 | Norm 3.824
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 3.150
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.224
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 1.526
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.538
TRAINING: | Iteration [7/12] | Loss 0.13 | Norm 2.765
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.506
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.649
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 2.160
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 0.963
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 2.155
Epoch: 923/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 2.606
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.481
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.461
TRAINING: | Iteration [4/12] | Loss 0.15 | Norm 3.644
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.901
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 3.016
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 3.522
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 0.969
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.405
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 2.192
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.244
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 2.657
Epoch: 924/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.822
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.978
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 2.343
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 0.847
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.379
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.432
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 1.887
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 2.933
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 0.890
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.532
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 2.940
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.222
Epoch: 925/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.919
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.438
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.313
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 2.284
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.139
TRAINING: | Iteration [6/12] | Loss 0.19 | Norm 3.368
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.613
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.098
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.367
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.110
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.739
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 2.763
Epoch: 926/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.17 | Norm 3.323
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.189
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.611
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.677
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.117
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.569
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.548
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.201
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 3.011
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 0.585
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 2.945
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.461
Epoch: 927/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.948
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.800
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.351
TRAINING: | Iteration [4/12] | Loss 0.16 | Norm 3.378
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 3.744
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 2.178
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 0.995
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.380
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 3.277
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.105
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 0.928
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.271
Epoch: 928/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.238
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 2.023
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.446
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.170
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 2.080
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.208
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.265
TRAINING: | Iteration [8/12] | Loss 0.17 | Norm 3.311
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.138
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.468
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 0.758
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.052
Epoch: 929/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.115
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 2.828
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 1.840
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.585
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.216
TRAINING: | Iteration [6/12] | Loss 0.16 | Norm 3.057
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.598
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 2.978
TRAINING: | Iteration [9/12] | Loss 0.16 | Norm 2.931
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.235
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.721
TRAINING: | Iteration [12/12] | Loss 0.28 | Norm 5.000
Epoch: 930/10000 | Epoch Time: 0.095 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.19 | Norm 3.697
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.934
TRAINING: | Iteration [3/12] | Loss 0.04 | Norm 0.902
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 2.680
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.715
TRAINING: | Iteration [6/12] | Loss 0.18 | Norm 3.548
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 0.813
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 2.680
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 0.896
TRAINING: | Iteration [10/12] | Loss 0.15 | Norm 2.780
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.052
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.610
Epoch: 931/10000 | Epoch Time: 0.099 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.201
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.624
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 2.302
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 1.695
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.291
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.247
TRAINING: | Iteration [7/12] | Loss 0.14 | Norm 3.524
TRAINING: | Iteration [8/12] | Loss 0.17 | Norm 2.790
TRAINING: | Iteration [9/12] | Loss 0.14 | Norm 2.381
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.205
TRAINING: | Iteration [11/12] | Loss 0.15 | Norm 3.365
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.005
Epoch: 932/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 2.894
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.682
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.889
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.535
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 1.903
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.460
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.536
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.875
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 1.859
TRAINING: | Iteration [10/12] | Loss 0.39 | Norm 5.000
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 0.515
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.080
Epoch: 933/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 2.317
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 1.980
TRAINING: | Iteration [3/12] | Loss 0.18 | Norm 4.048
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.239
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.043
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 2.244
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 2.817
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.434
TRAINING: | Iteration [9/12] | Loss 0.16 | Norm 2.802
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 2.965
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.593
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 3.758
Epoch: 934/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.824
TRAINING: | Iteration [2/12] | Loss 0.15 | Norm 3.194
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.668
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 2.565
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.238
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 2.514
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.428
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.536
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.938
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 2.460
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 2.179
TRAINING: | Iteration [12/12] | Loss 0.15 | Norm 3.913
Epoch: 935/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 3.131
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 3.203
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.976
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.763
TRAINING: | Iteration [5/12] | Loss 0.16 | Norm 4.047
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 3.576
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 3.143
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.842
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 3.010
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.204
TRAINING: | Iteration [11/12] | Loss 0.20 | Norm 3.910
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.555
Epoch: 936/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 4.490
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.025
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.292
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 0.576
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 3.136
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.264
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 5.000
TRAINING: | Iteration [8/12] | Loss 0.16 | Norm 3.570
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.070
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.579
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.769
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 4.063
Epoch: 937/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 5.000
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.501
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.385
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.674
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 2.170
TRAINING: | Iteration [6/12] | Loss 0.23 | Norm 4.590
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 1.702
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.804
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.012
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.678
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.523
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 3.380
Epoch: 938/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.053
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.472
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.364
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.877
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 2.292
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.769
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.787
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 2.346
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 2.303
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.427
TRAINING: | Iteration [11/12] | Loss 0.14 | Norm 2.088
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 0.877
Epoch: 939/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.798
TRAINING: | Iteration [2/12] | Loss 0.17 | Norm 2.679
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.520
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 0.581
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.181
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.105
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.610
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 3.169
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.537
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 0.733
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 1.807
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.399
Epoch: 940/10000 | Epoch Time: 0.092 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.19 | Norm 3.705
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.977
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 0.698
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.257
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.552
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 1.904
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.787
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.722
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.945
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.284
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.204
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.205
Epoch: 941/10000 | Epoch Time: 0.096 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 2.399
TRAINING: | Iteration [2/12] | Loss 0.21 | Norm 4.207
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.499
TRAINING: | Iteration [4/12] | Loss 0.17 | Norm 4.077
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.176
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.124
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 2.653
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.037
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.099
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.904
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 2.376
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 2.929
Epoch: 942/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.159
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 1.709
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 2.702
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 0.862
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 2.069
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.707
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.567
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.638
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.431
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.471
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 2.509
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 2.621
Epoch: 943/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.425
TRAINING: | Iteration [2/12] | Loss 0.18 | Norm 3.321
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.018
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.921
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 0.906
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.844
TRAINING: | Iteration [7/12] | Loss 0.15 | Norm 3.463
TRAINING: | Iteration [8/12] | Loss 0.15 | Norm 4.119
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.945
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.588
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.660
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 0.571
Epoch: 944/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 3.018
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 4.218
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.939
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.487
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 0.615
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 4.092
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 3.446
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 2.706
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.189
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.268
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.492
TRAINING: | Iteration [12/12] | Loss 0.38 | Norm 5.000
Epoch: 945/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.140
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 0.816
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.397
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.108
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 1.517
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 0.683
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.396
TRAINING: | Iteration [8/12] | Loss 0.05 | Norm 1.640
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.141
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 2.802
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.258
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 2.246
Epoch: 946/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 0.952
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.225
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.208
TRAINING: | Iteration [4/12] | Loss 0.18 | Norm 2.925
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.797
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.722
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 0.663
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.110
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 2.511
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.205
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 1.441
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.129
Epoch: 947/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.268
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 2.902
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.256
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 0.669
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 2.879
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.065
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.104
TRAINING: | Iteration [8/12] | Loss 0.20 | Norm 3.438
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.142
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 2.046
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 0.887
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.535
Epoch: 948/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.779
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 3.517
TRAINING: | Iteration [3/12] | Loss 0.16 | Norm 2.985
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 2.347
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 0.693
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.562
TRAINING: | Iteration [7/12] | Loss 0.15 | Norm 2.837
TRAINING: | Iteration [8/12] | Loss 0.25 | Norm 4.299
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.920
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.169
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.624
TRAINING: | Iteration [12/12] | Loss 0.16 | Norm 2.803
Epoch: 949/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 3.608
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.691
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.829
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 0.919
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.629
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 2.713
TRAINING: | Iteration [7/12] | Loss 0.13 | Norm 3.597
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.269
TRAINING: | Iteration [9/12] | Loss 0.14 | Norm 3.092
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 2.591
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.270
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.238
Epoch: 950/10000 | Epoch Time: 0.092 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.16 | Norm 4.437
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.529
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 1.715
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 1.579
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 1.932
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 0.869
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.403
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 3.160
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 2.403
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 2.546
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.552
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.515
Epoch: 951/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 2.848
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 2.903
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.071
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.472
TRAINING: | Iteration [5/12] | Loss 0.15 | Norm 3.483
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 2.814
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.938
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.628
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 0.937
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 3.038
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 4.178
TRAINING: | Iteration [12/12] | Loss 0.18 | Norm 2.914
Epoch: 952/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 2.857
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.164
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 1.830
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.867
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.738
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 2.660
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 1.836
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 3.204
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.594
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 0.614
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.400
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.198
Epoch: 953/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.295
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.682
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 2.392
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.452
TRAINING: | Iteration [5/12] | Loss 0.05 | Norm 0.910
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 0.744
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 0.903
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.730
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.373
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.552
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 2.507
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.625
Epoch: 954/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.101
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.580
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.287
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 3.147
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.882
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.847
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 3.401
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 2.520
TRAINING: | Iteration [9/12] | Loss 0.20 | Norm 3.787
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 0.541
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 3.078
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.922
Epoch: 955/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 1.748
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.504
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.427
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.548
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.064
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.454
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.737
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 0.803
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 0.998
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.318
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 1.952
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 0.945
Epoch: 956/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.127
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.829
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 1.727
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.619
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.108
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 1.605
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.468
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.353
TRAINING: | Iteration [9/12] | Loss 0.18 | Norm 3.825
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 2.391
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 2.945
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 1.675
Epoch: 957/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 0.983
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.443
TRAINING: | Iteration [3/12] | Loss 0.17 | Norm 3.344
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.677
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 2.214
TRAINING: | Iteration [6/12] | Loss 0.19 | Norm 3.037
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 2.621
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.398
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.243
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 2.836
TRAINING: | Iteration [11/12] | Loss 0.14 | Norm 4.381
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.504
Epoch: 958/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 3.654
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 4.130
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.383
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.968
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 0.808
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.861
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.338
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 2.025
TRAINING: | Iteration [9/12] | Loss 0.21 | Norm 4.433
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 0.693
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.528
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.301
Epoch: 959/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 0.807
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 2.443
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 0.758
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.315
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.725
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.802
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.096
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.468
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.393
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 1.663
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 2.515
TRAINING: | Iteration [12/12] | Loss 0.16 | Norm 3.049
Epoch: 960/10000 | Epoch Time: 0.093 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.744
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.561
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.738
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 3.538
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 2.344
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.845
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 2.521
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.292
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.775
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 2.091
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 3.041
TRAINING: | Iteration [12/12] | Loss 0.15 | Norm 3.196
Epoch: 961/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.20 | Norm 4.465
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.278
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.171
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.975
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.514
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 2.311
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 3.401
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.862
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.858
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 2.452
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 2.024
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.172
Epoch: 962/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 2.105
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 0.790
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.262
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.603
TRAINING: | Iteration [5/12] | Loss 0.14 | Norm 2.905
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.383
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 2.797
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.812
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 2.592
TRAINING: | Iteration [10/12] | Loss 0.24 | Norm 4.466
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.242
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.148
Epoch: 963/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.210
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.944
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.867
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 0.570
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.884
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.345
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.242
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 0.883
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.883
TRAINING: | Iteration [10/12] | Loss 0.19 | Norm 3.182
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.741
TRAINING: | Iteration [12/12] | Loss 0.16 | Norm 3.209
Epoch: 964/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 3.205
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.072
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 0.685
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.555
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 0.837
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 2.585
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 2.528
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.230
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.399
TRAINING: | Iteration [10/12] | Loss 0.18 | Norm 3.137
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.288
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 3.621
Epoch: 965/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 0.849
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 1.581
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 3.087
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 3.690
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.598
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 0.809
TRAINING: | Iteration [7/12] | Loss 0.14 | Norm 3.523
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 4.446
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.766
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 2.500
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 0.653
TRAINING: | Iteration [12/12] | Loss 0.18 | Norm 2.903
Epoch: 966/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.14 | Norm 3.936
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 3.703
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.690
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.457
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.318
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 4.032
TRAINING: | Iteration [7/12] | Loss 0.22 | Norm 4.553
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 4.050
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 2.621
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.919
TRAINING: | Iteration [11/12] | Loss 0.21 | Norm 4.812
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.412
Epoch: 967/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.145
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.131
TRAINING: | Iteration [3/12] | Loss 0.17 | Norm 3.174
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.429
TRAINING: | Iteration [5/12] | Loss 0.22 | Norm 3.866
TRAINING: | Iteration [6/12] | Loss 0.16 | Norm 2.375
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.314
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 0.986
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 2.992
TRAINING: | Iteration [10/12] | Loss 0.16 | Norm 2.912
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 2.529
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 1.065
Epoch: 968/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.16 | Norm 3.910
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.827
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 2.488
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 0.788
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 2.420
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 3.211
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.372
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.919
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 4.043
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.900
TRAINING: | Iteration [11/12] | Loss 0.15 | Norm 3.566
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 3.669
Epoch: 969/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 3.871
TRAINING: | Iteration [2/12] | Loss 0.16 | Norm 4.484
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 0.785
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.966
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.734
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 3.135
TRAINING: | Iteration [7/12] | Loss 0.22 | Norm 4.706
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.854
TRAINING: | Iteration [9/12] | Loss 0.15 | Norm 3.431
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 1.070
TRAINING: | Iteration [11/12] | Loss 0.16 | Norm 4.313
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 1.362
Epoch: 970/10000 | Epoch Time: 0.092 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 2.497
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.433
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 2.096
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 3.000
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 2.988
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.098
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 3.472
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.576
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.122
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.030
TRAINING: | Iteration [11/12] | Loss 0.16 | Norm 5.000
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.408
Epoch: 971/10000 | Epoch Time: 0.095 seconds
TRAINING: | Iteration [1/12] | Loss 0.14 | Norm 2.941
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.531
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 3.134
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.202
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 0.754
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.820
TRAINING: | Iteration [7/12] | Loss 0.15 | Norm 4.560
TRAINING: | Iteration [8/12] | Loss 0.17 | Norm 3.979
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.460
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 2.573
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.592
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.178
Epoch: 972/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.17 | Norm 4.291
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 4.378
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 3.769
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.320
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 3.249
TRAINING: | Iteration [6/12] | Loss 0.16 | Norm 4.641
TRAINING: | Iteration [7/12] | Loss 0.13 | Norm 3.627
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.704
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.190
TRAINING: | Iteration [10/12] | Loss 0.16 | Norm 3.185
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 2.031
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.077
Epoch: 973/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.670
TRAINING: | Iteration [2/12] | Loss 0.14 | Norm 3.967
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 2.562
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 1.942
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.364
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 2.626
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.886
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 3.347
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.005
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 2.687
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 0.814
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.602
Epoch: 974/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.877
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.494
TRAINING: | Iteration [3/12] | Loss 0.26 | Norm 4.413
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 3.017
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.069
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 2.212
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 0.947
TRAINING: | Iteration [8/12] | Loss 0.15 | Norm 2.551
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.918
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.187
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.702
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.064
Epoch: 975/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.270
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.435
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 0.887
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.362
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.945
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.025
TRAINING: | Iteration [7/12] | Loss 0.21 | Norm 4.084
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 2.227
TRAINING: | Iteration [9/12] | Loss 0.31 | Norm 3.841
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 0.878
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.273
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.475
Epoch: 976/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 2.188
TRAINING: | Iteration [2/12] | Loss 0.21 | Norm 4.355
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.475
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.964
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 2.830
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.594
TRAINING: | Iteration [7/12] | Loss 0.22 | Norm 4.101
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.680
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 2.484
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 1.319
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.458
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 3.093
Epoch: 977/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.629
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 0.553
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 2.887
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.184
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.775
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 0.853
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 2.858
TRAINING: | Iteration [8/12] | Loss 0.29 | Norm 5.000
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.796
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.596
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 2.197
TRAINING: | Iteration [12/12] | Loss 0.28 | Norm 4.250
Epoch: 978/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.783
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 2.547
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.326
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 2.221
TRAINING: | Iteration [5/12] | Loss 0.14 | Norm 2.187
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.533
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 1.782
TRAINING: | Iteration [8/12] | Loss 0.20 | Norm 4.247
TRAINING: | Iteration [9/12] | Loss 0.25 | Norm 4.190
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.727
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 2.280
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.554
Epoch: 979/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.817
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.001
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.204
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 2.293
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 2.336
TRAINING: | Iteration [6/12] | Loss 0.17 | Norm 3.549
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.737
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 2.779
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 2.795
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.008
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.159
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 3.382
Epoch: 980/10000 | Epoch Time: 0.092 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.216
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.940
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.853
TRAINING: | Iteration [4/12] | Loss 0.23 | Norm 4.465
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.011
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 3.536
TRAINING: | Iteration [7/12] | Loss 0.25 | Norm 4.792
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.575
TRAINING: | Iteration [9/12] | Loss 0.17 | Norm 3.313
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 2.587
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 3.876
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 0.804
Epoch: 981/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 2.474
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.058
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 2.819
TRAINING: | Iteration [4/12] | Loss 0.15 | Norm 3.625
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.336
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.600
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.614
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.745
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 2.325
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 3.145
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 0.856
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 3.238
Epoch: 982/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.122
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.543
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.097
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.480
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 2.032
TRAINING: | Iteration [6/12] | Loss 0.15 | Norm 2.828
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.796
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.734
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.797
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 0.897
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.547
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 2.186
Epoch: 983/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.19 | Norm 3.090
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.728
TRAINING: | Iteration [3/12] | Loss 0.24 | Norm 3.498
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 2.749
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 1.681
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 2.126
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.512
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 2.341
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 1.971
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 3.621
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.687
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.995
Epoch: 984/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.913
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.952
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 4.003
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 4.355
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.698
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 2.828
TRAINING: | Iteration [7/12] | Loss 0.14 | Norm 4.738
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 3.158
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 2.662
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.662
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 2.220
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 3.116
Epoch: 985/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 2.441
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.806
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.291
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.520
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.859
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 2.155
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 2.645
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.369
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 0.926
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.144
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 1.399
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.947
Epoch: 986/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 3.158
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.599
TRAINING: | Iteration [3/12] | Loss 0.23 | Norm 4.600
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.695
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.530
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 1.458
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.278
TRAINING: | Iteration [8/12] | Loss 0.26 | Norm 4.238
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.336
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 0.961
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 2.711
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 3.082
Epoch: 987/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.604
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 0.877
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.774
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.968
TRAINING: | Iteration [5/12] | Loss 0.14 | Norm 4.030
TRAINING: | Iteration [6/12] | Loss 0.05 | Norm 1.602
TRAINING: | Iteration [7/12] | Loss 0.17 | Norm 3.399
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.281
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.850
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 2.129
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.959
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.375
Epoch: 988/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.24 | Norm 3.945
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 2.328
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.496
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.121
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 0.941
TRAINING: | Iteration [6/12] | Loss 0.31 | Norm 5.000
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.730
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.391
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 3.442
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.701
TRAINING: | Iteration [11/12] | Loss 0.17 | Norm 3.770
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 1.676
Epoch: 989/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.753
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.056
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.431
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.055
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 2.836
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 1.432
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.862
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.455
TRAINING: | Iteration [9/12] | Loss 0.16 | Norm 3.376
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.837
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 1.780
TRAINING: | Iteration [12/12] | Loss 0.20 | Norm 4.447
Epoch: 990/10000 | Epoch Time: 0.093 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 2.711
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 2.561
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.342
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.928
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.930
TRAINING: | Iteration [6/12] | Loss 0.19 | Norm 3.914
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 3.158
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.753
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 1.954
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.185
TRAINING: | Iteration [11/12] | Loss 0.15 | Norm 4.087
TRAINING: | Iteration [12/12] | Loss 0.30 | Norm 4.885
Epoch: 991/10000 | Epoch Time: 0.094 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.474
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 2.814
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.163
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 2.244
TRAINING: | Iteration [5/12] | Loss 0.22 | Norm 4.849
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.810
TRAINING: | Iteration [7/12] | Loss 0.22 | Norm 4.418
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.633
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 1.749
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 2.150
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.465
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 2.202
Epoch: 992/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 0.780
TRAINING: | Iteration [2/12] | Loss 0.15 | Norm 3.345
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.129
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 1.517
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.944
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 3.565
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.083
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 0.949
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 2.192
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 3.014
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.274
TRAINING: | Iteration [12/12] | Loss 0.16 | Norm 3.829
Epoch: 993/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.826
TRAINING: | Iteration [2/12] | Loss 0.24 | Norm 4.913
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 0.773
TRAINING: | Iteration [4/12] | Loss 0.15 | Norm 2.633
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 3.084
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.060
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.942
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 3.293
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 2.877
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 0.914
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.047
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.535
Epoch: 994/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.15 | Norm 2.347
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 0.497
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.022
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.255
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 2.958
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 1.750
TRAINING: | Iteration [7/12] | Loss 0.16 | Norm 3.432
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.051
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 2.698
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.717
TRAINING: | Iteration [11/12] | Loss 0.17 | Norm 3.677
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 3.160
Epoch: 995/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 0.852
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.746
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 1.959
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.653
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.758
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.297
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.351
TRAINING: | Iteration [8/12] | Loss 0.15 | Norm 3.361
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 1.907
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 2.411
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 3.259
TRAINING: | Iteration [12/12] | Loss 0.22 | Norm 3.754
Epoch: 996/10000 | Epoch Time: 0.093 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 0.643
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 1.381
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 0.814
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.695
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.855
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.014
TRAINING: | Iteration [7/12] | Loss 0.19 | Norm 2.731
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.279
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 0.829
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 3.205
TRAINING: | Iteration [11/12] | Loss 0.24 | Norm 4.789
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 2.757
Epoch: 997/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 2.743
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.076
TRAINING: | Iteration [3/12] | Loss 0.16 | Norm 4.171
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.787
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 2.362
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.513
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.592
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 2.205
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 2.584
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 1.969
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 2.156
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.791
Epoch: 998/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 0.662
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 0.787
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 0.691
TRAINING: | Iteration [4/12] | Loss 0.18 | Norm 3.705
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.223
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.407
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.367
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.337
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.134
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.803
TRAINING: | Iteration [11/12] | Loss 0.05 | Norm 0.695
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.502
Epoch: 999/10000 | Epoch Time: 0.092 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.476
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.363
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 0.872
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 2.255
TRAINING: | Iteration [5/12] | Loss 0.20 | Norm 4.091
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.924
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.000
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 1.032
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.524
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.967
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 0.718
TRAINING: | Iteration [12/12] | Loss 0.20 | Norm 3.459
Epoch: 1000/10000 | Epoch Time: 0.093 seconds
Saving Model
Preparation of Training Data time: 70.897 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.169
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 1.248
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 1.412
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 0.944
TRAINING: | Iteration [5/12] | Loss 0.27 | Norm 4.491
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 1.990
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 2.275
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.224
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 1.690
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 0.984
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 2.055
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 2.193
Epoch: 1001/10000 | Epoch Time: 0.116 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.260
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 2.239
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 2.233
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 2.041
TRAINING: | Iteration [5/12] | Loss 0.25 | Norm 4.021
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 2.409
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 1.829
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 2.175
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 2.322
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 3.335
TRAINING: | Iteration [11/12] | Loss 0.19 | Norm 3.067
TRAINING: | Iteration [12/12] | Loss 0.20 | Norm 4.350
Epoch: 1002/10000 | Epoch Time: 0.105 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.729
TRAINING: | Iteration [2/12] | Loss 0.16 | Norm 2.737
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 0.854
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 0.849
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 0.993
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.717
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 1.409
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.232
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.802
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 0.902
TRAINING: | Iteration [11/12] | Loss 0.28 | Norm 4.487
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.460
Epoch: 1003/10000 | Epoch Time: 0.106 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 2.143
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 2.997
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.338
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 1.638
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.374
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.458
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 1.950
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.410
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.032
TRAINING: | Iteration [10/12] | Loss 0.20 | Norm 3.119
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 0.974
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.766
Epoch: 1004/10000 | Epoch Time: 0.117 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.645
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 2.914
TRAINING: | Iteration [3/12] | Loss 0.20 | Norm 4.196
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 2.366
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.380
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 2.492
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 2.593
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 2.207
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 3.141
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 1.601
TRAINING: | Iteration [11/12] | Loss 0.15 | Norm 3.300
TRAINING: | Iteration [12/12] | Loss 0.18 | Norm 4.172
Epoch: 1005/10000 | Epoch Time: 0.118 seconds
TRAINING: | Iteration [1/12] | Loss 0.16 | Norm 3.150
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 3.953
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.101
TRAINING: | Iteration [4/12] | Loss 0.21 | Norm 4.614
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.473
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 2.300
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 1.934
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 2.222
TRAINING: | Iteration [9/12] | Loss 0.15 | Norm 3.582
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 2.212
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 2.368
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 1.232
Epoch: 1006/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 2.004
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 2.802
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.208
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 2.129
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 1.530
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.662
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.048
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 1.910
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 0.905
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 1.777
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.218
TRAINING: | Iteration [12/12] | Loss 0.19 | Norm 4.088
Epoch: 1007/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.625
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 2.324
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 2.241
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 3.622
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.957
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 2.228
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 2.325
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.264
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 2.507
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 2.837
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.655
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 0.865
Epoch: 1008/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 2.192
TRAINING: | Iteration [2/12] | Loss 0.14 | Norm 4.303
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 2.849
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.640
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 4.601
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.275
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.295
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.448
TRAINING: | Iteration [9/12] | Loss 0.16 | Norm 2.985
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 0.814
TRAINING: | Iteration [11/12] | Loss 0.17 | Norm 3.685
TRAINING: | Iteration [12/12] | Loss 0.17 | Norm 2.971
Epoch: 1009/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.884
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.440
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.186
TRAINING: | Iteration [4/12] | Loss 0.14 | Norm 3.312
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.593
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 4.114
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 1.903
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.430
TRAINING: | Iteration [9/12] | Loss 0.16 | Norm 3.206
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 2.066
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 3.299
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 3.461
Epoch: 1010/10000 | Epoch Time: 0.102 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 2.831
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.481
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 3.073
TRAINING: | Iteration [4/12] | Loss 0.15 | Norm 3.294
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.673
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 2.011
TRAINING: | Iteration [7/12] | Loss 0.16 | Norm 3.548
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 1.938
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 3.243
TRAINING: | Iteration [10/12] | Loss 0.15 | Norm 3.073
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.256
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 1.810
Epoch: 1011/10000 | Epoch Time: 0.107 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 2.773
TRAINING: | Iteration [2/12] | Loss 0.21 | Norm 5.000
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 1.112
TRAINING: | Iteration [4/12] | Loss 0.16 | Norm 2.852
TRAINING: | Iteration [5/12] | Loss 0.14 | Norm 3.758
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.977
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 1.608
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 2.633
TRAINING: | Iteration [9/12] | Loss 0.17 | Norm 2.863
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 2.316
TRAINING: | Iteration [11/12] | Loss 0.16 | Norm 2.151
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.036
Epoch: 1012/10000 | Epoch Time: 0.118 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.741
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 3.336
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 2.287
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 0.792
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.063
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 2.825
TRAINING: | Iteration [7/12] | Loss 0.16 | Norm 3.911
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 3.994
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 2.474
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.139
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 2.816
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 2.970
Epoch: 1013/10000 | Epoch Time: 0.116 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.108
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 4.640
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.063
TRAINING: | Iteration [4/12] | Loss 0.25 | Norm 4.036
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 1.895
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 2.957
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 2.690
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 3.366
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.803
TRAINING: | Iteration [10/12] | Loss 0.27 | Norm 4.498
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 3.163
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 2.268
Epoch: 1014/10000 | Epoch Time: 0.100 seconds
TRAINING: | Iteration [1/12] | Loss 0.16 | Norm 4.252
TRAINING: | Iteration [2/12] | Loss 0.14 | Norm 3.181
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.398
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 2.861
TRAINING: | Iteration [5/12] | Loss 0.17 | Norm 3.399
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 0.890
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.648
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.155
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 2.596
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 1.936
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 2.113
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.549
Epoch: 1015/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.869
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.177
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.656
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.543
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.456
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.145
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 0.743
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 0.651
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 0.456
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 2.491
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 2.796
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.665
Epoch: 1016/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.14 | Norm 2.792
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.500
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 0.529
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.403
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.641
TRAINING: | Iteration [6/12] | Loss 0.14 | Norm 2.755
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.071
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 3.025
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 3.463
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 1.805
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.873
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.883
Epoch: 1017/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 2.427
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 1.866
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.510
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.892
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 0.735
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 0.740
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 0.876
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 1.807
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 0.466
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 2.737
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 2.753
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 2.465
Epoch: 1018/10000 | Epoch Time: 0.099 seconds
TRAINING: | Iteration [1/12] | Loss 0.15 | Norm 2.601
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.448
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 1.839
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 2.785
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.709
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.690
TRAINING: | Iteration [7/12] | Loss 0.15 | Norm 3.095
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.374
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.579
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.963
TRAINING: | Iteration [11/12] | Loss 0.25 | Norm 4.033
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.696
Epoch: 1019/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.24 | Norm 4.772
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.329
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.644
TRAINING: | Iteration [4/12] | Loss 0.06 | Norm 1.034
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 0.732
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 0.988
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 2.538
TRAINING: | Iteration [8/12] | Loss 0.15 | Norm 2.351
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 2.882
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 1.537
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.832
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 1.775
Epoch: 1020/10000 | Epoch Time: 0.117 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 0.773
TRAINING: | Iteration [2/12] | Loss 0.05 | Norm 1.083
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.692
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 4.328
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.115
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 2.966
TRAINING: | Iteration [7/12] | Loss 0.15 | Norm 2.441
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.622
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 3.595
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 4.236
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 3.236
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 2.920
Epoch: 1021/10000 | Epoch Time: 0.106 seconds
TRAINING: | Iteration [1/12] | Loss 0.05 | Norm 1.091
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 4.485
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 4.858
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.610
TRAINING: | Iteration [5/12] | Loss 0.14 | Norm 3.212
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 0.938
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.590
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 3.895
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 3.164
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.462
TRAINING: | Iteration [11/12] | Loss 0.33 | Norm 5.000
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 1.740
Epoch: 1022/10000 | Epoch Time: 0.116 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 3.071
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 1.937
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.552
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.167
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 0.946
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 3.095
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 2.157
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 2.039
TRAINING: | Iteration [9/12] | Loss 0.14 | Norm 3.253
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 2.312
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.496
TRAINING: | Iteration [12/12] | Loss 0.21 | Norm 4.043
Epoch: 1023/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.937
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.886
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.512
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.923
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 2.871
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 2.490
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.413
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 2.873
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 0.954
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.008
TRAINING: | Iteration [11/12] | Loss 0.26 | Norm 4.872
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.592
Epoch: 1024/10000 | Epoch Time: 0.119 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 3.029
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.182
TRAINING: | Iteration [3/12] | Loss 0.14 | Norm 3.001
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 3.244
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.187
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.291
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.339
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 2.489
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 3.206
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.902
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 2.689
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.930
Epoch: 1025/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.007
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.101
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.336
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 1.532
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 3.444
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 0.771
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.135
TRAINING: | Iteration [8/12] | Loss 0.15 | Norm 3.418
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.148
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.182
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 3.571
TRAINING: | Iteration [12/12] | Loss 0.32 | Norm 4.957
Epoch: 1026/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 2.444
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 2.481
TRAINING: | Iteration [3/12] | Loss 0.16 | Norm 2.725
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 2.523
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 1.492
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.104
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.225
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 1.816
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 1.644
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 0.801
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 1.950
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 2.579
Epoch: 1027/10000 | Epoch Time: 0.105 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.694
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 0.863
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 0.536
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 2.141
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 2.506
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 0.534
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.039
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.231
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 0.865
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.051
TRAINING: | Iteration [11/12] | Loss 0.24 | Norm 4.063
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 2.540
Epoch: 1028/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.489
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 0.669
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.591
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.065
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 1.414
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 2.567
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.369
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.145
TRAINING: | Iteration [9/12] | Loss 0.14 | Norm 2.280
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 0.996
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 3.780
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.428
Epoch: 1029/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.904
TRAINING: | Iteration [2/12] | Loss 0.23 | Norm 4.400
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.800
TRAINING: | Iteration [4/12] | Loss 0.15 | Norm 2.730
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 1.853
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.174
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 3.518
TRAINING: | Iteration [8/12] | Loss 0.17 | Norm 3.699
TRAINING: | Iteration [9/12] | Loss 0.19 | Norm 3.687
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 1.252
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 1.405
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 2.949
Epoch: 1030/10000 | Epoch Time: 0.101 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.594
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.108
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.144
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.210
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.380
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.238
TRAINING: | Iteration [7/12] | Loss 0.14 | Norm 2.877
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.071
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.292
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 1.715
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 1.214
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 2.985
Epoch: 1031/10000 | Epoch Time: 0.122 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.226
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 1.892
TRAINING: | Iteration [3/12] | Loss 0.16 | Norm 3.572
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.229
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.274
TRAINING: | Iteration [6/12] | Loss 0.17 | Norm 3.774
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 0.620
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.264
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 0.995
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.274
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 0.968
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.306
Epoch: 1032/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.419
TRAINING: | Iteration [2/12] | Loss 0.15 | Norm 2.601
TRAINING: | Iteration [3/12] | Loss 0.19 | Norm 4.350
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 1.419
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 2.771
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.717
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.610
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.063
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.101
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.230
TRAINING: | Iteration [11/12] | Loss 0.17 | Norm 3.225
TRAINING: | Iteration [12/12] | Loss 0.19 | Norm 4.077
Epoch: 1033/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 0.746
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 2.036
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 1.310
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.515
TRAINING: | Iteration [5/12] | Loss 0.14 | Norm 2.682
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 1.857
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.427
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.247
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.477
TRAINING: | Iteration [10/12] | Loss 0.15 | Norm 3.573
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.608
TRAINING: | Iteration [12/12] | Loss 0.24 | Norm 4.178
Epoch: 1034/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.482
TRAINING: | Iteration [2/12] | Loss 0.14 | Norm 2.719
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.433
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 1.438
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 2.852
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 0.984
TRAINING: | Iteration [7/12] | Loss 0.14 | Norm 3.296
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 3.359
TRAINING: | Iteration [9/12] | Loss 0.14 | Norm 2.385
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.067
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 1.024
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.892
Epoch: 1035/10000 | Epoch Time: 0.115 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 2.363
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 0.830
TRAINING: | Iteration [3/12] | Loss 0.15 | Norm 2.476
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.080
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 0.666
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.035
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 2.211
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 2.645
TRAINING: | Iteration [9/12] | Loss 0.23 | Norm 3.574
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.347
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.869
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 2.176
Epoch: 1036/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.131
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.239
TRAINING: | Iteration [3/12] | Loss 0.17 | Norm 2.803
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.878
TRAINING: | Iteration [5/12] | Loss 0.21 | Norm 3.029
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 2.071
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.358
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.063
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 1.936
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.679
TRAINING: | Iteration [11/12] | Loss 0.28 | Norm 4.398
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 2.709
Epoch: 1037/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 3.117
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.998
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.629
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.987
TRAINING: | Iteration [5/12] | Loss 0.14 | Norm 4.230
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 4.000
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 2.045
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.595
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.303
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 3.018
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.585
TRAINING: | Iteration [12/12] | Loss 0.38 | Norm 5.000
Epoch: 1038/10000 | Epoch Time: 0.100 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.772
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.114
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 3.507
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.454
TRAINING: | Iteration [5/12] | Loss 0.22 | Norm 3.872
TRAINING: | Iteration [6/12] | Loss 0.14 | Norm 2.847
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 3.293
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.538
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.240
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.196
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.340
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.911
Epoch: 1039/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.20 | Norm 3.195
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 0.785
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.840
TRAINING: | Iteration [4/12] | Loss 0.14 | Norm 4.790
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.100
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.348
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.751
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 4.886
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.640
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 3.014
TRAINING: | Iteration [11/12] | Loss 0.14 | Norm 3.017
TRAINING: | Iteration [12/12] | Loss 0.19 | Norm 3.430
Epoch: 1040/10000 | Epoch Time: 0.104 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 3.112
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.745
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.120
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 2.568
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.195
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.585
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.405
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.745
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.462
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 2.508
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.497
TRAINING: | Iteration [12/12] | Loss 0.17 | Norm 4.881
Epoch: 1041/10000 | Epoch Time: 0.118 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.037
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.110
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 2.467
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 2.309
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.859
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 3.716
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 3.618
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 1.730
TRAINING: | Iteration [9/12] | Loss 0.31 | Norm 4.834
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.790
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 3.604
TRAINING: | Iteration [12/12] | Loss 0.18 | Norm 4.099
Epoch: 1042/10000 | Epoch Time: 0.116 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.722
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.652
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.219
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 2.261
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 1.806
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 3.010
TRAINING: | Iteration [7/12] | Loss 0.16 | Norm 2.429
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 1.216
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.026
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 3.318
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 3.248
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 1.411
Epoch: 1043/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.22 | Norm 3.358
TRAINING: | Iteration [2/12] | Loss 0.17 | Norm 3.074
TRAINING: | Iteration [3/12] | Loss 0.14 | Norm 2.096
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 1.973
TRAINING: | Iteration [5/12] | Loss 0.17 | Norm 3.374
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.830
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.550
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.464
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.307
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 3.844
TRAINING: | Iteration [11/12] | Loss 0.40 | Norm 5.000
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.345
Epoch: 1044/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 3.139
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.379
TRAINING: | Iteration [3/12] | Loss 0.15 | Norm 2.551
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.961
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 2.155
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 1.374
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.689
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.352
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 1.983
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 2.913
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 2.336
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.452
Epoch: 1045/10000 | Epoch Time: 0.105 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 0.972
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 1.501
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.360
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 1.608
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.676
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.448
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.533
TRAINING: | Iteration [8/12] | Loss 0.16 | Norm 3.135
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 0.588
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 0.745
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.123
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 3.638
Epoch: 1046/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 3.086
TRAINING: | Iteration [2/12] | Loss 0.18 | Norm 2.997
TRAINING: | Iteration [3/12] | Loss 0.35 | Norm 4.655
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 2.259
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 2.245
TRAINING: | Iteration [6/12] | Loss 0.14 | Norm 3.149
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 3.013
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 1.874
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.885
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.235
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 1.893
TRAINING: | Iteration [12/12] | Loss 0.17 | Norm 2.919
Epoch: 1047/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.17 | Norm 4.017
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.063
TRAINING: | Iteration [3/12] | Loss 0.29 | Norm 4.252
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.571
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 2.511
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.058
TRAINING: | Iteration [7/12] | Loss 0.15 | Norm 2.813
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 2.192
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 3.858
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 1.082
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 1.272
TRAINING: | Iteration [12/12] | Loss 0.16 | Norm 2.880
Epoch: 1048/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.622
TRAINING: | Iteration [2/12] | Loss 0.14 | Norm 2.239
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 3.255
TRAINING: | Iteration [4/12] | Loss 0.15 | Norm 3.737
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.980
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 2.435
TRAINING: | Iteration [7/12] | Loss 0.15 | Norm 3.540
TRAINING: | Iteration [8/12] | Loss 0.18 | Norm 3.862
TRAINING: | Iteration [9/12] | Loss 0.26 | Norm 4.519
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.442
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 2.834
TRAINING: | Iteration [12/12] | Loss 0.32 | Norm 5.000
Epoch: 1049/10000 | Epoch Time: 0.105 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 1.507
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.469
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 0.953
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 2.149
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 0.773
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 0.815
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 2.180
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 2.431
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 2.308
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.125
TRAINING: | Iteration [11/12] | Loss 0.18 | Norm 3.028
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 1.146
Epoch: 1050/10000 | Epoch Time: 0.105 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.518
TRAINING: | Iteration [2/12] | Loss 0.14 | Norm 2.832
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.165
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.007
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 0.626
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 2.432
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.467
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.313
TRAINING: | Iteration [9/12] | Loss 0.14 | Norm 3.130
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 2.649
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 3.654
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 3.448
Epoch: 1051/10000 | Epoch Time: 0.106 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 0.956
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.116
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 1.714
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 1.743
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.609
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.892
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.419
TRAINING: | Iteration [8/12] | Loss 0.19 | Norm 3.635
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 1.958
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.180
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 3.006
TRAINING: | Iteration [12/12] | Loss 0.31 | Norm 5.000
Epoch: 1052/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.15 | Norm 4.302
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 1.217
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.188
TRAINING: | Iteration [4/12] | Loss 0.21 | Norm 3.938
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 2.851
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 2.012
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 0.957
TRAINING: | Iteration [8/12] | Loss 0.24 | Norm 4.278
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 1.974
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 2.452
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 1.906
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.740
Epoch: 1053/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 0.717
TRAINING: | Iteration [2/12] | Loss 0.18 | Norm 3.506
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 1.410
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 1.778
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 2.135
TRAINING: | Iteration [6/12] | Loss 0.17 | Norm 3.374
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 0.888
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.318
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 2.294
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.954
TRAINING: | Iteration [11/12] | Loss 0.16 | Norm 2.812
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.485
Epoch: 1054/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.515
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.729
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 0.863
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 2.238
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 1.509
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 2.707
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 1.348
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 2.789
TRAINING: | Iteration [9/12] | Loss 0.15 | Norm 3.614
TRAINING: | Iteration [10/12] | Loss 0.16 | Norm 4.121
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.006
TRAINING: | Iteration [12/12] | Loss 0.17 | Norm 3.199
Epoch: 1055/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.603
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.325
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.102
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 1.763
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.799
TRAINING: | Iteration [6/12] | Loss 0.15 | Norm 4.483
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.469
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.068
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.148
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.138
TRAINING: | Iteration [11/12] | Loss 0.14 | Norm 3.553
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 0.736
Epoch: 1056/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.483
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 1.221
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 2.105
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.466
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 1.898
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.691
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 1.272
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.596
TRAINING: | Iteration [9/12] | Loss 0.16 | Norm 3.237
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.779
TRAINING: | Iteration [11/12] | Loss 0.14 | Norm 3.138
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 0.820
Epoch: 1057/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 3.101
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.259
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 0.790
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 1.871
TRAINING: | Iteration [5/12] | Loss 0.23 | Norm 4.059
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.759
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 1.879
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 0.912
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 0.840
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 2.272
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 1.702
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 2.013
Epoch: 1058/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.17 | Norm 3.506
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.690
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 1.837
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 2.590
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 1.465
TRAINING: | Iteration [6/12] | Loss 0.16 | Norm 3.225
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 2.061
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 0.987
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 0.444
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 1.631
TRAINING: | Iteration [11/12] | Loss 0.17 | Norm 2.985
TRAINING: | Iteration [12/12] | Loss 0.18 | Norm 3.647
Epoch: 1059/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.115
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 1.853
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 1.984
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.530
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.237
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 2.824
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.254
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 2.244
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.020
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.328
TRAINING: | Iteration [11/12] | Loss 0.33 | Norm 4.999
TRAINING: | Iteration [12/12] | Loss 0.24 | Norm 4.117
Epoch: 1060/10000 | Epoch Time: 0.106 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.568
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.543
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.302
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.001
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 2.965
TRAINING: | Iteration [6/12] | Loss 0.38 | Norm 5.000
TRAINING: | Iteration [7/12] | Loss 0.23 | Norm 4.002
TRAINING: | Iteration [8/12] | Loss 0.15 | Norm 3.006
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 0.875
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 2.873
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 1.553
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 1.393
Epoch: 1061/10000 | Epoch Time: 0.105 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 3.181
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 2.012
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.274
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 2.802
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 2.671
TRAINING: | Iteration [6/12] | Loss 0.15 | Norm 2.411
TRAINING: | Iteration [7/12] | Loss 0.14 | Norm 3.587
TRAINING: | Iteration [8/12] | Loss 0.15 | Norm 2.638
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.578
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 2.762
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.973
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 1.881
Epoch: 1062/10000 | Epoch Time: 0.105 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 3.225
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 1.257
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.384
TRAINING: | Iteration [4/12] | Loss 0.16 | Norm 3.005
TRAINING: | Iteration [5/12] | Loss 0.14 | Norm 2.923
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 1.824
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 2.579
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.834
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.744
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.478
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.588
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 2.160
Epoch: 1063/10000 | Epoch Time: 0.106 seconds
TRAINING: | Iteration [1/12] | Loss 0.17 | Norm 3.846
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.416
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.061
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 0.505
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.392
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 0.871
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 2.335
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.879
TRAINING: | Iteration [9/12] | Loss 0.14 | Norm 2.395
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.326
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 2.257
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.085
Epoch: 1064/10000 | Epoch Time: 0.105 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.808
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 2.570
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.068
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.580
TRAINING: | Iteration [5/12] | Loss 0.16 | Norm 4.530
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.568
TRAINING: | Iteration [7/12] | Loss 0.18 | Norm 4.071
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 2.318
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.945
TRAINING: | Iteration [10/12] | Loss 0.26 | Norm 4.340
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 2.840
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 3.292
Epoch: 1065/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.049
TRAINING: | Iteration [2/12] | Loss 0.14 | Norm 3.580
TRAINING: | Iteration [3/12] | Loss 0.16 | Norm 3.429
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 3.740
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 2.879
TRAINING: | Iteration [6/12] | Loss 0.18 | Norm 3.963
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 0.715
TRAINING: | Iteration [8/12] | Loss 0.15 | Norm 3.502
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 3.892
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 3.693
TRAINING: | Iteration [11/12] | Loss 0.27 | Norm 4.904
TRAINING: | Iteration [12/12] | Loss 0.16 | Norm 4.791
Epoch: 1066/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.011
TRAINING: | Iteration [2/12] | Loss 0.25 | Norm 4.132
TRAINING: | Iteration [3/12] | Loss 0.19 | Norm 2.910
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 2.676
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 0.681
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 0.735
TRAINING: | Iteration [7/12] | Loss 0.13 | Norm 1.944
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.633
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 1.781
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 1.334
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 0.993
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.196
Epoch: 1067/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.17 | Norm 3.109
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 2.214
TRAINING: | Iteration [3/12] | Loss 0.15 | Norm 3.000
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.739
TRAINING: | Iteration [5/12] | Loss 0.15 | Norm 2.188
TRAINING: | Iteration [6/12] | Loss 0.21 | Norm 4.009
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 1.448
TRAINING: | Iteration [8/12] | Loss 0.20 | Norm 4.291
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 2.966
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 1.498
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.341
TRAINING: | Iteration [12/12] | Loss 0.30 | Norm 4.845
Epoch: 1068/10000 | Epoch Time: 0.100 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.446
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 1.401
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 0.512
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.239
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 2.252
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 1.515
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.080
TRAINING: | Iteration [8/12] | Loss 0.16 | Norm 2.692
TRAINING: | Iteration [9/12] | Loss 0.05 | Norm 0.716
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.657
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 1.699
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.220
Epoch: 1069/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 2.586
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.046
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.722
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 0.704
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 2.793
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 2.864
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 1.049
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.190
TRAINING: | Iteration [9/12] | Loss 0.23 | Norm 4.501
TRAINING: | Iteration [10/12] | Loss 0.19 | Norm 3.764
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 1.946
TRAINING: | Iteration [12/12] | Loss 0.15 | Norm 2.243
Epoch: 1070/10000 | Epoch Time: 0.117 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.524
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 2.157
TRAINING: | Iteration [3/12] | Loss 0.26 | Norm 4.259
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 1.325
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 3.028
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.455
TRAINING: | Iteration [7/12] | Loss 0.14 | Norm 2.798
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.134
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.120
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 1.279
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 2.142
TRAINING: | Iteration [12/12] | Loss 0.15 | Norm 3.509
Epoch: 1071/10000 | Epoch Time: 0.105 seconds
TRAINING: | Iteration [1/12] | Loss 0.14 | Norm 3.352
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 2.344
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.270
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 1.592
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 1.686
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.803
TRAINING: | Iteration [7/12] | Loss 0.13 | Norm 1.765
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.178
TRAINING: | Iteration [9/12] | Loss 0.35 | Norm 4.925
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.078
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 1.767
TRAINING: | Iteration [12/12] | Loss 0.15 | Norm 2.949
Epoch: 1072/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.764
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.049
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.034
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 1.318
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 2.036
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.254
TRAINING: | Iteration [7/12] | Loss 0.14 | Norm 2.618
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.781
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 2.603
TRAINING: | Iteration [10/12] | Loss 0.20 | Norm 3.904
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.848
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 1.967
Epoch: 1073/10000 | Epoch Time: 0.100 seconds
TRAINING: | Iteration [1/12] | Loss 0.15 | Norm 2.221
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 3.030
TRAINING: | Iteration [3/12] | Loss 0.15 | Norm 2.813
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 2.639
TRAINING: | Iteration [5/12] | Loss 0.25 | Norm 4.408
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.010
TRAINING: | Iteration [7/12] | Loss 0.19 | Norm 3.610
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 3.441
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 2.234
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 1.120
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.023
TRAINING: | Iteration [12/12] | Loss 0.15 | Norm 3.206
Epoch: 1074/10000 | Epoch Time: 0.105 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.349
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.223
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 1.808
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 3.276
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.216
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 1.774
TRAINING: | Iteration [7/12] | Loss 0.15 | Norm 3.842
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 2.328
TRAINING: | Iteration [9/12] | Loss 0.17 | Norm 3.439
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 1.653
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.709
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 0.992
Epoch: 1075/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.447
TRAINING: | Iteration [2/12] | Loss 0.17 | Norm 3.586
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.484
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.957
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 2.164
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 1.964
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 1.989
TRAINING: | Iteration [8/12] | Loss 0.15 | Norm 2.943
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.446
TRAINING: | Iteration [10/12] | Loss 0.18 | Norm 3.300
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 2.274
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.568
Epoch: 1076/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 2.322
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 3.395
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.767
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.126
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 3.184
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 3.318
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 0.892
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.923
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 2.467
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 2.243
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 0.815
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.617
Epoch: 1077/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.199
TRAINING: | Iteration [2/12] | Loss 0.06 | Norm 0.659
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.393
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.155
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.665
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 2.196
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.062
TRAINING: | Iteration [8/12] | Loss 0.21 | Norm 4.502
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 1.891
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 0.803
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.540
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 3.164
Epoch: 1078/10000 | Epoch Time: 0.118 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.136
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 2.672
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.337
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 2.480
TRAINING: | Iteration [5/12] | Loss 0.17 | Norm 4.206
TRAINING: | Iteration [6/12] | Loss 0.14 | Norm 3.212
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 1.430
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 0.979
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.066
TRAINING: | Iteration [10/12] | Loss 0.20 | Norm 3.195
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.525
TRAINING: | Iteration [12/12] | Loss 0.17 | Norm 3.426
Epoch: 1079/10000 | Epoch Time: 0.100 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 1.941
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.272
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 1.845
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.266
TRAINING: | Iteration [5/12] | Loss 0.21 | Norm 3.994
TRAINING: | Iteration [6/12] | Loss 0.16 | Norm 4.437
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.757
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 0.985
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.175
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 3.915
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 1.791
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 2.712
Epoch: 1080/10000 | Epoch Time: 0.102 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 2.958
TRAINING: | Iteration [2/12] | Loss 0.20 | Norm 3.726
TRAINING: | Iteration [3/12] | Loss 0.19 | Norm 3.862
TRAINING: | Iteration [4/12] | Loss 0.25 | Norm 3.644
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.526
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 2.072
TRAINING: | Iteration [7/12] | Loss 0.15 | Norm 3.671
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.564
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 2.799
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.066
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.226
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 2.702
Epoch: 1081/10000 | Epoch Time: 0.106 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 0.905
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 2.756
TRAINING: | Iteration [3/12] | Loss 0.19 | Norm 2.991
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 2.677
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.496
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.393
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.688
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 2.326
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.951
TRAINING: | Iteration [10/12] | Loss 0.21 | Norm 2.574
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 1.817
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 2.670
Epoch: 1082/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.936
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.299
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 2.467
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 2.802
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.720
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.471
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.697
TRAINING: | Iteration [8/12] | Loss 0.15 | Norm 2.688
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.398
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 1.900
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 0.922
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.077
Epoch: 1083/10000 | Epoch Time: 0.107 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 0.540
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 1.770
TRAINING: | Iteration [3/12] | Loss 0.22 | Norm 2.995
TRAINING: | Iteration [4/12] | Loss 0.18 | Norm 3.904
TRAINING: | Iteration [5/12] | Loss 0.14 | Norm 3.034
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 0.733
TRAINING: | Iteration [7/12] | Loss 0.15 | Norm 2.722
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.974
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 2.494
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.096
TRAINING: | Iteration [11/12] | Loss 0.19 | Norm 4.082
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 1.822
Epoch: 1084/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.609
TRAINING: | Iteration [2/12] | Loss 0.16 | Norm 4.195
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 3.239
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.697
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.782
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.354
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.966
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 2.207
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 2.013
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 2.447
TRAINING: | Iteration [11/12] | Loss 0.14 | Norm 2.345
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 3.479
Epoch: 1085/10000 | Epoch Time: 0.119 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.839
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 1.212
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.487
TRAINING: | Iteration [4/12] | Loss 0.18 | Norm 3.278
TRAINING: | Iteration [5/12] | Loss 0.16 | Norm 3.271
TRAINING: | Iteration [6/12] | Loss 0.16 | Norm 2.906
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 1.750
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 0.796
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.132
TRAINING: | Iteration [10/12] | Loss 0.24 | Norm 3.648
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 2.395
TRAINING: | Iteration [12/12] | Loss 0.15 | Norm 3.203
Epoch: 1086/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.203
TRAINING: | Iteration [2/12] | Loss 0.15 | Norm 2.541
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.347
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 1.890
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 1.844
TRAINING: | Iteration [6/12] | Loss 0.15 | Norm 2.819
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.689
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 2.341
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.204
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.647
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.364
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 2.101
Epoch: 1087/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 0.907
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.144
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 1.895
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 2.097
TRAINING: | Iteration [5/12] | Loss 0.17 | Norm 3.364
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.023
TRAINING: | Iteration [7/12] | Loss 0.13 | Norm 1.867
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.544
TRAINING: | Iteration [9/12] | Loss 0.17 | Norm 3.379
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.065
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.047
TRAINING: | Iteration [12/12] | Loss 0.35 | Norm 5.000
Epoch: 1088/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.773
TRAINING: | Iteration [2/12] | Loss 0.22 | Norm 3.780
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.098
TRAINING: | Iteration [4/12] | Loss 0.14 | Norm 2.132
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 2.303
TRAINING: | Iteration [6/12] | Loss 0.14 | Norm 2.519
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 2.493
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.265
TRAINING: | Iteration [9/12] | Loss 0.14 | Norm 2.897
TRAINING: | Iteration [10/12] | Loss 0.18 | Norm 3.269
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 2.237
TRAINING: | Iteration [12/12] | Loss 0.17 | Norm 4.014
Epoch: 1089/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 0.987
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 2.522
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.657
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.473
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.206
TRAINING: | Iteration [6/12] | Loss 0.33 | Norm 5.000
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 1.543
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 3.068
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.693
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 3.013
TRAINING: | Iteration [11/12] | Loss 0.19 | Norm 3.410
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.591
Epoch: 1090/10000 | Epoch Time: 0.101 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.487
TRAINING: | Iteration [2/12] | Loss 0.14 | Norm 3.142
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 2.827
TRAINING: | Iteration [4/12] | Loss 0.14 | Norm 2.766
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 0.660
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 2.121
TRAINING: | Iteration [7/12] | Loss 0.27 | Norm 4.726
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 1.892
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.365
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.711
TRAINING: | Iteration [11/12] | Loss 0.14 | Norm 2.997
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 1.727
Epoch: 1091/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 0.987
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.751
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 3.099
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.038
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 2.303
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.701
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.363
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.487
TRAINING: | Iteration [9/12] | Loss 0.18 | Norm 3.559
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 1.435
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 2.685
TRAINING: | Iteration [12/12] | Loss 0.25 | Norm 4.363
Epoch: 1092/10000 | Epoch Time: 0.116 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 1.405
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 1.535
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 1.788
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.659
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 1.648
TRAINING: | Iteration [6/12] | Loss 0.24 | Norm 3.922
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 1.719
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 0.699
TRAINING: | Iteration [9/12] | Loss 0.15 | Norm 2.296
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.647
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.202
TRAINING: | Iteration [12/12] | Loss 0.20 | Norm 3.160
Epoch: 1093/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 1.967
TRAINING: | Iteration [2/12] | Loss 0.24 | Norm 4.600
TRAINING: | Iteration [3/12] | Loss 0.18 | Norm 3.797
TRAINING: | Iteration [4/12] | Loss 0.34 | Norm 4.884
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 1.723
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 2.821
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 0.988
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.475
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 1.725
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 2.095
TRAINING: | Iteration [11/12] | Loss 0.15 | Norm 2.854
TRAINING: | Iteration [12/12] | Loss 0.25 | Norm 4.550
Epoch: 1094/10000 | Epoch Time: 0.116 seconds
TRAINING: | Iteration [1/12] | Loss 0.17 | Norm 3.427
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 2.433
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.616
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.247
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.564
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.233
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 1.726
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 2.723
TRAINING: | Iteration [9/12] | Loss 0.15 | Norm 3.054
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 1.756
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.565
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 2.636
Epoch: 1095/10000 | Epoch Time: 0.117 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 1.971
TRAINING: | Iteration [2/12] | Loss 0.15 | Norm 2.763
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 1.694
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 1.405
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 1.665
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 1.803
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 1.870
TRAINING: | Iteration [8/12] | Loss 0.27 | Norm 4.053
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 1.003
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.069
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 1.869
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.486
Epoch: 1096/10000 | Epoch Time: 0.117 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.744
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 1.654
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.634
TRAINING: | Iteration [4/12] | Loss 0.30 | Norm 4.151
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.274
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.556
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 2.447
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.555
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 2.520
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 2.150
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 1.192
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.377
Epoch: 1097/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 3.858
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 1.964
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 3.162
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 3.815
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.243
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.868
TRAINING: | Iteration [7/12] | Loss 0.16 | Norm 3.510
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 2.064
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 1.914
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 2.307
TRAINING: | Iteration [11/12] | Loss 0.42 | Norm 5.000
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.440
Epoch: 1098/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.16 | Norm 2.719
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.606
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.449
TRAINING: | Iteration [4/12] | Loss 0.18 | Norm 4.478
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.605
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 2.345
TRAINING: | Iteration [7/12] | Loss 0.22 | Norm 4.007
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.123
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 3.458
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 2.905
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 1.957
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 3.073
Epoch: 1099/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 1.921
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 3.117
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.364
TRAINING: | Iteration [4/12] | Loss 0.05 | Norm 1.131
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.387
TRAINING: | Iteration [6/12] | Loss 0.15 | Norm 5.000
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 3.975
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 3.149
TRAINING: | Iteration [9/12] | Loss 0.14 | Norm 2.955
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 3.904
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.363
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 2.319
Epoch: 1100/10000 | Epoch Time: 0.104 seconds
Saving Model
Preparation of Training Data time: 26.435 seconds
TRAINING: | Iteration [1/12] | Loss 0.14 | Norm 3.246
TRAINING: | Iteration [2/12] | Loss 0.16 | Norm 3.925
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.647
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.414
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.315
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 1.862
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 0.876
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 2.488
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.418
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 2.560
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 2.075
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.228
Epoch: 1101/10000 | Epoch Time: 0.120 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 3.275
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 2.309
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.064
TRAINING: | Iteration [4/12] | Loss 0.17 | Norm 3.296
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 1.599
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 3.532
TRAINING: | Iteration [7/12] | Loss 0.16 | Norm 2.943
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 3.452
TRAINING: | Iteration [9/12] | Loss 0.29 | Norm 5.000
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.743
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 3.420
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 2.738
Epoch: 1102/10000 | Epoch Time: 0.106 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 4.045
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 2.137
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.948
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 3.078
TRAINING: | Iteration [5/12] | Loss 0.06 | Norm 1.016
TRAINING: | Iteration [6/12] | Loss 0.14 | Norm 2.534
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 3.099
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.571
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.563
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 1.613
TRAINING: | Iteration [11/12] | Loss 0.06 | Norm 1.030
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 2.789
Epoch: 1103/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.792
TRAINING: | Iteration [2/12] | Loss 0.15 | Norm 2.793
TRAINING: | Iteration [3/12] | Loss 0.18 | Norm 3.286
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 1.142
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 2.286
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.440
TRAINING: | Iteration [7/12] | Loss 0.14 | Norm 1.856
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 0.961
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 3.113
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.165
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 1.783
TRAINING: | Iteration [12/12] | Loss 0.15 | Norm 3.890
Epoch: 1104/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.14 | Norm 1.833
TRAINING: | Iteration [2/12] | Loss 0.14 | Norm 2.737
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 3.788
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 1.771
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.360
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 1.980
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 2.481
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 2.797
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 0.885
TRAINING: | Iteration [10/12] | Loss 0.15 | Norm 1.912
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.175
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 2.763
Epoch: 1105/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.15 | Norm 3.312
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 2.823
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.536
TRAINING: | Iteration [4/12] | Loss 0.16 | Norm 3.067
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.324
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.954
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.745
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.631
TRAINING: | Iteration [9/12] | Loss 0.15 | Norm 3.524
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 0.782
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 1.402
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 2.684
Epoch: 1106/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.764
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.695
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.550
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 2.106
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.811
TRAINING: | Iteration [6/12] | Loss 0.18 | Norm 4.273
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.411
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 2.573
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.732
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.995
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.145
TRAINING: | Iteration [12/12] | Loss 0.19 | Norm 4.074
Epoch: 1107/10000 | Epoch Time: 0.117 seconds
TRAINING: | Iteration [1/12] | Loss 0.14 | Norm 2.469
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 3.273
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 2.924
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 2.598
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 2.567
TRAINING: | Iteration [6/12] | Loss 0.15 | Norm 3.583
TRAINING: | Iteration [7/12] | Loss 0.24 | Norm 3.927
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 3.129
TRAINING: | Iteration [9/12] | Loss 0.18 | Norm 3.074
TRAINING: | Iteration [10/12] | Loss 0.19 | Norm 3.785
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.233
TRAINING: | Iteration [12/12] | Loss 0.22 | Norm 4.223
Epoch: 1108/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.14 | Norm 2.727
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.913
TRAINING: | Iteration [3/12] | Loss 0.18 | Norm 4.777
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 0.747
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 0.817
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 2.598
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.069
TRAINING: | Iteration [8/12] | Loss 0.15 | Norm 3.598
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 1.887
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 3.282
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 2.070
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 4.711
Epoch: 1109/10000 | Epoch Time: 0.099 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 0.921
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.437
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.089
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.594
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 2.759
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 2.392
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 3.277
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.674
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 2.874
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.324
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 1.758
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.463
Epoch: 1110/10000 | Epoch Time: 0.102 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.15 | Norm 2.138
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.795
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.620
TRAINING: | Iteration [4/12] | Loss 0.21 | Norm 3.177
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 0.940
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.111
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 2.277
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 3.501
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 1.730
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.247
TRAINING: | Iteration [11/12] | Loss 0.14 | Norm 3.193
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.916
Epoch: 1111/10000 | Epoch Time: 0.106 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.764
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.973
TRAINING: | Iteration [3/12] | Loss 0.16 | Norm 2.609
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 2.839
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 2.607
TRAINING: | Iteration [6/12] | Loss 0.15 | Norm 4.501
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 1.793
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 3.164
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 3.739
TRAINING: | Iteration [10/12] | Loss 0.17 | Norm 4.876
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 2.434
TRAINING: | Iteration [12/12] | Loss 0.22 | Norm 3.806
Epoch: 1112/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.14 | Norm 2.429
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 3.109
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 2.300
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 3.719
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 1.986
TRAINING: | Iteration [6/12] | Loss 0.28 | Norm 4.611
TRAINING: | Iteration [7/12] | Loss 0.36 | Norm 5.000
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.952
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 3.672
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.503
TRAINING: | Iteration [11/12] | Loss 0.16 | Norm 3.894
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.796
Epoch: 1113/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.16 | Norm 3.598
TRAINING: | Iteration [2/12] | Loss 0.23 | Norm 3.698
TRAINING: | Iteration [3/12] | Loss 0.15 | Norm 2.824
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.869
TRAINING: | Iteration [5/12] | Loss 0.15 | Norm 2.870
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.326
TRAINING: | Iteration [7/12] | Loss 0.35 | Norm 5.000
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.584
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 1.760
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 1.928
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 1.997
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 2.667
Epoch: 1114/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.735
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.297
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 0.874
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 1.989
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.654
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 1.727
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 1.711
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 3.010
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.346
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 3.267
TRAINING: | Iteration [11/12] | Loss 0.15 | Norm 3.473
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.018
Epoch: 1115/10000 | Epoch Time: 0.116 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 2.125
TRAINING: | Iteration [2/12] | Loss 0.25 | Norm 3.867
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 1.489
TRAINING: | Iteration [4/12] | Loss 0.20 | Norm 5.000
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 1.601
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 2.019
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 3.385
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 3.227
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.286
TRAINING: | Iteration [10/12] | Loss 0.05 | Norm 0.738
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.463
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 1.815
Epoch: 1116/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.380
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 1.178
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.513
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 1.565
TRAINING: | Iteration [5/12] | Loss 0.14 | Norm 2.085
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 2.772
TRAINING: | Iteration [7/12] | Loss 0.21 | Norm 4.879
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 0.742
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 3.490
TRAINING: | Iteration [10/12] | Loss 0.16 | Norm 3.223
TRAINING: | Iteration [11/12] | Loss 0.17 | Norm 3.691
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.924
Epoch: 1117/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.476
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.006
TRAINING: | Iteration [3/12] | Loss 0.15 | Norm 1.986
TRAINING: | Iteration [4/12] | Loss 0.16 | Norm 3.460
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 5.000
TRAINING: | Iteration [6/12] | Loss 0.18 | Norm 3.437
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.224
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.877
TRAINING: | Iteration [9/12] | Loss 0.15 | Norm 2.602
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.012
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 4.173
TRAINING: | Iteration [12/12] | Loss 0.22 | Norm 4.509
Epoch: 1118/10000 | Epoch Time: 0.115 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.804
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.399
TRAINING: | Iteration [3/12] | Loss 0.20 | Norm 4.018
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 3.548
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.170
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 1.916
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 2.437
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 2.691
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.092
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 2.012
TRAINING: | Iteration [11/12] | Loss 0.21 | Norm 4.290
TRAINING: | Iteration [12/12] | Loss 0.06 | Norm 0.755
Epoch: 1119/10000 | Epoch Time: 0.114 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 2.533
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 1.950
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 2.313
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 1.551
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 0.959
TRAINING: | Iteration [6/12] | Loss 0.30 | Norm 4.152
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 3.656
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 2.394
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 1.610
TRAINING: | Iteration [10/12] | Loss 0.40 | Norm 5.000
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.651
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 1.556
Epoch: 1120/10000 | Epoch Time: 0.101 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.26 | Norm 4.496
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 1.518
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.400
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.520
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.150
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 1.799
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.460
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 2.286
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.329
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 0.852
TRAINING: | Iteration [11/12] | Loss 0.22 | Norm 4.020
TRAINING: | Iteration [12/12] | Loss 0.18 | Norm 3.445
Epoch: 1121/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.338
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.335
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 2.118
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 0.971
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 1.268
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 2.985
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.563
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 2.033
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.337
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 2.914
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 3.262
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 2.792
Epoch: 1122/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 2.079
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 0.983
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.048
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.560
TRAINING: | Iteration [5/12] | Loss 0.14 | Norm 3.395
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.909
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 1.973
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.253
TRAINING: | Iteration [9/12] | Loss 0.18 | Norm 3.698
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 2.708
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 2.732
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 3.092
Epoch: 1123/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.053
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 0.732
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 1.233
TRAINING: | Iteration [4/12] | Loss 0.18 | Norm 2.963
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 1.754
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 1.308
TRAINING: | Iteration [7/12] | Loss 0.15 | Norm 2.713
TRAINING: | Iteration [8/12] | Loss 0.16 | Norm 3.633
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.110
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 2.317
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 2.296
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 3.794
Epoch: 1124/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.16 | Norm 3.023
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 2.416
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 2.066
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.621
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 4.919
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.660
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 3.098
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 2.610
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 4.515
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 2.829
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 3.069
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 2.537
Epoch: 1125/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 2.771
TRAINING: | Iteration [2/12] | Loss 0.14 | Norm 3.650
TRAINING: | Iteration [3/12] | Loss 0.16 | Norm 3.326
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 2.798
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.775
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 1.007
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 2.643
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.314
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.796
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 3.899
TRAINING: | Iteration [11/12] | Loss 0.16 | Norm 3.501
TRAINING: | Iteration [12/12] | Loss 0.61 | Norm 5.000
Epoch: 1126/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 0.731
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 1.546
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.135
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.607
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 1.091
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 0.810
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 1.819
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 2.690
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.702
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 1.782
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 1.414
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.622
Epoch: 1127/10000 | Epoch Time: 0.100 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.437
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 1.706
TRAINING: | Iteration [3/12] | Loss 0.14 | Norm 2.620
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 2.671
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.014
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 2.679
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.758
TRAINING: | Iteration [8/12] | Loss 0.18 | Norm 3.433
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 1.060
TRAINING: | Iteration [10/12] | Loss 0.15 | Norm 3.713
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 1.218
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 1.606
Epoch: 1128/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 2.254
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.178
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.970
TRAINING: | Iteration [4/12] | Loss 0.19 | Norm 4.750
TRAINING: | Iteration [5/12] | Loss 0.20 | Norm 3.414
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 2.565
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.248
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 4.117
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 2.539
TRAINING: | Iteration [10/12] | Loss 0.42 | Norm 5.000
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 2.428
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.926
Epoch: 1129/10000 | Epoch Time: 0.105 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 2.640
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 4.276
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 3.277
TRAINING: | Iteration [4/12] | Loss 0.24 | Norm 4.413
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.072
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.567
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 3.161
TRAINING: | Iteration [8/12] | Loss 0.17 | Norm 5.000
TRAINING: | Iteration [9/12] | Loss 0.14 | Norm 3.174
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 2.967
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.037
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 1.725
Epoch: 1130/10000 | Epoch Time: 0.103 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.14 | Norm 2.880
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 3.208
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 3.331
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 2.445
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 1.851
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 2.017
TRAINING: | Iteration [7/12] | Loss 0.13 | Norm 3.865
TRAINING: | Iteration [8/12] | Loss 0.24 | Norm 5.000
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.828
TRAINING: | Iteration [10/12] | Loss 0.27 | Norm 4.661
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 2.879
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.287
Epoch: 1131/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 3.158
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 3.442
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.397
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.084
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 0.781
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.760
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.681
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.830
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 2.996
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 3.170
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.987
TRAINING: | Iteration [12/12] | Loss 0.25 | Norm 4.275
Epoch: 1132/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.196
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 3.139
TRAINING: | Iteration [3/12] | Loss 0.17 | Norm 2.808
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 2.663
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.819
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 0.978
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 1.429
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 4.543
TRAINING: | Iteration [9/12] | Loss 0.14 | Norm 2.602
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.232
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.484
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.055
Epoch: 1133/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.885
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.019
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 1.714
TRAINING: | Iteration [4/12] | Loss 0.28 | Norm 4.299
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 0.620
TRAINING: | Iteration [6/12] | Loss 0.17 | Norm 3.585
TRAINING: | Iteration [7/12] | Loss 0.17 | Norm 3.009
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 1.586
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 1.909
TRAINING: | Iteration [10/12] | Loss 0.18 | Norm 4.834
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 2.133
TRAINING: | Iteration [12/12] | Loss 0.17 | Norm 3.423
Epoch: 1134/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.905
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.737
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 0.894
TRAINING: | Iteration [4/12] | Loss 0.14 | Norm 2.014
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 1.702
TRAINING: | Iteration [6/12] | Loss 0.20 | Norm 3.387
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.325
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.534
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.729
TRAINING: | Iteration [10/12] | Loss 0.16 | Norm 3.650
TRAINING: | Iteration [11/12] | Loss 0.15 | Norm 3.103
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 3.304
Epoch: 1135/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.415
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.673
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.081
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 2.246
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.894
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 1.384
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.049
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.794
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.209
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 0.938
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 1.018
TRAINING: | Iteration [12/12] | Loss 0.17 | Norm 3.332
Epoch: 1136/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.801
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.480
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 1.317
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.824
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 2.734
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 0.878
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.262
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.279
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.174
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.918
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.413
TRAINING: | Iteration [12/12] | Loss 0.28 | Norm 4.755
Epoch: 1137/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.15 | Norm 2.008
TRAINING: | Iteration [2/12] | Loss 0.24 | Norm 4.325
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.776
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.928
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 3.285
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 4.858
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 1.483
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.982
TRAINING: | Iteration [9/12] | Loss 0.17 | Norm 4.411
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 2.735
TRAINING: | Iteration [11/12] | Loss 0.18 | Norm 5.000
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 1.430
Epoch: 1138/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.312
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 3.351
TRAINING: | Iteration [3/12] | Loss 0.23 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 3.987
TRAINING: | Iteration [5/12] | Loss 0.14 | Norm 3.422
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 0.876
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 2.322
TRAINING: | Iteration [8/12] | Loss 0.15 | Norm 2.708
TRAINING: | Iteration [9/12] | Loss 0.16 | Norm 4.662
TRAINING: | Iteration [10/12] | Loss 0.16 | Norm 4.859
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 2.596
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 2.863
Epoch: 1139/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 2.829
TRAINING: | Iteration [2/12] | Loss 0.17 | Norm 3.125
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.758
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 2.450
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 2.607
TRAINING: | Iteration [6/12] | Loss 0.15 | Norm 2.628
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.084
TRAINING: | Iteration [8/12] | Loss 0.22 | Norm 3.290
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 1.990
TRAINING: | Iteration [10/12] | Loss 0.33 | Norm 5.000
TRAINING: | Iteration [11/12] | Loss 0.14 | Norm 5.000
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 3.067
Epoch: 1140/10000 | Epoch Time: 0.118 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.27 | Norm 4.579
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 2.576
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 2.671
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 3.335
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 2.791
TRAINING: | Iteration [6/12] | Loss 0.15 | Norm 2.585
TRAINING: | Iteration [7/12] | Loss 0.25 | Norm 4.553
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 1.633
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 2.519
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 2.386
TRAINING: | Iteration [11/12] | Loss 0.23 | Norm 3.858
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.065
Epoch: 1141/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.16 | Norm 2.834
TRAINING: | Iteration [2/12] | Loss 0.14 | Norm 2.757
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 2.219
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 1.481
TRAINING: | Iteration [5/12] | Loss 0.14 | Norm 2.695
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 2.812
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 1.378
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.152
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 2.115
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.128
TRAINING: | Iteration [11/12] | Loss 0.19 | Norm 2.860
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.606
Epoch: 1142/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 0.891
TRAINING: | Iteration [2/12] | Loss 0.14 | Norm 2.754
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.632
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 2.088
TRAINING: | Iteration [5/12] | Loss 0.17 | Norm 2.592
TRAINING: | Iteration [6/12] | Loss 0.14 | Norm 2.455
TRAINING: | Iteration [7/12] | Loss 0.21 | Norm 3.528
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 0.926
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.258
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.082
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 1.510
TRAINING: | Iteration [12/12] | Loss 0.30 | Norm 4.294
Epoch: 1143/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.29 | Norm 4.394
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 0.933
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.850
TRAINING: | Iteration [4/12] | Loss 0.22 | Norm 3.842
TRAINING: | Iteration [5/12] | Loss 0.16 | Norm 3.064
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 1.994
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.527
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 3.075
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 1.543
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 0.747
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 2.333
TRAINING: | Iteration [12/12] | Loss 0.45 | Norm 5.000
Epoch: 1144/10000 | Epoch Time: 0.116 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 0.663
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 2.319
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 1.313
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 0.873
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.186
TRAINING: | Iteration [6/12] | Loss 0.16 | Norm 2.656
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 1.663
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 2.179
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 1.256
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.359
TRAINING: | Iteration [11/12] | Loss 0.18 | Norm 3.048
TRAINING: | Iteration [12/12] | Loss 0.62 | Norm 5.000
Epoch: 1145/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.152
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.312
TRAINING: | Iteration [3/12] | Loss 0.45 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 0.15 | Norm 1.982
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 1.668
TRAINING: | Iteration [6/12] | Loss 0.36 | Norm 5.000
TRAINING: | Iteration [7/12] | Loss 0.13 | Norm 3.163
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.530
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 1.441
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 2.499
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 1.085
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 2.695
Epoch: 1146/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 0.923
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.692
TRAINING: | Iteration [3/12] | Loss 0.35 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 2.057
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 1.798
TRAINING: | Iteration [6/12] | Loss 0.30 | Norm 5.000
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 0.827
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.166
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 1.895
TRAINING: | Iteration [10/12] | Loss 0.15 | Norm 2.354
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 2.905
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 2.069
Epoch: 1147/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.217
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 1.739
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.187
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 2.243
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 2.155
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 2.072
TRAINING: | Iteration [7/12] | Loss 0.06 | Norm 1.238
TRAINING: | Iteration [8/12] | Loss 0.06 | Norm 0.621
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 2.132
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 1.002
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.416
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 2.021
Epoch: 1148/10000 | Epoch Time: 0.116 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 0.811
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.486
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.003
TRAINING: | Iteration [4/12] | Loss 0.24 | Norm 4.062
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 0.989
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 1.666
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 0.549
TRAINING: | Iteration [8/12] | Loss 0.16 | Norm 2.764
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 0.939
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.257
TRAINING: | Iteration [11/12] | Loss 0.14 | Norm 2.852
TRAINING: | Iteration [12/12] | Loss 0.15 | Norm 2.401
Epoch: 1149/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.342
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 0.941
TRAINING: | Iteration [3/12] | Loss 0.16 | Norm 3.257
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 2.930
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 1.659
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 0.777
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 1.602
TRAINING: | Iteration [8/12] | Loss 0.16 | Norm 3.007
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 1.289
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 1.646
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 2.717
TRAINING: | Iteration [12/12] | Loss 0.16 | Norm 4.144
Epoch: 1150/10000 | Epoch Time: 0.103 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 2.316
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 1.628
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.849
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 2.477
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.516
TRAINING: | Iteration [6/12] | Loss 0.14 | Norm 2.281
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.658
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.697
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.657
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 1.722
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 2.032
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.569
Epoch: 1151/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 1.862
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 1.768
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.782
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 1.695
TRAINING: | Iteration [5/12] | Loss 0.21 | Norm 3.651
TRAINING: | Iteration [6/12] | Loss 0.15 | Norm 2.047
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.898
TRAINING: | Iteration [8/12] | Loss 0.19 | Norm 3.726
TRAINING: | Iteration [9/12] | Loss 0.23 | Norm 4.645
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 1.118
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 1.048
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.183
Epoch: 1152/10000 | Epoch Time: 0.100 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 2.226
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 1.832
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 1.120
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.254
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 1.733
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 2.369
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 1.463
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.071
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.203
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.772
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.365
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.625
Epoch: 1153/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.545
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.522
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 3.148
TRAINING: | Iteration [4/12] | Loss 0.16 | Norm 4.349
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.143
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 2.006
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 2.857
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.638
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 2.230
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.739
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 2.234
TRAINING: | Iteration [12/12] | Loss 0.15 | Norm 3.005
Epoch: 1154/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 1.749
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 2.394
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 0.793
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.173
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 2.608
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 2.724
TRAINING: | Iteration [7/12] | Loss 0.13 | Norm 3.010
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.053
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 1.838
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 1.884
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 2.138
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.637
Epoch: 1155/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.414
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 1.674
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.354
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 2.089
TRAINING: | Iteration [5/12] | Loss 0.14 | Norm 2.135
TRAINING: | Iteration [6/12] | Loss 0.14 | Norm 2.462
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 0.906
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.259
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 2.171
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 1.873
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 1.212
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 3.783
Epoch: 1156/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 2.546
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 1.725
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.816
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 3.519
TRAINING: | Iteration [5/12] | Loss 0.19 | Norm 4.335
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.169
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.704
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.806
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 2.841
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 2.572
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 3.626
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.153
Epoch: 1157/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.578
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 2.284
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 3.963
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 2.702
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 3.465
TRAINING: | Iteration [6/12] | Loss 0.33 | Norm 4.978
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.824
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 2.830
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 3.825
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 2.168
TRAINING: | Iteration [11/12] | Loss 0.21 | Norm 2.929
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 1.850
Epoch: 1158/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 3.720
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.343
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 3.085
TRAINING: | Iteration [4/12] | Loss 0.14 | Norm 2.913
TRAINING: | Iteration [5/12] | Loss 0.15 | Norm 3.867
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.452
TRAINING: | Iteration [7/12] | Loss 0.15 | Norm 5.000
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.765
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 2.205
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 1.698
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 1.935
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 2.334
Epoch: 1159/10000 | Epoch Time: 0.100 seconds
TRAINING: | Iteration [1/12] | Loss 0.16 | Norm 3.541
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 3.358
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 1.748
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 1.576
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 2.097
TRAINING: | Iteration [6/12] | Loss 0.14 | Norm 2.899
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.790
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.263
TRAINING: | Iteration [9/12] | Loss 0.14 | Norm 2.078
TRAINING: | Iteration [10/12] | Loss 0.17 | Norm 3.635
TRAINING: | Iteration [11/12] | Loss 0.26 | Norm 5.000
TRAINING: | Iteration [12/12] | Loss 0.25 | Norm 5.000
Epoch: 1160/10000 | Epoch Time: 0.101 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.27 | Norm 4.140
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.080
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.008
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 2.260
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.176
TRAINING: | Iteration [6/12] | Loss 0.17 | Norm 2.885
TRAINING: | Iteration [7/12] | Loss 0.27 | Norm 4.896
TRAINING: | Iteration [8/12] | Loss 0.15 | Norm 4.236
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 2.175
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.238
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 2.443
TRAINING: | Iteration [12/12] | Loss 0.16 | Norm 3.239
Epoch: 1161/10000 | Epoch Time: 0.105 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.865
TRAINING: | Iteration [2/12] | Loss 0.15 | Norm 3.364
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 2.686
TRAINING: | Iteration [4/12] | Loss 0.15 | Norm 3.125
TRAINING: | Iteration [5/12] | Loss 0.18 | Norm 3.631
TRAINING: | Iteration [6/12] | Loss 0.25 | Norm 4.248
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 1.671
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 2.481
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 1.754
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 4.260
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 2.525
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 3.543
Epoch: 1162/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.108
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.329
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 0.603
TRAINING: | Iteration [4/12] | Loss 0.20 | Norm 4.533
TRAINING: | Iteration [5/12] | Loss 0.20 | Norm 3.478
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 2.308
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 3.316
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 1.925
TRAINING: | Iteration [9/12] | Loss 0.14 | Norm 1.271
TRAINING: | Iteration [10/12] | Loss 0.18 | Norm 3.596
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 1.740
TRAINING: | Iteration [12/12] | Loss 0.24 | Norm 4.190
Epoch: 1163/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.35 | Norm 5.000
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 1.491
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 3.242
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.255
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.361
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 2.125
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 2.082
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 1.125
TRAINING: | Iteration [9/12] | Loss 0.33 | Norm 5.000
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 2.754
TRAINING: | Iteration [11/12] | Loss 0.16 | Norm 3.274
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 2.504
Epoch: 1164/10000 | Epoch Time: 0.114 seconds
TRAINING: | Iteration [1/12] | Loss 0.15 | Norm 4.448
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.522
TRAINING: | Iteration [3/12] | Loss 0.05 | Norm 2.037
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.367
TRAINING: | Iteration [5/12] | Loss 0.19 | Norm 3.447
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 0.719
TRAINING: | Iteration [7/12] | Loss 0.37 | Norm 5.000
TRAINING: | Iteration [8/12] | Loss 0.20 | Norm 2.961
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 3.061
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 0.947
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 2.977
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 3.007
Epoch: 1165/10000 | Epoch Time: 0.119 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 1.981
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 1.942
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.859
TRAINING: | Iteration [4/12] | Loss 0.15 | Norm 3.670
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 2.388
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.395
TRAINING: | Iteration [7/12] | Loss 0.13 | Norm 2.907
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 2.417
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.692
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 1.609
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 1.851
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.383
Epoch: 1166/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.745
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 1.780
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.685
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.157
TRAINING: | Iteration [5/12] | Loss 0.15 | Norm 2.684
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 2.245
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.189
TRAINING: | Iteration [8/12] | Loss 0.15 | Norm 2.086
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.262
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.931
TRAINING: | Iteration [11/12] | Loss 0.15 | Norm 3.080
TRAINING: | Iteration [12/12] | Loss 0.15 | Norm 3.090
Epoch: 1167/10000 | Epoch Time: 0.116 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 3.281
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.128
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 1.595
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.396
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.358
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 2.166
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 1.462
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.823
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 1.589
TRAINING: | Iteration [10/12] | Loss 0.20 | Norm 2.531
TRAINING: | Iteration [11/12] | Loss 0.19 | Norm 3.992
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.467
Epoch: 1168/10000 | Epoch Time: 0.113 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 1.956
TRAINING: | Iteration [2/12] | Loss 0.32 | Norm 5.000
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.348
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.203
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.592
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 2.729
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.610
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 2.468
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 0.748
TRAINING: | Iteration [10/12] | Loss 0.15 | Norm 2.901
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 2.103
TRAINING: | Iteration [12/12] | Loss 0.21 | Norm 4.224
Epoch: 1169/10000 | Epoch Time: 0.122 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 1.530
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 2.285
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.245
TRAINING: | Iteration [4/12] | Loss 0.17 | Norm 2.375
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.640
TRAINING: | Iteration [6/12] | Loss 0.26 | Norm 4.441
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 2.280
TRAINING: | Iteration [8/12] | Loss 0.16 | Norm 3.260
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.412
TRAINING: | Iteration [10/12] | Loss 0.15 | Norm 3.111
TRAINING: | Iteration [11/12] | Loss 0.30 | Norm 5.000
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 1.484
Epoch: 1170/10000 | Epoch Time: 0.106 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 1.875
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 2.370
TRAINING: | Iteration [3/12] | Loss 0.16 | Norm 2.589
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.635
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 2.506
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 2.318
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 1.604
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.605
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.068
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 3.713
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 1.153
TRAINING: | Iteration [12/12] | Loss 0.18 | Norm 3.327
Epoch: 1171/10000 | Epoch Time: 0.106 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.055
TRAINING: | Iteration [2/12] | Loss 0.28 | Norm 3.808
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 3.220
TRAINING: | Iteration [4/12] | Loss 0.16 | Norm 3.678
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.262
TRAINING: | Iteration [6/12] | Loss 0.26 | Norm 4.044
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 1.834
TRAINING: | Iteration [8/12] | Loss 0.30 | Norm 5.000
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 2.819
TRAINING: | Iteration [10/12] | Loss 0.24 | Norm 4.094
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.341
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 2.368
Epoch: 1172/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.17 | Norm 3.775
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 0.694
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 2.175
TRAINING: | Iteration [4/12] | Loss 0.14 | Norm 2.546
TRAINING: | Iteration [5/12] | Loss 0.28 | Norm 4.495
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.457
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 0.936
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 1.846
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 1.953
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 1.833
TRAINING: | Iteration [11/12] | Loss 0.25 | Norm 4.309
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 0.689
Epoch: 1173/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.06 | Norm 1.072
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.889
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.217
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 2.605
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 1.747
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 1.607
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 2.182
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 2.283
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 1.686
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 2.925
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 3.142
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.181
Epoch: 1174/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 2.620
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 2.786
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 0.928
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 2.444
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.281
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 1.391
TRAINING: | Iteration [7/12] | Loss 0.18 | Norm 3.498
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 2.413
TRAINING: | Iteration [9/12] | Loss 0.14 | Norm 3.279
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 0.905
TRAINING: | Iteration [11/12] | Loss 0.14 | Norm 2.241
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 2.219
Epoch: 1175/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 1.324
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.816
TRAINING: | Iteration [3/12] | Loss 0.15 | Norm 2.792
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 2.541
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 2.508
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 1.384
TRAINING: | Iteration [7/12] | Loss 0.13 | Norm 2.070
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 1.726
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 0.844
TRAINING: | Iteration [10/12] | Loss 0.16 | Norm 3.223
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 1.877
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.244
Epoch: 1176/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.18 | Norm 3.763
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 1.072
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 1.751
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 2.399
TRAINING: | Iteration [5/12] | Loss 0.36 | Norm 5.000
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.853
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 0.682
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 2.987
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 2.031
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 1.169
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 2.843
TRAINING: | Iteration [12/12] | Loss 0.24 | Norm 2.423
Epoch: 1177/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.911
TRAINING: | Iteration [2/12] | Loss 0.16 | Norm 2.548
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.425
TRAINING: | Iteration [4/12] | Loss 0.17 | Norm 2.651
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.176
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 3.547
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.959
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 4.175
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 3.429
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 2.623
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 2.799
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 3.250
Epoch: 1178/10000 | Epoch Time: 0.100 seconds
TRAINING: | Iteration [1/12] | Loss 0.17 | Norm 3.357
TRAINING: | Iteration [2/12] | Loss 0.22 | Norm 3.567
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 1.932
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 1.348
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 1.873
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 2.244
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.340
TRAINING: | Iteration [8/12] | Loss 0.16 | Norm 1.840
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 1.867
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 0.669
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 2.425
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.535
Epoch: 1179/10000 | Epoch Time: 0.113 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.182
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.204
TRAINING: | Iteration [3/12] | Loss 0.14 | Norm 3.030
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.431
TRAINING: | Iteration [5/12] | Loss 0.30 | Norm 5.000
TRAINING: | Iteration [6/12] | Loss 0.17 | Norm 3.322
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 1.435
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 1.883
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 2.628
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 2.911
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.195
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 1.278
Epoch: 1180/10000 | Epoch Time: 0.113 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.207
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.616
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 3.698
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.061
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.535
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 1.313
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 1.381
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 2.449
TRAINING: | Iteration [9/12] | Loss 0.14 | Norm 3.093
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 3.250
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 1.286
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 2.320
Epoch: 1181/10000 | Epoch Time: 0.113 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.322
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 2.475
TRAINING: | Iteration [3/12] | Loss 0.21 | Norm 4.707
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.556
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.004
TRAINING: | Iteration [6/12] | Loss 0.15 | Norm 2.567
TRAINING: | Iteration [7/12] | Loss 0.13 | Norm 2.060
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.661
TRAINING: | Iteration [9/12] | Loss 0.14 | Norm 3.046
TRAINING: | Iteration [10/12] | Loss 0.15 | Norm 3.079
TRAINING: | Iteration [11/12] | Loss 0.16 | Norm 4.566
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 1.667
Epoch: 1182/10000 | Epoch Time: 0.117 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.291
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.563
TRAINING: | Iteration [3/12] | Loss 0.18 | Norm 3.417
TRAINING: | Iteration [4/12] | Loss 0.14 | Norm 2.474
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.242
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.162
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 1.631
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 3.171
TRAINING: | Iteration [9/12] | Loss 0.16 | Norm 4.364
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.028
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.336
TRAINING: | Iteration [12/12] | Loss 0.18 | Norm 5.000
Epoch: 1183/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.773
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 1.005
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 0.888
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.607
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.066
TRAINING: | Iteration [6/12] | Loss 0.43 | Norm 5.000
TRAINING: | Iteration [7/12] | Loss 0.14 | Norm 2.802
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 2.144
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.115
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 0.913
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 1.526
TRAINING: | Iteration [12/12] | Loss 0.31 | Norm 5.000
Epoch: 1184/10000 | Epoch Time: 0.121 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.561
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 2.617
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 0.611
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.204
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 1.832
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 2.431
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.441
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.952
TRAINING: | Iteration [9/12] | Loss 0.06 | Norm 0.740
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 0.838
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.349
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.321
Epoch: 1185/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.260
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.032
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.110
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 1.690
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 1.985
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 2.302
TRAINING: | Iteration [7/12] | Loss 0.37 | Norm 5.000
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.508
TRAINING: | Iteration [9/12] | Loss 0.18 | Norm 2.873
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 2.793
TRAINING: | Iteration [11/12] | Loss 0.15 | Norm 2.970
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.435
Epoch: 1186/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.099
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 2.084
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 1.867
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.115
TRAINING: | Iteration [5/12] | Loss 0.15 | Norm 1.906
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.669
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 3.244
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 2.611
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 1.875
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 1.716
TRAINING: | Iteration [11/12] | Loss 0.16 | Norm 3.104
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.403
Epoch: 1187/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.14 | Norm 2.186
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 2.533
TRAINING: | Iteration [3/12] | Loss 0.17 | Norm 3.123
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 0.964
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 2.563
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 0.992
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 0.650
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.665
TRAINING: | Iteration [9/12] | Loss 0.15 | Norm 3.523
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 2.859
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 2.366
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 1.402
Epoch: 1188/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 1.426
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 0.968
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 2.301
TRAINING: | Iteration [4/12] | Loss 0.15 | Norm 3.061
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 3.220
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.385
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 1.164
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 0.958
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 2.416
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.898
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.728
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.415
Epoch: 1189/10000 | Epoch Time: 0.114 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.422
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.929
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 4.247
TRAINING: | Iteration [4/12] | Loss 0.15 | Norm 3.146
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.388
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 1.174
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.372
TRAINING: | Iteration [8/12] | Loss 0.15 | Norm 3.080
TRAINING: | Iteration [9/12] | Loss 0.19 | Norm 5.000
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 2.866
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.176
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 1.271
Epoch: 1190/10000 | Epoch Time: 0.117 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 2.787
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.279
TRAINING: | Iteration [3/12] | Loss 0.06 | Norm 1.112
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 1.097
TRAINING: | Iteration [5/12] | Loss 0.18 | Norm 3.137
TRAINING: | Iteration [6/12] | Loss 0.15 | Norm 3.378
TRAINING: | Iteration [7/12] | Loss 0.40 | Norm 5.000
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.969
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.910
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 0.886
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.625
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.518
Epoch: 1191/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.15 | Norm 3.147
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 2.182
TRAINING: | Iteration [3/12] | Loss 0.18 | Norm 3.034
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.286
TRAINING: | Iteration [5/12] | Loss 0.14 | Norm 3.496
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 1.326
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 1.597
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 3.686
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.045
TRAINING: | Iteration [10/12] | Loss 0.23 | Norm 5.000
TRAINING: | Iteration [11/12] | Loss 0.25 | Norm 4.512
TRAINING: | Iteration [12/12] | Loss 0.15 | Norm 3.027
Epoch: 1192/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 2.037
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 2.239
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.919
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 0.850
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 1.145
TRAINING: | Iteration [6/12] | Loss 0.16 | Norm 2.694
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 1.889
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 2.233
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 1.836
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 1.069
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 1.890
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 2.599
Epoch: 1193/10000 | Epoch Time: 0.108 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 3.112
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 2.043
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 1.998
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 0.723
TRAINING: | Iteration [5/12] | Loss 0.23 | Norm 4.899
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 2.157
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 1.864
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 1.676
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 2.008
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 3.142
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 2.150
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 2.370
Epoch: 1194/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.153
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.006
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.117
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 2.146
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.683
TRAINING: | Iteration [6/12] | Loss 0.14 | Norm 2.765
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.459
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 2.191
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.364
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.820
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.263
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 2.039
Epoch: 1195/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 0.969
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.136
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.856
TRAINING: | Iteration [4/12] | Loss 0.20 | Norm 3.248
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.429
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 2.476
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.139
TRAINING: | Iteration [8/12] | Loss 0.25 | Norm 3.643
TRAINING: | Iteration [9/12] | Loss 0.19 | Norm 3.974
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 1.677
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 1.317
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.093
Epoch: 1196/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 0.987
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.624
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 1.400
TRAINING: | Iteration [4/12] | Loss 0.16 | Norm 3.369
TRAINING: | Iteration [5/12] | Loss 0.19 | Norm 2.952
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.475
TRAINING: | Iteration [7/12] | Loss 0.15 | Norm 3.857
TRAINING: | Iteration [8/12] | Loss 0.18 | Norm 2.041
TRAINING: | Iteration [9/12] | Loss 0.14 | Norm 2.579
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 1.508
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 1.925
TRAINING: | Iteration [12/12] | Loss 0.19 | Norm 2.196
Epoch: 1197/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 4.101
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 2.581
TRAINING: | Iteration [3/12] | Loss 0.21 | Norm 3.672
TRAINING: | Iteration [4/12] | Loss 0.15 | Norm 2.914
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 2.149
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 2.365
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 2.277
TRAINING: | Iteration [8/12] | Loss 0.15 | Norm 3.244
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 2.495
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.115
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 2.911
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 1.923
Epoch: 1198/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.178
TRAINING: | Iteration [2/12] | Loss 0.19 | Norm 3.416
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.854
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 1.699
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 0.990
TRAINING: | Iteration [6/12] | Loss 0.22 | Norm 4.339
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 2.323
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.534
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 2.225
TRAINING: | Iteration [10/12] | Loss 0.15 | Norm 3.043
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.312
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.195
Epoch: 1199/10000 | Epoch Time: 0.117 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.439
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 1.760
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 1.947
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 0.957
TRAINING: | Iteration [5/12] | Loss 0.15 | Norm 3.081
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 2.266
TRAINING: | Iteration [7/12] | Loss 0.19 | Norm 3.696
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.668
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 4.239
TRAINING: | Iteration [10/12] | Loss 0.24 | Norm 5.000
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 0.524
TRAINING: | Iteration [12/12] | Loss 0.32 | Norm 4.844
Epoch: 1200/10000 | Epoch Time: 0.104 seconds
Saving Model
Preparation of Training Data time: 34.902 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 1.434
TRAINING: | Iteration [2/12] | Loss 0.16 | Norm 2.346
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 1.069
TRAINING: | Iteration [4/12] | Loss 0.37 | Norm 5.000
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 0.975
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 2.028
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 0.984
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 2.090
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.225
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 1.825
TRAINING: | Iteration [11/12] | Loss 0.16 | Norm 2.619
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 2.804
Epoch: 1201/10000 | Epoch Time: 0.118 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 1.984
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 2.138
TRAINING: | Iteration [3/12] | Loss 0.18 | Norm 3.432
TRAINING: | Iteration [4/12] | Loss 0.20 | Norm 3.576
TRAINING: | Iteration [5/12] | Loss 0.15 | Norm 3.066
TRAINING: | Iteration [6/12] | Loss 0.16 | Norm 3.165
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.014
TRAINING: | Iteration [8/12] | Loss 0.15 | Norm 1.883
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 1.636
TRAINING: | Iteration [10/12] | Loss 0.20 | Norm 3.182
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 1.825
TRAINING: | Iteration [12/12] | Loss 0.25 | Norm 3.997
Epoch: 1202/10000 | Epoch Time: 0.106 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.386
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 1.897
TRAINING: | Iteration [3/12] | Loss 0.16 | Norm 3.727
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 2.886
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 1.593
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.183
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 1.103
TRAINING: | Iteration [8/12] | Loss 0.16 | Norm 3.094
TRAINING: | Iteration [9/12] | Loss 0.14 | Norm 1.027
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 2.770
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 1.831
TRAINING: | Iteration [12/12] | Loss 0.26 | Norm 4.637
Epoch: 1203/10000 | Epoch Time: 0.100 seconds
TRAINING: | Iteration [1/12] | Loss 0.14 | Norm 2.783
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 1.534
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 1.648
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 0.922
TRAINING: | Iteration [5/12] | Loss 0.15 | Norm 3.450
TRAINING: | Iteration [6/12] | Loss 0.06 | Norm 1.280
TRAINING: | Iteration [7/12] | Loss 0.14 | Norm 2.592
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 3.312
TRAINING: | Iteration [9/12] | Loss 0.14 | Norm 2.924
TRAINING: | Iteration [10/12] | Loss 0.22 | Norm 3.996
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.890
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.392
Epoch: 1204/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 3.521
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 3.312
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 3.305
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 1.842
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 3.586
TRAINING: | Iteration [6/12] | Loss 0.20 | Norm 5.000
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 4.115
TRAINING: | Iteration [8/12] | Loss 0.15 | Norm 2.865
TRAINING: | Iteration [9/12] | Loss 0.14 | Norm 3.091
TRAINING: | Iteration [10/12] | Loss 0.23 | Norm 5.000
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 2.404
TRAINING: | Iteration [12/12] | Loss 0.22 | Norm 4.553
Epoch: 1205/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.48 | Norm 5.000
TRAINING: | Iteration [2/12] | Loss 0.15 | Norm 2.561
TRAINING: | Iteration [3/12] | Loss 0.21 | Norm 4.116
TRAINING: | Iteration [4/12] | Loss 0.14 | Norm 2.151
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 1.718
TRAINING: | Iteration [6/12] | Loss 0.14 | Norm 3.527
TRAINING: | Iteration [7/12] | Loss 0.20 | Norm 3.938
TRAINING: | Iteration [8/12] | Loss 0.19 | Norm 3.510
TRAINING: | Iteration [9/12] | Loss 0.16 | Norm 3.663
TRAINING: | Iteration [10/12] | Loss 0.15 | Norm 3.217
TRAINING: | Iteration [11/12] | Loss 0.28 | Norm 4.910
TRAINING: | Iteration [12/12] | Loss 0.25 | Norm 3.802
Epoch: 1206/10000 | Epoch Time: 0.116 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 2.010
TRAINING: | Iteration [2/12] | Loss 0.16 | Norm 2.338
TRAINING: | Iteration [3/12] | Loss 0.14 | Norm 2.705
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.051
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 2.044
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.768
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 2.067
TRAINING: | Iteration [8/12] | Loss 0.25 | Norm 4.204
TRAINING: | Iteration [9/12] | Loss 0.18 | Norm 3.469
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 0.867
TRAINING: | Iteration [11/12] | Loss 0.21 | Norm 4.054
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 1.062
Epoch: 1207/10000 | Epoch Time: 0.117 seconds
TRAINING: | Iteration [1/12] | Loss 0.17 | Norm 2.873
TRAINING: | Iteration [2/12] | Loss 0.14 | Norm 2.719
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 1.942
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 1.431
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 1.968
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 0.552
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 3.003
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 1.734
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 2.314
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 1.712
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 1.446
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.626
Epoch: 1208/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.15 | Norm 2.493
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 2.040
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 1.050
TRAINING: | Iteration [4/12] | Loss 0.24 | Norm 3.433
TRAINING: | Iteration [5/12] | Loss 0.16 | Norm 2.766
TRAINING: | Iteration [6/12] | Loss 0.19 | Norm 2.426
TRAINING: | Iteration [7/12] | Loss 0.15 | Norm 2.641
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 2.841
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.054
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.357
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.654
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 1.445
Epoch: 1209/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 1.124
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.099
TRAINING: | Iteration [3/12] | Loss 0.16 | Norm 3.417
TRAINING: | Iteration [4/12] | Loss 0.18 | Norm 2.894
TRAINING: | Iteration [5/12] | Loss 0.26 | Norm 5.000
TRAINING: | Iteration [6/12] | Loss 0.18 | Norm 3.884
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 1.745
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 2.524
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 2.464
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.519
TRAINING: | Iteration [11/12] | Loss 0.16 | Norm 2.401
TRAINING: | Iteration [12/12] | Loss 0.21 | Norm 3.206
Epoch: 1210/10000 | Epoch Time: 0.102 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 0.921
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 1.807
TRAINING: | Iteration [3/12] | Loss 0.16 | Norm 2.439
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 2.131
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 2.311
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 2.126
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 1.472
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 1.483
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 1.169
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 2.082
TRAINING: | Iteration [11/12] | Loss 0.14 | Norm 2.251
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.346
Epoch: 1211/10000 | Epoch Time: 0.105 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 1.213
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 2.179
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 1.278
TRAINING: | Iteration [4/12] | Loss 0.17 | Norm 2.608
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 2.000
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 2.755
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 1.538
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.971
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 1.945
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 2.696
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 0.926
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 1.767
Epoch: 1212/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.18 | Norm 3.200
TRAINING: | Iteration [2/12] | Loss 0.19 | Norm 3.621
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 4.331
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 1.855
TRAINING: | Iteration [5/12] | Loss 0.14 | Norm 2.552
TRAINING: | Iteration [6/12] | Loss 0.24 | Norm 3.837
TRAINING: | Iteration [7/12] | Loss 0.24 | Norm 4.550
TRAINING: | Iteration [8/12] | Loss 0.16 | Norm 3.625
TRAINING: | Iteration [9/12] | Loss 0.16 | Norm 3.335
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 0.743
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 1.686
TRAINING: | Iteration [12/12] | Loss 0.19 | Norm 3.236
Epoch: 1213/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 2.014
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.209
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.749
TRAINING: | Iteration [4/12] | Loss 0.16 | Norm 2.915
TRAINING: | Iteration [5/12] | Loss 0.16 | Norm 2.916
TRAINING: | Iteration [6/12] | Loss 0.21 | Norm 3.170
TRAINING: | Iteration [7/12] | Loss 0.16 | Norm 3.021
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 2.296
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 2.318
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 2.467
TRAINING: | Iteration [11/12] | Loss 0.19 | Norm 3.804
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.656
Epoch: 1214/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.16 | Norm 4.508
TRAINING: | Iteration [2/12] | Loss 0.22 | Norm 4.162
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.248
TRAINING: | Iteration [4/12] | Loss 0.15 | Norm 2.574
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 2.762
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 0.859
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 1.393
TRAINING: | Iteration [8/12] | Loss 0.23 | Norm 4.109
TRAINING: | Iteration [9/12] | Loss 0.16 | Norm 2.064
TRAINING: | Iteration [10/12] | Loss 0.23 | Norm 4.486
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 1.247
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 1.126
Epoch: 1215/10000 | Epoch Time: 0.100 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 0.980
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 1.853
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.275
TRAINING: | Iteration [4/12] | Loss 0.15 | Norm 2.963
TRAINING: | Iteration [5/12] | Loss 0.17 | Norm 3.137
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 2.709
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.151
TRAINING: | Iteration [8/12] | Loss 0.17 | Norm 3.425
TRAINING: | Iteration [9/12] | Loss 0.16 | Norm 3.862
TRAINING: | Iteration [10/12] | Loss 0.22 | Norm 3.824
TRAINING: | Iteration [11/12] | Loss 0.26 | Norm 4.089
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.101
Epoch: 1216/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 1.996
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 1.587
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 1.140
TRAINING: | Iteration [4/12] | Loss 0.18 | Norm 3.972
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 2.218
TRAINING: | Iteration [6/12] | Loss 0.32 | Norm 4.680
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 2.621
TRAINING: | Iteration [8/12] | Loss 0.38 | Norm 5.000
TRAINING: | Iteration [9/12] | Loss 0.15 | Norm 1.723
TRAINING: | Iteration [10/12] | Loss 0.19 | Norm 3.498
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 1.705
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.066
Epoch: 1217/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.861
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 1.610
TRAINING: | Iteration [3/12] | Loss 0.30 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 2.506
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.426
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 2.881
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.244
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 1.790
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 1.225
TRAINING: | Iteration [10/12] | Loss 0.16 | Norm 3.070
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 0.774
TRAINING: | Iteration [12/12] | Loss 1.07 | Norm 5.000
Epoch: 1218/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.21 | Norm 3.376
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 2.646
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 1.327
TRAINING: | Iteration [4/12] | Loss 0.15 | Norm 4.304
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.321
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.355
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 1.989
TRAINING: | Iteration [8/12] | Loss 0.19 | Norm 3.150
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 2.011
TRAINING: | Iteration [10/12] | Loss 0.07 | Norm 1.838
TRAINING: | Iteration [11/12] | Loss 0.33 | Norm 5.000
TRAINING: | Iteration [12/12] | Loss 0.66 | Norm 5.000
Epoch: 1219/10000 | Epoch Time: 0.100 seconds
TRAINING: | Iteration [1/12] | Loss 0.14 | Norm 2.701
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 3.192
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.052
TRAINING: | Iteration [4/12] | Loss 0.16 | Norm 3.391
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.262
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 1.775
TRAINING: | Iteration [7/12] | Loss 0.17 | Norm 3.180
TRAINING: | Iteration [8/12] | Loss 0.15 | Norm 2.448
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 3.616
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 1.354
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.402
TRAINING: | Iteration [12/12] | Loss 0.35 | Norm 5.000
Epoch: 1220/10000 | Epoch Time: 0.117 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.14 | Norm 2.198
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.392
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 1.755
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 1.380
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 2.350
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 1.879
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 2.499
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 2.483
TRAINING: | Iteration [9/12] | Loss 0.15 | Norm 3.036
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.758
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 2.447
TRAINING: | Iteration [12/12] | Loss 0.16 | Norm 3.460
Epoch: 1221/10000 | Epoch Time: 0.108 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 2.382
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 3.040
TRAINING: | Iteration [3/12] | Loss 0.14 | Norm 1.643
TRAINING: | Iteration [4/12] | Loss 0.15 | Norm 3.006
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.098
TRAINING: | Iteration [6/12] | Loss 0.18 | Norm 3.916
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 2.040
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 2.895
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 1.411
TRAINING: | Iteration [10/12] | Loss 0.36 | Norm 4.700
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.325
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 2.422
Epoch: 1222/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 3.062
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.006
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.477
TRAINING: | Iteration [4/12] | Loss 0.15 | Norm 2.889
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 2.491
TRAINING: | Iteration [6/12] | Loss 0.16 | Norm 3.116
TRAINING: | Iteration [7/12] | Loss 0.17 | Norm 3.651
TRAINING: | Iteration [8/12] | Loss 0.15 | Norm 3.581
TRAINING: | Iteration [9/12] | Loss 0.41 | Norm 5.000
TRAINING: | Iteration [10/12] | Loss 0.15 | Norm 1.850
TRAINING: | Iteration [11/12] | Loss 0.16 | Norm 4.472
TRAINING: | Iteration [12/12] | Loss 0.16 | Norm 4.154
Epoch: 1223/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.21 | Norm 3.066
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 2.672
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 1.541
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 1.659
TRAINING: | Iteration [5/12] | Loss 0.26 | Norm 4.806
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.060
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 1.467
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 0.836
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.013
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 1.740
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 2.469
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 1.658
Epoch: 1224/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.23 | Norm 3.070
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 1.611
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.249
TRAINING: | Iteration [4/12] | Loss 0.23 | Norm 4.194
TRAINING: | Iteration [5/12] | Loss 0.16 | Norm 2.527
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 1.407
TRAINING: | Iteration [7/12] | Loss 0.20 | Norm 3.432
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 0.760
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 1.980
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 3.070
TRAINING: | Iteration [11/12] | Loss 0.15 | Norm 2.471
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 2.504
Epoch: 1225/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.14 | Norm 3.422
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 2.428
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 2.528
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 1.619
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.185
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 1.561
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 1.653
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.377
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.033
TRAINING: | Iteration [10/12] | Loss 0.15 | Norm 1.788
TRAINING: | Iteration [11/12] | Loss 0.25 | Norm 3.749
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 1.579
Epoch: 1226/10000 | Epoch Time: 0.100 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.715
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 2.652
TRAINING: | Iteration [3/12] | Loss 0.18 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 0.20 | Norm 4.665
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 2.790
TRAINING: | Iteration [6/12] | Loss 0.16 | Norm 2.350
TRAINING: | Iteration [7/12] | Loss 0.14 | Norm 3.264
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 1.802
TRAINING: | Iteration [9/12] | Loss 0.25 | Norm 2.913
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 0.993
TRAINING: | Iteration [11/12] | Loss 0.21 | Norm 4.485
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 3.564
Epoch: 1227/10000 | Epoch Time: 0.116 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 1.738
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 2.697
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 1.955
TRAINING: | Iteration [4/12] | Loss 0.20 | Norm 4.101
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.634
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 2.308
TRAINING: | Iteration [7/12] | Loss 0.36 | Norm 5.000
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 1.273
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 1.476
TRAINING: | Iteration [10/12] | Loss 0.15 | Norm 2.607
TRAINING: | Iteration [11/12] | Loss 0.26 | Norm 4.483
TRAINING: | Iteration [12/12] | Loss 0.16 | Norm 3.215
Epoch: 1228/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.15 | Norm 1.792
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.190
TRAINING: | Iteration [3/12] | Loss 0.26 | Norm 4.466
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.315
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 1.102
TRAINING: | Iteration [6/12] | Loss 0.14 | Norm 2.298
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 0.916
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.560
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 0.779
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 1.470
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.206
TRAINING: | Iteration [12/12] | Loss 0.16 | Norm 3.309
Epoch: 1229/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 3.228
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 1.209
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 1.323
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 3.090
TRAINING: | Iteration [5/12] | Loss 0.29 | Norm 4.717
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 2.861
TRAINING: | Iteration [7/12] | Loss 0.16 | Norm 3.309
TRAINING: | Iteration [8/12] | Loss 0.07 | Norm 0.946
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 1.190
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 3.620
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 1.392
TRAINING: | Iteration [12/12] | Loss 0.17 | Norm 3.364
Epoch: 1230/10000 | Epoch Time: 0.102 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 2.641
TRAINING: | Iteration [2/12] | Loss 0.17 | Norm 2.255
TRAINING: | Iteration [3/12] | Loss 0.14 | Norm 4.223
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 2.316
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.013
TRAINING: | Iteration [6/12] | Loss 0.14 | Norm 1.465
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 2.996
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.243
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 1.764
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 3.085
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 0.920
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 1.980
Epoch: 1231/10000 | Epoch Time: 0.108 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 2.494
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.085
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 1.495
TRAINING: | Iteration [4/12] | Loss 0.16 | Norm 2.574
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 3.475
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 1.500
TRAINING: | Iteration [7/12] | Loss 0.18 | Norm 3.350
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 2.033
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.203
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.076
TRAINING: | Iteration [11/12] | Loss 0.22 | Norm 4.050
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 2.864
Epoch: 1232/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.225
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 2.180
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.063
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 2.305
TRAINING: | Iteration [5/12] | Loss 0.14 | Norm 1.723
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 2.235
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 2.315
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 1.780
TRAINING: | Iteration [9/12] | Loss 0.19 | Norm 3.766
TRAINING: | Iteration [10/12] | Loss 0.15 | Norm 3.217
TRAINING: | Iteration [11/12] | Loss 0.18 | Norm 3.260
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 1.571
Epoch: 1233/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.15 | Norm 2.947
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.326
TRAINING: | Iteration [3/12] | Loss 0.14 | Norm 2.359
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 2.060
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 1.169
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 2.219
TRAINING: | Iteration [7/12] | Loss 0.28 | Norm 3.916
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 1.784
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 3.456
TRAINING: | Iteration [10/12] | Loss 0.26 | Norm 3.871
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 1.214
TRAINING: | Iteration [12/12] | Loss 0.23 | Norm 3.197
Epoch: 1234/10000 | Epoch Time: 0.106 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 1.251
TRAINING: | Iteration [2/12] | Loss 0.17 | Norm 3.390
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 2.155
TRAINING: | Iteration [4/12] | Loss 0.14 | Norm 2.038
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.738
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 1.882
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.120
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.497
TRAINING: | Iteration [9/12] | Loss 0.16 | Norm 2.993
TRAINING: | Iteration [10/12] | Loss 0.15 | Norm 2.839
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 1.947
TRAINING: | Iteration [12/12] | Loss 0.26 | Norm 4.823
Epoch: 1235/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.767
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 1.448
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 0.721
TRAINING: | Iteration [4/12] | Loss 0.15 | Norm 2.990
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 1.880
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 1.089
TRAINING: | Iteration [7/12] | Loss 0.19 | Norm 3.496
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.997
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 1.862
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 2.766
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 0.986
TRAINING: | Iteration [12/12] | Loss 0.19 | Norm 3.821
Epoch: 1236/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.19 | Norm 3.704
TRAINING: | Iteration [2/12] | Loss 0.17 | Norm 2.769
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 1.294
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 2.140
TRAINING: | Iteration [5/12] | Loss 0.15 | Norm 3.460
TRAINING: | Iteration [6/12] | Loss 0.19 | Norm 2.838
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 2.613
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 0.893
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 2.787
TRAINING: | Iteration [10/12] | Loss 0.15 | Norm 2.190
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 1.637
TRAINING: | Iteration [12/12] | Loss 0.36 | Norm 5.000
Epoch: 1237/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.22 | Norm 4.431
TRAINING: | Iteration [2/12] | Loss 0.29 | Norm 4.975
TRAINING: | Iteration [3/12] | Loss 0.45 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 2.247
TRAINING: | Iteration [5/12] | Loss 0.17 | Norm 2.901
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.287
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 2.859
TRAINING: | Iteration [8/12] | Loss 0.15 | Norm 2.867
TRAINING: | Iteration [9/12] | Loss 0.14 | Norm 2.706
TRAINING: | Iteration [10/12] | Loss 0.19 | Norm 3.105
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 2.511
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 2.997
Epoch: 1238/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.19 | Norm 2.782
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 1.950
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 0.868
TRAINING: | Iteration [4/12] | Loss 0.14 | Norm 2.851
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.700
TRAINING: | Iteration [6/12] | Loss 0.17 | Norm 3.662
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 1.647
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.707
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 0.997
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.569
TRAINING: | Iteration [11/12] | Loss 0.20 | Norm 3.457
TRAINING: | Iteration [12/12] | Loss 0.17 | Norm 3.111
Epoch: 1239/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.15 | Norm 2.555
TRAINING: | Iteration [2/12] | Loss 0.16 | Norm 2.765
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 0.915
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 1.434
TRAINING: | Iteration [5/12] | Loss 0.19 | Norm 3.563
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 1.978
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.916
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 2.117
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 1.016
TRAINING: | Iteration [10/12] | Loss 0.16 | Norm 3.391
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 1.521
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 1.834
Epoch: 1240/10000 | Epoch Time: 0.102 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 2.223
TRAINING: | Iteration [2/12] | Loss 0.19 | Norm 4.371
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.809
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 2.550
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 1.508
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 2.274
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.472
TRAINING: | Iteration [8/12] | Loss 0.16 | Norm 2.981
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 2.257
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 1.495
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 1.877
TRAINING: | Iteration [12/12] | Loss 0.15 | Norm 3.352
Epoch: 1241/10000 | Epoch Time: 0.107 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.160
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.229
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 1.966
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 2.989
TRAINING: | Iteration [5/12] | Loss 0.16 | Norm 2.826
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.694
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 1.856
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 1.686
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 1.952
TRAINING: | Iteration [10/12] | Loss 0.24 | Norm 3.186
TRAINING: | Iteration [11/12] | Loss 0.18 | Norm 3.934
TRAINING: | Iteration [12/12] | Loss 0.20 | Norm 3.346
Epoch: 1242/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.028
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 2.350
TRAINING: | Iteration [3/12] | Loss 0.15 | Norm 2.544
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.739
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 2.405
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.863
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.314
TRAINING: | Iteration [8/12] | Loss 0.22 | Norm 3.702
TRAINING: | Iteration [9/12] | Loss 0.15 | Norm 3.029
TRAINING: | Iteration [10/12] | Loss 0.18 | Norm 3.690
TRAINING: | Iteration [11/12] | Loss 0.15 | Norm 3.027
TRAINING: | Iteration [12/12] | Loss 0.15 | Norm 2.696
Epoch: 1243/10000 | Epoch Time: 0.100 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.252
TRAINING: | Iteration [2/12] | Loss 0.20 | Norm 4.226
TRAINING: | Iteration [3/12] | Loss 0.18 | Norm 3.088
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 2.405
TRAINING: | Iteration [5/12] | Loss 0.20 | Norm 3.489
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 1.377
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 1.478
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 2.715
TRAINING: | Iteration [9/12] | Loss 0.22 | Norm 2.921
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 3.420
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.212
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 1.726
Epoch: 1244/10000 | Epoch Time: 0.116 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 2.054
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 0.897
TRAINING: | Iteration [3/12] | Loss 0.17 | Norm 2.707
TRAINING: | Iteration [4/12] | Loss 0.34 | Norm 5.000
TRAINING: | Iteration [5/12] | Loss 0.22 | Norm 4.130
TRAINING: | Iteration [6/12] | Loss 0.18 | Norm 3.086
TRAINING: | Iteration [7/12] | Loss 0.13 | Norm 2.085
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 1.126
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.085
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 0.677
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 2.082
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 2.071
Epoch: 1245/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 1.874
TRAINING: | Iteration [2/12] | Loss 0.20 | Norm 3.597
TRAINING: | Iteration [3/12] | Loss 0.15 | Norm 3.130
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 1.201
TRAINING: | Iteration [5/12] | Loss 0.15 | Norm 2.873
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 1.580
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.843
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 2.321
TRAINING: | Iteration [9/12] | Loss 0.16 | Norm 2.552
TRAINING: | Iteration [10/12] | Loss 0.19 | Norm 2.602
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.364
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 2.436
Epoch: 1246/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.688
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 2.511
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 2.243
TRAINING: | Iteration [4/12] | Loss 0.15 | Norm 2.233
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 1.736
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 2.184
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 0.712
TRAINING: | Iteration [8/12] | Loss 0.20 | Norm 4.127
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 2.615
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 1.456
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.183
TRAINING: | Iteration [12/12] | Loss 0.19 | Norm 3.583
Epoch: 1247/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 2.406
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 1.428
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.048
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 1.422
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.418
TRAINING: | Iteration [6/12] | Loss 0.49 | Norm 5.000
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 1.882
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 1.510
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 1.630
TRAINING: | Iteration [10/12] | Loss 0.15 | Norm 2.727
TRAINING: | Iteration [11/12] | Loss 0.17 | Norm 4.624
TRAINING: | Iteration [12/12] | Loss 0.16 | Norm 1.682
Epoch: 1248/10000 | Epoch Time: 0.119 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 1.152
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 1.795
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 3.245
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 2.299
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 2.390
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 2.166
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.108
TRAINING: | Iteration [8/12] | Loss 0.18 | Norm 3.825
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.840
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 3.338
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 2.542
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 3.286
Epoch: 1249/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.20 | Norm 5.000
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 2.344
TRAINING: | Iteration [3/12] | Loss 0.14 | Norm 2.547
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 2.490
TRAINING: | Iteration [5/12] | Loss 0.20 | Norm 3.600
TRAINING: | Iteration [6/12] | Loss 0.32 | Norm 4.595
TRAINING: | Iteration [7/12] | Loss 0.22 | Norm 5.000
TRAINING: | Iteration [8/12] | Loss 0.20 | Norm 4.645
TRAINING: | Iteration [9/12] | Loss 0.15 | Norm 4.572
TRAINING: | Iteration [10/12] | Loss 0.22 | Norm 4.065
TRAINING: | Iteration [11/12] | Loss 0.18 | Norm 3.589
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 2.953
Epoch: 1250/10000 | Epoch Time: 0.105 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.15 | Norm 3.732
TRAINING: | Iteration [2/12] | Loss 0.14 | Norm 3.666
TRAINING: | Iteration [3/12] | Loss 0.16 | Norm 3.488
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 1.747
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 2.131
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 4.113
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 3.535
TRAINING: | Iteration [8/12] | Loss 0.18 | Norm 3.491
TRAINING: | Iteration [9/12] | Loss 0.17 | Norm 3.170
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 2.142
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.841
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.857
Epoch: 1251/10000 | Epoch Time: 0.105 seconds
TRAINING: | Iteration [1/12] | Loss 0.17 | Norm 5.000
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 2.183
TRAINING: | Iteration [3/12] | Loss 0.28 | Norm 4.895
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 0.942
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 3.563
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 1.294
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 1.648
TRAINING: | Iteration [8/12] | Loss 0.41 | Norm 5.000
TRAINING: | Iteration [9/12] | Loss 0.24 | Norm 4.924
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 0.767
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.767
TRAINING: | Iteration [12/12] | Loss 0.17 | Norm 2.837
Epoch: 1252/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 1.603
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 1.696
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 3.172
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 2.187
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.736
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 1.540
TRAINING: | Iteration [7/12] | Loss 0.23 | Norm 4.296
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 3.549
TRAINING: | Iteration [9/12] | Loss 0.14 | Norm 2.854
TRAINING: | Iteration [10/12] | Loss 0.15 | Norm 3.225
TRAINING: | Iteration [11/12] | Loss 0.20 | Norm 3.120
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 3.242
Epoch: 1253/10000 | Epoch Time: 0.106 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 2.035
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 2.290
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 2.234
TRAINING: | Iteration [4/12] | Loss 0.15 | Norm 2.143
TRAINING: | Iteration [5/12] | Loss 0.17 | Norm 3.531
TRAINING: | Iteration [6/12] | Loss 0.16 | Norm 3.339
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 2.713
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.916
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 3.416
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 1.553
TRAINING: | Iteration [11/12] | Loss 0.17 | Norm 3.150
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.426
Epoch: 1254/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 1.354
TRAINING: | Iteration [2/12] | Loss 0.15 | Norm 3.452
TRAINING: | Iteration [3/12] | Loss 0.15 | Norm 2.736
TRAINING: | Iteration [4/12] | Loss 0.17 | Norm 2.926
TRAINING: | Iteration [5/12] | Loss 0.18 | Norm 2.364
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 3.033
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 1.781
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.101
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 1.610
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.436
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 0.906
TRAINING: | Iteration [12/12] | Loss 0.41 | Norm 5.000
Epoch: 1255/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.16 | Norm 2.304
TRAINING: | Iteration [2/12] | Loss 0.26 | Norm 4.072
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 1.335
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 2.115
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.020
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.786
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 2.660
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 2.137
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 1.524
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 2.529
TRAINING: | Iteration [11/12] | Loss 0.17 | Norm 3.362
TRAINING: | Iteration [12/12] | Loss 0.21 | Norm 3.856
Epoch: 1256/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.15 | Norm 2.082
TRAINING: | Iteration [2/12] | Loss 0.16 | Norm 1.919
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 1.882
TRAINING: | Iteration [4/12] | Loss 0.16 | Norm 2.175
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 2.207
TRAINING: | Iteration [6/12] | Loss 0.17 | Norm 2.530
TRAINING: | Iteration [7/12] | Loss 0.19 | Norm 3.034
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 5.000
TRAINING: | Iteration [9/12] | Loss 0.16 | Norm 2.612
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 1.113
TRAINING: | Iteration [11/12] | Loss 0.15 | Norm 2.358
TRAINING: | Iteration [12/12] | Loss 0.42 | Norm 5.000
Epoch: 1257/10000 | Epoch Time: 0.118 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.950
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.857
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 2.312
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 2.108
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 1.968
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 1.869
TRAINING: | Iteration [7/12] | Loss 0.24 | Norm 3.652
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 0.961
TRAINING: | Iteration [9/12] | Loss 0.15 | Norm 2.928
TRAINING: | Iteration [10/12] | Loss 0.22 | Norm 4.070
TRAINING: | Iteration [11/12] | Loss 0.16 | Norm 2.458
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 2.937
Epoch: 1258/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.14 | Norm 1.639
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.178
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 0.888
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 0.922
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 0.540
TRAINING: | Iteration [6/12] | Loss 0.30 | Norm 4.034
TRAINING: | Iteration [7/12] | Loss 0.14 | Norm 1.826
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 1.137
TRAINING: | Iteration [9/12] | Loss 0.19 | Norm 3.399
TRAINING: | Iteration [10/12] | Loss 0.17 | Norm 3.669
TRAINING: | Iteration [11/12] | Loss 0.43 | Norm 5.000
TRAINING: | Iteration [12/12] | Loss 0.27 | Norm 4.459
Epoch: 1259/10000 | Epoch Time: 0.100 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 2.184
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 0.813
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 1.911
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 1.157
TRAINING: | Iteration [5/12] | Loss 0.51 | Norm 5.000
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 1.275
TRAINING: | Iteration [7/12] | Loss 0.15 | Norm 3.280
TRAINING: | Iteration [8/12] | Loss 0.17 | Norm 3.200
TRAINING: | Iteration [9/12] | Loss 0.18 | Norm 2.628
TRAINING: | Iteration [10/12] | Loss 0.16 | Norm 2.897
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.852
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.470
Epoch: 1260/10000 | Epoch Time: 0.101 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.201
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 1.251
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.015
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 1.773
TRAINING: | Iteration [5/12] | Loss 0.15 | Norm 2.631
TRAINING: | Iteration [6/12] | Loss 0.16 | Norm 2.786
TRAINING: | Iteration [7/12] | Loss 0.15 | Norm 3.161
TRAINING: | Iteration [8/12] | Loss 0.15 | Norm 2.300
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 1.424
TRAINING: | Iteration [10/12] | Loss 0.06 | Norm 0.809
TRAINING: | Iteration [11/12] | Loss 0.24 | Norm 3.875
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.422
Epoch: 1261/10000 | Epoch Time: 0.105 seconds
TRAINING: | Iteration [1/12] | Loss 0.20 | Norm 3.493
TRAINING: | Iteration [2/12] | Loss 0.15 | Norm 2.992
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 2.426
TRAINING: | Iteration [4/12] | Loss 0.14 | Norm 2.611
TRAINING: | Iteration [5/12] | Loss 0.15 | Norm 2.540
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 1.649
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 2.358
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 1.121
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 1.308
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 2.629
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.812
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 3.707
Epoch: 1262/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 2.688
TRAINING: | Iteration [2/12] | Loss 0.18 | Norm 3.954
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 1.648
TRAINING: | Iteration [4/12] | Loss 0.15 | Norm 1.977
TRAINING: | Iteration [5/12] | Loss 0.15 | Norm 3.848
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 1.138
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 2.353
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 2.536
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 0.686
TRAINING: | Iteration [10/12] | Loss 0.17 | Norm 2.438
TRAINING: | Iteration [11/12] | Loss 0.15 | Norm 2.903
TRAINING: | Iteration [12/12] | Loss 0.23 | Norm 3.848
Epoch: 1263/10000 | Epoch Time: 0.114 seconds
TRAINING: | Iteration [1/12] | Loss 0.17 | Norm 2.805
TRAINING: | Iteration [2/12] | Loss 0.19 | Norm 1.887
TRAINING: | Iteration [3/12] | Loss 0.27 | Norm 4.566
TRAINING: | Iteration [4/12] | Loss 0.14 | Norm 4.685
TRAINING: | Iteration [5/12] | Loss 0.15 | Norm 2.376
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 2.173
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.386
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 2.871
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.476
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 2.548
TRAINING: | Iteration [11/12] | Loss 0.18 | Norm 3.428
TRAINING: | Iteration [12/12] | Loss 0.16 | Norm 3.346
Epoch: 1264/10000 | Epoch Time: 0.114 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 2.598
TRAINING: | Iteration [2/12] | Loss 0.18 | Norm 3.104
TRAINING: | Iteration [3/12] | Loss 0.16 | Norm 2.504
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 0.694
TRAINING: | Iteration [5/12] | Loss 0.18 | Norm 3.942
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 2.520
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.645
TRAINING: | Iteration [8/12] | Loss 0.20 | Norm 2.431
TRAINING: | Iteration [9/12] | Loss 0.20 | Norm 4.189
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 1.448
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 2.068
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 2.398
Epoch: 1265/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.681
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 3.911
TRAINING: | Iteration [3/12] | Loss 0.25 | Norm 4.589
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 3.744
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 2.635
TRAINING: | Iteration [6/12] | Loss 0.14 | Norm 2.162
TRAINING: | Iteration [7/12] | Loss 0.16 | Norm 2.625
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 4.224
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 1.302
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 2.501
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 1.009
TRAINING: | Iteration [12/12] | Loss 0.17 | Norm 2.743
Epoch: 1266/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 2.733
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 1.837
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 1.567
TRAINING: | Iteration [4/12] | Loss 0.20 | Norm 4.739
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 2.701
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 1.316
TRAINING: | Iteration [7/12] | Loss 0.27 | Norm 5.000
TRAINING: | Iteration [8/12] | Loss 0.16 | Norm 2.904
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 0.898
TRAINING: | Iteration [10/12] | Loss 0.21 | Norm 4.290
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 2.918
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.352
Epoch: 1267/10000 | Epoch Time: 0.120 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 2.202
TRAINING: | Iteration [2/12] | Loss 0.18 | Norm 2.431
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 1.282
TRAINING: | Iteration [4/12] | Loss 0.25 | Norm 4.197
TRAINING: | Iteration [5/12] | Loss 0.18 | Norm 3.190
TRAINING: | Iteration [6/12] | Loss 0.17 | Norm 2.757
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 2.141
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 1.918
TRAINING: | Iteration [9/12] | Loss 0.16 | Norm 1.974
TRAINING: | Iteration [10/12] | Loss 0.31 | Norm 4.831
TRAINING: | Iteration [11/12] | Loss 0.14 | Norm 2.039
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 2.775
Epoch: 1268/10000 | Epoch Time: 0.118 seconds
TRAINING: | Iteration [1/12] | Loss 0.24 | Norm 3.881
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.554
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 0.879
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 1.202
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 3.776
TRAINING: | Iteration [6/12] | Loss 0.16 | Norm 4.266
TRAINING: | Iteration [7/12] | Loss 0.18 | Norm 3.895
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 3.675
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 3.134
TRAINING: | Iteration [10/12] | Loss 0.16 | Norm 2.212
TRAINING: | Iteration [11/12] | Loss 0.15 | Norm 1.867
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 2.930
Epoch: 1269/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.141
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 1.102
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 1.146
TRAINING: | Iteration [4/12] | Loss 0.19 | Norm 3.082
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 1.997
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 1.519
TRAINING: | Iteration [7/12] | Loss 0.15 | Norm 2.599
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 2.421
TRAINING: | Iteration [9/12] | Loss 0.20 | Norm 2.049
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 1.210
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 1.229
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 2.179
Epoch: 1270/10000 | Epoch Time: 0.113 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 1.582
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.139
TRAINING: | Iteration [3/12] | Loss 0.24 | Norm 4.241
TRAINING: | Iteration [4/12] | Loss 0.23 | Norm 4.091
TRAINING: | Iteration [5/12] | Loss 0.14 | Norm 2.219
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 1.810
TRAINING: | Iteration [7/12] | Loss 0.32 | Norm 5.000
TRAINING: | Iteration [8/12] | Loss 0.15 | Norm 2.797
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 1.209
TRAINING: | Iteration [10/12] | Loss 0.18 | Norm 3.163
TRAINING: | Iteration [11/12] | Loss 0.14 | Norm 2.689
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 2.314
Epoch: 1271/10000 | Epoch Time: 0.106 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 2.603
TRAINING: | Iteration [2/12] | Loss 0.15 | Norm 3.989
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.770
TRAINING: | Iteration [4/12] | Loss 0.20 | Norm 3.321
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 2.024
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.645
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 2.122
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 1.878
TRAINING: | Iteration [9/12] | Loss 0.20 | Norm 3.257
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.559
TRAINING: | Iteration [11/12] | Loss 0.18 | Norm 2.995
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 1.400
Epoch: 1272/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 0.673
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 2.170
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 1.779
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 1.530
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 1.798
TRAINING: | Iteration [6/12] | Loss 0.18 | Norm 2.547
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 0.814
TRAINING: | Iteration [8/12] | Loss 0.16 | Norm 2.564
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 0.995
TRAINING: | Iteration [10/12] | Loss 0.17 | Norm 2.622
TRAINING: | Iteration [11/12] | Loss 0.14 | Norm 1.740
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.358
Epoch: 1273/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 1.880
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 1.187
TRAINING: | Iteration [3/12] | Loss 0.14 | Norm 2.506
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 2.105
TRAINING: | Iteration [5/12] | Loss 0.17 | Norm 3.819
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 2.455
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.242
TRAINING: | Iteration [8/12] | Loss 0.15 | Norm 1.939
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 3.289
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 2.006
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 1.269
TRAINING: | Iteration [12/12] | Loss 0.24 | Norm 5.000
Epoch: 1274/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.27 | Norm 4.611
TRAINING: | Iteration [2/12] | Loss 0.14 | Norm 3.351
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 2.523
TRAINING: | Iteration [4/12] | Loss 0.20 | Norm 4.068
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 0.982
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 1.771
TRAINING: | Iteration [7/12] | Loss 0.16 | Norm 3.168
TRAINING: | Iteration [8/12] | Loss 0.15 | Norm 3.081
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 2.597
TRAINING: | Iteration [10/12] | Loss 0.22 | Norm 4.045
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 2.078
TRAINING: | Iteration [12/12] | Loss 0.18 | Norm 2.597
Epoch: 1275/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 2.109
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 2.588
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 1.787
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 1.799
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 1.590
TRAINING: | Iteration [6/12] | Loss 0.16 | Norm 3.148
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 2.201
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 1.606
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 1.774
TRAINING: | Iteration [10/12] | Loss 0.19 | Norm 2.873
TRAINING: | Iteration [11/12] | Loss 0.15 | Norm 2.862
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 2.456
Epoch: 1276/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 0.918
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 1.663
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 1.928
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.160
TRAINING: | Iteration [5/12] | Loss 0.17 | Norm 2.987
TRAINING: | Iteration [6/12] | Loss 0.19 | Norm 3.581
TRAINING: | Iteration [7/12] | Loss 0.31 | Norm 5.000
TRAINING: | Iteration [8/12] | Loss 0.15 | Norm 3.145
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 1.682
TRAINING: | Iteration [10/12] | Loss 0.29 | Norm 5.000
TRAINING: | Iteration [11/12] | Loss 0.19 | Norm 3.045
TRAINING: | Iteration [12/12] | Loss 0.33 | Norm 4.968
Epoch: 1277/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.028
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 2.476
TRAINING: | Iteration [3/12] | Loss 0.20 | Norm 2.248
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 1.002
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 1.258
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 2.852
TRAINING: | Iteration [7/12] | Loss 0.16 | Norm 3.345
TRAINING: | Iteration [8/12] | Loss 0.25 | Norm 4.585
TRAINING: | Iteration [9/12] | Loss 0.16 | Norm 2.627
TRAINING: | Iteration [10/12] | Loss 0.15 | Norm 1.750
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 2.054
TRAINING: | Iteration [12/12] | Loss 0.18 | Norm 3.819
Epoch: 1278/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.17 | Norm 2.749
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 1.302
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.363
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 1.577
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 2.446
TRAINING: | Iteration [6/12] | Loss 0.19 | Norm 3.888
TRAINING: | Iteration [7/12] | Loss 0.18 | Norm 3.861
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 2.751
TRAINING: | Iteration [9/12] | Loss 0.20 | Norm 3.626
TRAINING: | Iteration [10/12] | Loss 0.23 | Norm 4.038
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 1.196
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 1.851
Epoch: 1279/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 2.125
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 2.971
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 2.873
TRAINING: | Iteration [4/12] | Loss 0.18 | Norm 2.353
TRAINING: | Iteration [5/12] | Loss 0.14 | Norm 2.121
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.530
TRAINING: | Iteration [7/12] | Loss 0.15 | Norm 2.128
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 1.764
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 1.347
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 1.243
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.373
TRAINING: | Iteration [12/12] | Loss 0.19 | Norm 2.713
Epoch: 1280/10000 | Epoch Time: 0.101 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.096
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 1.019
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 1.465
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 1.322
TRAINING: | Iteration [5/12] | Loss 0.14 | Norm 2.395
TRAINING: | Iteration [6/12] | Loss 0.15 | Norm 3.254
TRAINING: | Iteration [7/12] | Loss 0.41 | Norm 5.000
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 2.485
TRAINING: | Iteration [9/12] | Loss 0.21 | Norm 2.973
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 1.468
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 0.891
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 2.378
Epoch: 1281/10000 | Epoch Time: 0.121 seconds
TRAINING: | Iteration [1/12] | Loss 0.17 | Norm 2.795
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 3.298
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 2.183
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 1.486
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.400
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.376
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 0.807
TRAINING: | Iteration [8/12] | Loss 0.15 | Norm 2.517
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 2.411
TRAINING: | Iteration [10/12] | Loss 0.16 | Norm 2.872
TRAINING: | Iteration [11/12] | Loss 0.07 | Norm 0.901
TRAINING: | Iteration [12/12] | Loss 0.17 | Norm 2.440
Epoch: 1282/10000 | Epoch Time: 0.117 seconds
TRAINING: | Iteration [1/12] | Loss 0.14 | Norm 2.607
TRAINING: | Iteration [2/12] | Loss 0.15 | Norm 2.231
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.178
TRAINING: | Iteration [4/12] | Loss 0.15 | Norm 2.581
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 0.683
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 1.535
TRAINING: | Iteration [7/12] | Loss 0.17 | Norm 3.102
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 3.005
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.377
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 1.833
TRAINING: | Iteration [11/12] | Loss 0.16 | Norm 1.603
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 2.306
Epoch: 1283/10000 | Epoch Time: 0.116 seconds
TRAINING: | Iteration [1/12] | Loss 0.19 | Norm 2.947
TRAINING: | Iteration [2/12] | Loss 0.16 | Norm 2.852
TRAINING: | Iteration [3/12] | Loss 0.14 | Norm 2.208
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 2.212
TRAINING: | Iteration [5/12] | Loss 0.31 | Norm 4.651
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 2.196
TRAINING: | Iteration [7/12] | Loss 0.22 | Norm 4.076
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 3.418
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 2.618
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 2.037
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 1.481
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 2.260
Epoch: 1284/10000 | Epoch Time: 0.106 seconds
TRAINING: | Iteration [1/12] | Loss 0.22 | Norm 4.136
TRAINING: | Iteration [2/12] | Loss 0.15 | Norm 3.617
TRAINING: | Iteration [3/12] | Loss 0.17 | Norm 4.051
TRAINING: | Iteration [4/12] | Loss 0.33 | Norm 5.000
TRAINING: | Iteration [5/12] | Loss 0.15 | Norm 3.105
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.046
TRAINING: | Iteration [7/12] | Loss 0.38 | Norm 5.000
TRAINING: | Iteration [8/12] | Loss 0.24 | Norm 4.117
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 2.575
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 2.432
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 1.449
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 3.136
Epoch: 1285/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.16 | Norm 2.843
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 0.993
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 1.634
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 2.948
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 1.404
TRAINING: | Iteration [6/12] | Loss 0.14 | Norm 2.774
TRAINING: | Iteration [7/12] | Loss 0.30 | Norm 4.986
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 1.999
TRAINING: | Iteration [9/12] | Loss 0.35 | Norm 4.490
TRAINING: | Iteration [10/12] | Loss 0.23 | Norm 4.153
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 1.667
TRAINING: | Iteration [12/12] | Loss 0.24 | Norm 4.076
Epoch: 1286/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.42 | Norm 5.000
TRAINING: | Iteration [2/12] | Loss 0.14 | Norm 2.687
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 1.500
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 1.860
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.864
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.091
TRAINING: | Iteration [7/12] | Loss 0.13 | Norm 1.596
TRAINING: | Iteration [8/12] | Loss 0.16 | Norm 3.305
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 1.001
TRAINING: | Iteration [10/12] | Loss 0.29 | Norm 3.880
TRAINING: | Iteration [11/12] | Loss 0.14 | Norm 2.117
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 1.716
Epoch: 1287/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.20 | Norm 3.103
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 1.091
TRAINING: | Iteration [3/12] | Loss 0.24 | Norm 4.729
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 2.685
TRAINING: | Iteration [5/12] | Loss 0.37 | Norm 5.000
TRAINING: | Iteration [6/12] | Loss 0.15 | Norm 2.913
TRAINING: | Iteration [7/12] | Loss 0.22 | Norm 3.891
TRAINING: | Iteration [8/12] | Loss 0.17 | Norm 2.710
TRAINING: | Iteration [9/12] | Loss 0.16 | Norm 2.687
TRAINING: | Iteration [10/12] | Loss 0.20 | Norm 2.947
TRAINING: | Iteration [11/12] | Loss 0.32 | Norm 5.000
TRAINING: | Iteration [12/12] | Loss 0.17 | Norm 4.609
Epoch: 1288/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 1.775
TRAINING: | Iteration [2/12] | Loss 0.25 | Norm 4.531
TRAINING: | Iteration [3/12] | Loss 0.28 | Norm 4.130
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.747
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 3.137
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 2.533
TRAINING: | Iteration [7/12] | Loss 0.20 | Norm 4.026
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 1.117
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 2.165
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 2.415
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 4.408
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 2.273
Epoch: 1289/10000 | Epoch Time: 0.116 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 2.027
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.193
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 1.360
TRAINING: | Iteration [4/12] | Loss 0.27 | Norm 4.256
TRAINING: | Iteration [5/12] | Loss 0.16 | Norm 3.303
TRAINING: | Iteration [6/12] | Loss 0.23 | Norm 4.165
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 1.590
TRAINING: | Iteration [8/12] | Loss 0.18 | Norm 1.421
TRAINING: | Iteration [9/12] | Loss 0.18 | Norm 3.212
TRAINING: | Iteration [10/12] | Loss 0.16 | Norm 2.197
TRAINING: | Iteration [11/12] | Loss 0.16 | Norm 2.479
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 2.169
Epoch: 1290/10000 | Epoch Time: 0.101 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.102
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 3.016
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 1.385
TRAINING: | Iteration [4/12] | Loss 0.14 | Norm 2.481
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 2.710
TRAINING: | Iteration [6/12] | Loss 0.20 | Norm 2.684
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 0.738
TRAINING: | Iteration [8/12] | Loss 0.25 | Norm 4.193
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.116
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 2.061
TRAINING: | Iteration [11/12] | Loss 0.15 | Norm 3.019
TRAINING: | Iteration [12/12] | Loss 0.21 | Norm 3.912
Epoch: 1291/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 1.974
TRAINING: | Iteration [2/12] | Loss 0.07 | Norm 1.146
TRAINING: | Iteration [3/12] | Loss 0.20 | Norm 2.758
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 2.054
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.256
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 2.231
TRAINING: | Iteration [7/12] | Loss 0.49 | Norm 5.000
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 2.170
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 2.755
TRAINING: | Iteration [10/12] | Loss 0.24 | Norm 3.272
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 2.564
TRAINING: | Iteration [12/12] | Loss 0.16 | Norm 3.137
Epoch: 1292/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.14 | Norm 1.463
TRAINING: | Iteration [2/12] | Loss 0.16 | Norm 1.298
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.778
TRAINING: | Iteration [4/12] | Loss 0.20 | Norm 2.687
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.076
TRAINING: | Iteration [6/12] | Loss 0.17 | Norm 2.761
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.374
TRAINING: | Iteration [8/12] | Loss 0.15 | Norm 2.975
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 1.569
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 2.577
TRAINING: | Iteration [11/12] | Loss 0.18 | Norm 2.652
TRAINING: | Iteration [12/12] | Loss 0.15 | Norm 2.790
Epoch: 1293/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.16 | Norm 3.166
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.325
TRAINING: | Iteration [3/12] | Loss 0.19 | Norm 4.001
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 1.978
TRAINING: | Iteration [5/12] | Loss 0.17 | Norm 3.629
TRAINING: | Iteration [6/12] | Loss 0.24 | Norm 4.207
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 1.728
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 1.304
TRAINING: | Iteration [9/12] | Loss 0.14 | Norm 3.186
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 0.519
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.077
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 1.710
Epoch: 1294/10000 | Epoch Time: 0.106 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 1.921
TRAINING: | Iteration [2/12] | Loss 0.20 | Norm 2.989
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 1.880
TRAINING: | Iteration [4/12] | Loss 0.26 | Norm 4.605
TRAINING: | Iteration [5/12] | Loss 0.14 | Norm 2.568
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 3.017
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 0.830
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.396
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 1.277
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 1.386
TRAINING: | Iteration [11/12] | Loss 0.21 | Norm 3.004
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 1.470
Epoch: 1295/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.17 | Norm 3.765
TRAINING: | Iteration [2/12] | Loss 0.33 | Norm 5.000
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 1.148
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 1.885
TRAINING: | Iteration [5/12] | Loss 0.20 | Norm 3.810
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 2.253
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.521
TRAINING: | Iteration [8/12] | Loss 0.30 | Norm 4.427
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 1.056
TRAINING: | Iteration [10/12] | Loss 0.16 | Norm 3.152
TRAINING: | Iteration [11/12] | Loss 0.28 | Norm 5.000
TRAINING: | Iteration [12/12] | Loss 0.19 | Norm 2.556
Epoch: 1296/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.25 | Norm 4.887
TRAINING: | Iteration [2/12] | Loss 0.16 | Norm 2.339
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 1.600
TRAINING: | Iteration [4/12] | Loss 0.22 | Norm 5.000
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 0.509
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 2.195
TRAINING: | Iteration [7/12] | Loss 0.14 | Norm 1.250
TRAINING: | Iteration [8/12] | Loss 0.52 | Norm 5.000
TRAINING: | Iteration [9/12] | Loss 0.17 | Norm 4.080
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 1.748
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.107
TRAINING: | Iteration [12/12] | Loss 0.18 | Norm 3.694
Epoch: 1297/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 2.074
TRAINING: | Iteration [2/12] | Loss 0.23 | Norm 4.150
TRAINING: | Iteration [3/12] | Loss 0.15 | Norm 2.144
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 2.300
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.479
TRAINING: | Iteration [6/12] | Loss 0.15 | Norm 1.275
TRAINING: | Iteration [7/12] | Loss 0.13 | Norm 1.912
TRAINING: | Iteration [8/12] | Loss 0.35 | Norm 5.000
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 1.844
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 2.216
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 1.140
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 1.878
Epoch: 1298/10000 | Epoch Time: 0.119 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 2.620
TRAINING: | Iteration [2/12] | Loss 0.15 | Norm 2.594
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 1.582
TRAINING: | Iteration [4/12] | Loss 0.27 | Norm 4.766
TRAINING: | Iteration [5/12] | Loss 0.20 | Norm 3.468
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 3.406
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 1.902
TRAINING: | Iteration [8/12] | Loss 0.20 | Norm 3.258
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 3.074
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 1.874
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 1.264
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 2.252
Epoch: 1299/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.31 | Norm 4.874
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 1.955
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 1.988
TRAINING: | Iteration [4/12] | Loss 0.17 | Norm 3.508
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 0.823
TRAINING: | Iteration [6/12] | Loss 0.14 | Norm 1.772
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 2.169
TRAINING: | Iteration [8/12] | Loss 0.15 | Norm 2.927
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 1.676
TRAINING: | Iteration [10/12] | Loss 0.15 | Norm 3.305
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 0.698
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 1.935
Epoch: 1300/10000 | Epoch Time: 0.103 seconds
Saving Model
Preparation of Training Data time: 73.427 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 1.341
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 2.436
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 1.315
TRAINING: | Iteration [4/12] | Loss 0.14 | Norm 2.283
TRAINING: | Iteration [5/12] | Loss 0.17 | Norm 2.433
TRAINING: | Iteration [6/12] | Loss 0.14 | Norm 2.402
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 1.670
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.422
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 1.104
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 2.233
TRAINING: | Iteration [11/12] | Loss 0.17 | Norm 4.144
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 1.707
Epoch: 1301/10000 | Epoch Time: 0.107 seconds
TRAINING: | Iteration [1/12] | Loss 0.17 | Norm 2.720
TRAINING: | Iteration [2/12] | Loss 0.14 | Norm 2.464
TRAINING: | Iteration [3/12] | Loss 0.24 | Norm 4.068
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 1.572
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.710
TRAINING: | Iteration [6/12] | Loss 0.18 | Norm 4.057
TRAINING: | Iteration [7/12] | Loss 0.38 | Norm 5.000
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 1.765
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 1.651
TRAINING: | Iteration [10/12] | Loss 0.25 | Norm 5.000
TRAINING: | Iteration [11/12] | Loss 0.14 | Norm 2.399
TRAINING: | Iteration [12/12] | Loss 0.15 | Norm 3.027
Epoch: 1302/10000 | Epoch Time: 0.107 seconds
TRAINING: | Iteration [1/12] | Loss 0.14 | Norm 3.418
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.225
TRAINING: | Iteration [3/12] | Loss 0.20 | Norm 2.825
TRAINING: | Iteration [4/12] | Loss 0.16 | Norm 3.493
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 2.302
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 2.668
TRAINING: | Iteration [7/12] | Loss 0.15 | Norm 2.450
TRAINING: | Iteration [8/12] | Loss 0.35 | Norm 5.000
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 1.266
TRAINING: | Iteration [10/12] | Loss 0.15 | Norm 2.709
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 1.023
TRAINING: | Iteration [12/12] | Loss 0.18 | Norm 2.912
Epoch: 1303/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 1.164
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 0.752
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 1.200
TRAINING: | Iteration [4/12] | Loss 0.16 | Norm 3.050
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 0.756
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.306
TRAINING: | Iteration [7/12] | Loss 0.16 | Norm 3.082
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 1.811
TRAINING: | Iteration [9/12] | Loss 0.14 | Norm 1.507
TRAINING: | Iteration [10/12] | Loss 0.17 | Norm 3.045
TRAINING: | Iteration [11/12] | Loss 0.14 | Norm 2.533
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 2.596
Epoch: 1304/10000 | Epoch Time: 0.116 seconds
TRAINING: | Iteration [1/12] | Loss 0.14 | Norm 2.559
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.841
TRAINING: | Iteration [3/12] | Loss 0.14 | Norm 2.816
TRAINING: | Iteration [4/12] | Loss 0.18 | Norm 4.030
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 2.065
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 2.145
TRAINING: | Iteration [7/12] | Loss 0.15 | Norm 3.788
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 4.304
TRAINING: | Iteration [9/12] | Loss 0.21 | Norm 4.085
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.255
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 2.655
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 2.587
Epoch: 1305/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 2.874
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 4.168
TRAINING: | Iteration [3/12] | Loss 0.18 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 1.509
TRAINING: | Iteration [5/12] | Loss 0.19 | Norm 3.994
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 2.308
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 4.553
TRAINING: | Iteration [8/12] | Loss 0.32 | Norm 5.000
TRAINING: | Iteration [9/12] | Loss 0.28 | Norm 4.418
TRAINING: | Iteration [10/12] | Loss 0.23 | Norm 4.702
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 2.577
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 2.852
Epoch: 1306/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 3.235
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 2.554
TRAINING: | Iteration [3/12] | Loss 0.15 | Norm 2.388
TRAINING: | Iteration [4/12] | Loss 0.17 | Norm 3.371
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 2.060
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 4.644
TRAINING: | Iteration [7/12] | Loss 0.19 | Norm 5.000
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.096
TRAINING: | Iteration [9/12] | Loss 0.22 | Norm 3.523
TRAINING: | Iteration [10/12] | Loss 0.18 | Norm 4.524
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 1.704
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 1.256
Epoch: 1307/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 2.736
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 1.121
TRAINING: | Iteration [3/12] | Loss 0.32 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 0.16 | Norm 3.829
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 4.385
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 1.228
TRAINING: | Iteration [7/12] | Loss 0.16 | Norm 2.177
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 2.095
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.013
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 2.252
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 0.551
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 1.484
Epoch: 1308/10000 | Epoch Time: 0.100 seconds
TRAINING: | Iteration [1/12] | Loss 0.15 | Norm 4.791
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 2.009
TRAINING: | Iteration [3/12] | Loss 0.22 | Norm 4.093
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 0.889
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 1.317
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 2.356
TRAINING: | Iteration [7/12] | Loss 0.07 | Norm 1.002
TRAINING: | Iteration [8/12] | Loss 0.17 | Norm 3.254
TRAINING: | Iteration [9/12] | Loss 0.26 | Norm 5.000
TRAINING: | Iteration [10/12] | Loss 0.45 | Norm 5.000
TRAINING: | Iteration [11/12] | Loss 0.14 | Norm 2.357
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 1.117
Epoch: 1309/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.16 | Norm 3.389
TRAINING: | Iteration [2/12] | Loss 0.17 | Norm 3.028
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 2.281
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 1.778
TRAINING: | Iteration [5/12] | Loss 0.20 | Norm 3.701
TRAINING: | Iteration [6/12] | Loss 0.17 | Norm 3.451
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 3.563
TRAINING: | Iteration [8/12] | Loss 0.39 | Norm 5.000
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.318
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 2.930
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 2.875
TRAINING: | Iteration [12/12] | Loss 0.21 | Norm 3.264
Epoch: 1310/10000 | Epoch Time: 0.103 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 2.752
TRAINING: | Iteration [2/12] | Loss 0.16 | Norm 2.326
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 2.394
TRAINING: | Iteration [4/12] | Loss 0.19 | Norm 2.621
TRAINING: | Iteration [5/12] | Loss 0.19 | Norm 3.513
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 1.791
TRAINING: | Iteration [7/12] | Loss 0.16 | Norm 3.328
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 2.201
TRAINING: | Iteration [9/12] | Loss 0.18 | Norm 2.828
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 2.582
TRAINING: | Iteration [11/12] | Loss 0.14 | Norm 2.422
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 2.114
Epoch: 1311/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.14 | Norm 2.651
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 2.836
TRAINING: | Iteration [3/12] | Loss 0.15 | Norm 3.702
TRAINING: | Iteration [4/12] | Loss 0.17 | Norm 2.619
TRAINING: | Iteration [5/12] | Loss 0.17 | Norm 2.309
TRAINING: | Iteration [6/12] | Loss 0.18 | Norm 4.582
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 1.751
TRAINING: | Iteration [8/12] | Loss 0.23 | Norm 4.484
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 1.816
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 3.743
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 2.136
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.260
Epoch: 1312/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.22 | Norm 4.094
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 1.961
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 3.131
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 1.912
TRAINING: | Iteration [5/12] | Loss 0.34 | Norm 5.000
TRAINING: | Iteration [6/12] | Loss 0.20 | Norm 3.575
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 1.715
TRAINING: | Iteration [8/12] | Loss 0.26 | Norm 4.441
TRAINING: | Iteration [9/12] | Loss 0.23 | Norm 3.859
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 1.787
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 2.333
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 0.729
Epoch: 1313/10000 | Epoch Time: 0.116 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 3.342
TRAINING: | Iteration [2/12] | Loss 0.19 | Norm 4.535
TRAINING: | Iteration [3/12] | Loss 0.31 | Norm 4.861
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 1.894
TRAINING: | Iteration [5/12] | Loss 0.15 | Norm 4.377
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 2.338
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 1.913
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 1.561
TRAINING: | Iteration [9/12] | Loss 0.23 | Norm 3.556
TRAINING: | Iteration [10/12] | Loss 0.33 | Norm 5.000
TRAINING: | Iteration [11/12] | Loss 0.15 | Norm 3.363
TRAINING: | Iteration [12/12] | Loss 0.17 | Norm 2.505
Epoch: 1314/10000 | Epoch Time: 0.116 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.283
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 1.208
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 1.914
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 1.992
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 2.740
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 2.036
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.049
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 2.279
TRAINING: | Iteration [9/12] | Loss 0.16 | Norm 3.586
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 1.585
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 2.177
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.140
Epoch: 1315/10000 | Epoch Time: 0.118 seconds
TRAINING: | Iteration [1/12] | Loss 0.14 | Norm 2.744
TRAINING: | Iteration [2/12] | Loss 0.15 | Norm 2.823
TRAINING: | Iteration [3/12] | Loss 0.14 | Norm 2.202
TRAINING: | Iteration [4/12] | Loss 0.15 | Norm 2.516
TRAINING: | Iteration [5/12] | Loss 0.16 | Norm 2.362
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 1.266
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 1.898
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 1.184
TRAINING: | Iteration [9/12] | Loss 0.16 | Norm 3.335
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 2.608
TRAINING: | Iteration [11/12] | Loss 0.15 | Norm 2.645
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 2.144
Epoch: 1316/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 1.262
TRAINING: | Iteration [2/12] | Loss 0.52 | Norm 5.000
TRAINING: | Iteration [3/12] | Loss 0.15 | Norm 2.744
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 0.889
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 2.452
TRAINING: | Iteration [6/12] | Loss 0.17 | Norm 3.386
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 1.340
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.187
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 1.439
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.425
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 3.445
TRAINING: | Iteration [12/12] | Loss 0.16 | Norm 5.000
Epoch: 1317/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 2.062
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 1.699
TRAINING: | Iteration [3/12] | Loss 0.15 | Norm 3.932
TRAINING: | Iteration [4/12] | Loss 0.14 | Norm 4.158
TRAINING: | Iteration [5/12] | Loss 0.16 | Norm 4.442
TRAINING: | Iteration [6/12] | Loss 0.17 | Norm 2.646
TRAINING: | Iteration [7/12] | Loss 0.15 | Norm 2.460
TRAINING: | Iteration [8/12] | Loss 0.26 | Norm 4.572
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 3.099
TRAINING: | Iteration [10/12] | Loss 0.22 | Norm 4.840
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 3.302
TRAINING: | Iteration [12/12] | Loss 0.16 | Norm 3.255
Epoch: 1318/10000 | Epoch Time: 0.105 seconds
TRAINING: | Iteration [1/12] | Loss 0.15 | Norm 2.500
TRAINING: | Iteration [2/12] | Loss 0.19 | Norm 3.672
TRAINING: | Iteration [3/12] | Loss 0.14 | Norm 2.194
TRAINING: | Iteration [4/12] | Loss 0.15 | Norm 2.537
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 1.896
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 1.835
TRAINING: | Iteration [7/12] | Loss 0.13 | Norm 3.109
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 2.093
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.116
TRAINING: | Iteration [10/12] | Loss 0.23 | Norm 3.998
TRAINING: | Iteration [11/12] | Loss 0.19 | Norm 3.500
TRAINING: | Iteration [12/12] | Loss 0.27 | Norm 5.000
Epoch: 1319/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.15 | Norm 3.156
TRAINING: | Iteration [2/12] | Loss 0.25 | Norm 3.741
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 3.300
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 1.639
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.445
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 0.995
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 1.671
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 2.210
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 3.391
TRAINING: | Iteration [10/12] | Loss 0.18 | Norm 2.113
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 1.968
TRAINING: | Iteration [12/12] | Loss 0.15 | Norm 3.979
Epoch: 1320/10000 | Epoch Time: 0.105 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 2.947
TRAINING: | Iteration [2/12] | Loss 0.18 | Norm 4.810
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 2.710
TRAINING: | Iteration [4/12] | Loss 0.15 | Norm 4.118
TRAINING: | Iteration [5/12] | Loss 0.14 | Norm 3.574
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 2.092
TRAINING: | Iteration [7/12] | Loss 0.15 | Norm 3.418
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.857
TRAINING: | Iteration [9/12] | Loss 0.17 | Norm 2.900
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 1.349
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 1.887
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.526
Epoch: 1321/10000 | Epoch Time: 0.106 seconds
TRAINING: | Iteration [1/12] | Loss 0.15 | Norm 1.455
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 1.321
TRAINING: | Iteration [3/12] | Loss 0.18 | Norm 4.609
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 2.172
TRAINING: | Iteration [5/12] | Loss 0.30 | Norm 5.000
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 3.084
TRAINING: | Iteration [7/12] | Loss 0.34 | Norm 5.000
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 1.201
TRAINING: | Iteration [9/12] | Loss 0.26 | Norm 4.158
TRAINING: | Iteration [10/12] | Loss 0.15 | Norm 2.011
TRAINING: | Iteration [11/12] | Loss 0.18 | Norm 3.495
TRAINING: | Iteration [12/12] | Loss 0.33 | Norm 5.000
Epoch: 1322/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 1.099
TRAINING: | Iteration [2/12] | Loss 0.16 | Norm 3.083
TRAINING: | Iteration [3/12] | Loss 0.08 | Norm 0.951
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 1.624
TRAINING: | Iteration [5/12] | Loss 0.14 | Norm 1.341
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 0.567
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 1.130
TRAINING: | Iteration [8/12] | Loss 0.15 | Norm 2.812
TRAINING: | Iteration [9/12] | Loss 0.19 | Norm 2.593
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 2.643
TRAINING: | Iteration [11/12] | Loss 0.14 | Norm 1.617
TRAINING: | Iteration [12/12] | Loss 0.21 | Norm 3.363
Epoch: 1323/10000 | Epoch Time: 0.100 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 3.400
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 1.643
TRAINING: | Iteration [3/12] | Loss 0.21 | Norm 4.144
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 1.180
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 2.707
TRAINING: | Iteration [6/12] | Loss 0.38 | Norm 5.000
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 1.193
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 2.134
TRAINING: | Iteration [9/12] | Loss 0.16 | Norm 2.026
TRAINING: | Iteration [10/12] | Loss 0.18 | Norm 3.923
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 1.104
TRAINING: | Iteration [12/12] | Loss 0.23 | Norm 4.017
Epoch: 1324/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.30 | Norm 4.165
TRAINING: | Iteration [2/12] | Loss 0.22 | Norm 3.300
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 1.456
TRAINING: | Iteration [4/12] | Loss 0.16 | Norm 2.789
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 2.942
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.989
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 2.244
TRAINING: | Iteration [8/12] | Loss 0.21 | Norm 3.224
TRAINING: | Iteration [9/12] | Loss 0.14 | Norm 1.697
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 1.204
TRAINING: | Iteration [11/12] | Loss 0.23 | Norm 4.453
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.098
Epoch: 1325/10000 | Epoch Time: 0.117 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.467
TRAINING: | Iteration [2/12] | Loss 0.15 | Norm 1.098
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 1.849
TRAINING: | Iteration [4/12] | Loss 0.08 | Norm 1.358
TRAINING: | Iteration [5/12] | Loss 0.15 | Norm 1.871
TRAINING: | Iteration [6/12] | Loss 0.17 | Norm 3.734
TRAINING: | Iteration [7/12] | Loss 0.08 | Norm 1.520
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.108
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 1.568
TRAINING: | Iteration [10/12] | Loss 0.17 | Norm 4.073
TRAINING: | Iteration [11/12] | Loss 0.16 | Norm 2.498
TRAINING: | Iteration [12/12] | Loss 0.59 | Norm 5.000
Epoch: 1326/10000 | Epoch Time: 0.116 seconds
TRAINING: | Iteration [1/12] | Loss 0.16 | Norm 2.835
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 1.463
TRAINING: | Iteration [3/12] | Loss 0.20 | Norm 4.183
TRAINING: | Iteration [4/12] | Loss 0.15 | Norm 3.136
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 1.999
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 1.446
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.120
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 2.100
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 1.138
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.255
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 1.097
TRAINING: | Iteration [12/12] | Loss 0.17 | Norm 3.353
Epoch: 1327/10000 | Epoch Time: 0.100 seconds
TRAINING: | Iteration [1/12] | Loss 0.15 | Norm 2.289
TRAINING: | Iteration [2/12] | Loss 0.14 | Norm 3.638
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 2.575
TRAINING: | Iteration [4/12] | Loss 0.16 | Norm 1.637
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 1.775
TRAINING: | Iteration [6/12] | Loss 0.07 | Norm 0.887
TRAINING: | Iteration [7/12] | Loss 0.26 | Norm 4.496
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 2.292
TRAINING: | Iteration [9/12] | Loss 0.15 | Norm 2.163
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 2.136
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 2.247
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.208
Epoch: 1328/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 2.939
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 2.335
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 2.647
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 0.939
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 2.419
TRAINING: | Iteration [6/12] | Loss 0.15 | Norm 3.231
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 0.773
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 1.484
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 1.593
TRAINING: | Iteration [10/12] | Loss 0.22 | Norm 3.130
TRAINING: | Iteration [11/12] | Loss 0.17 | Norm 2.349
TRAINING: | Iteration [12/12] | Loss 0.16 | Norm 2.490
Epoch: 1329/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.833
TRAINING: | Iteration [2/12] | Loss 0.17 | Norm 2.140
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 1.784
TRAINING: | Iteration [4/12] | Loss 0.28 | Norm 3.758
TRAINING: | Iteration [5/12] | Loss 0.21 | Norm 3.671
TRAINING: | Iteration [6/12] | Loss 0.14 | Norm 1.954
TRAINING: | Iteration [7/12] | Loss 0.13 | Norm 1.846
TRAINING: | Iteration [8/12] | Loss 0.22 | Norm 3.948
TRAINING: | Iteration [9/12] | Loss 0.14 | Norm 2.468
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 1.552
TRAINING: | Iteration [11/12] | Loss 0.15 | Norm 2.232
TRAINING: | Iteration [12/12] | Loss 0.23 | Norm 2.318
Epoch: 1330/10000 | Epoch Time: 0.100 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.16 | Norm 2.728
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 1.892
TRAINING: | Iteration [3/12] | Loss 0.20 | Norm 3.863
TRAINING: | Iteration [4/12] | Loss 0.14 | Norm 1.991
TRAINING: | Iteration [5/12] | Loss 0.15 | Norm 3.030
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 2.040
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 1.655
TRAINING: | Iteration [8/12] | Loss 0.15 | Norm 1.816
TRAINING: | Iteration [9/12] | Loss 0.16 | Norm 2.864
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 0.890
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 2.573
TRAINING: | Iteration [12/12] | Loss 0.17 | Norm 3.331
Epoch: 1331/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.17 | Norm 2.785
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 2.396
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 2.273
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 1.274
TRAINING: | Iteration [5/12] | Loss 0.34 | Norm 5.000
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 1.308
TRAINING: | Iteration [7/12] | Loss 0.19 | Norm 3.766
TRAINING: | Iteration [8/12] | Loss 0.15 | Norm 2.313
TRAINING: | Iteration [9/12] | Loss 0.30 | Norm 4.391
TRAINING: | Iteration [10/12] | Loss 0.20 | Norm 3.257
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 1.140
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 1.709
Epoch: 1332/10000 | Epoch Time: 0.116 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.403
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 2.540
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 2.026
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.455
TRAINING: | Iteration [5/12] | Loss 0.24 | Norm 4.165
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 1.539
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 2.435
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 1.685
TRAINING: | Iteration [9/12] | Loss 0.14 | Norm 2.453
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 1.305
TRAINING: | Iteration [11/12] | Loss 0.17 | Norm 3.209
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.441
Epoch: 1333/10000 | Epoch Time: 0.120 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 1.888
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 1.693
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 2.388
TRAINING: | Iteration [4/12] | Loss 0.15 | Norm 2.142
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 2.012
TRAINING: | Iteration [6/12] | Loss 0.16 | Norm 2.486
TRAINING: | Iteration [7/12] | Loss 0.13 | Norm 2.144
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 1.970
TRAINING: | Iteration [9/12] | Loss 0.18 | Norm 2.940
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 1.394
TRAINING: | Iteration [11/12] | Loss 0.24 | Norm 3.331
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 1.819
Epoch: 1334/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.21 | Norm 3.734
TRAINING: | Iteration [2/12] | Loss 0.14 | Norm 2.104
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 1.879
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 2.213
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 1.697
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.442
TRAINING: | Iteration [7/12] | Loss 0.14 | Norm 2.562
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 1.311
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 1.392
TRAINING: | Iteration [10/12] | Loss 0.26 | Norm 3.948
TRAINING: | Iteration [11/12] | Loss 0.34 | Norm 5.000
TRAINING: | Iteration [12/12] | Loss 0.16 | Norm 4.015
Epoch: 1335/10000 | Epoch Time: 0.100 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 0.844
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 0.987
TRAINING: | Iteration [3/12] | Loss 0.14 | Norm 3.842
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.694
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.115
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 2.297
TRAINING: | Iteration [7/12] | Loss 0.20 | Norm 2.984
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.082
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 1.958
TRAINING: | Iteration [10/12] | Loss 0.18 | Norm 4.679
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.713
TRAINING: | Iteration [12/12] | Loss 0.16 | Norm 2.310
Epoch: 1336/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 2.436
TRAINING: | Iteration [2/12] | Loss 0.22 | Norm 3.216
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.477
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 2.994
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 3.030
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 2.149
TRAINING: | Iteration [7/12] | Loss 0.15 | Norm 2.074
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 1.775
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 2.129
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 1.167
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 2.731
TRAINING: | Iteration [12/12] | Loss 0.20 | Norm 2.715
Epoch: 1337/10000 | Epoch Time: 0.118 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 1.557
TRAINING: | Iteration [2/12] | Loss 0.08 | Norm 0.929
TRAINING: | Iteration [3/12] | Loss 0.17 | Norm 2.231
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 1.899
TRAINING: | Iteration [5/12] | Loss 0.14 | Norm 2.196
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 2.206
TRAINING: | Iteration [7/12] | Loss 0.19 | Norm 3.795
TRAINING: | Iteration [8/12] | Loss 0.19 | Norm 3.434
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 2.030
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 0.856
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 1.639
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 2.396
Epoch: 1338/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.08 | Norm 1.184
TRAINING: | Iteration [2/12] | Loss 0.18 | Norm 2.647
TRAINING: | Iteration [3/12] | Loss 0.21 | Norm 2.286
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 1.451
TRAINING: | Iteration [5/12] | Loss 0.25 | Norm 3.869
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 1.841
TRAINING: | Iteration [7/12] | Loss 0.23 | Norm 2.053
TRAINING: | Iteration [8/12] | Loss 0.17 | Norm 3.275
TRAINING: | Iteration [9/12] | Loss 0.14 | Norm 2.732
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 2.612
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 2.294
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 1.571
Epoch: 1339/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.20 | Norm 3.185
TRAINING: | Iteration [2/12] | Loss 0.16 | Norm 2.886
TRAINING: | Iteration [3/12] | Loss 0.18 | Norm 3.754
TRAINING: | Iteration [4/12] | Loss 0.37 | Norm 5.000
TRAINING: | Iteration [5/12] | Loss 0.14 | Norm 3.512
TRAINING: | Iteration [6/12] | Loss 0.14 | Norm 2.607
TRAINING: | Iteration [7/12] | Loss 0.15 | Norm 3.114
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.831
TRAINING: | Iteration [9/12] | Loss 0.18 | Norm 3.802
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 3.024
TRAINING: | Iteration [11/12] | Loss 0.35 | Norm 5.000
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 1.636
Epoch: 1340/10000 | Epoch Time: 0.103 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 3.553
TRAINING: | Iteration [2/12] | Loss 0.17 | Norm 4.155
TRAINING: | Iteration [3/12] | Loss 0.20 | Norm 3.353
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 2.240
TRAINING: | Iteration [5/12] | Loss 0.07 | Norm 1.228
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.489
TRAINING: | Iteration [7/12] | Loss 0.13 | Norm 2.166
TRAINING: | Iteration [8/12] | Loss 0.17 | Norm 3.263
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.121
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 2.238
TRAINING: | Iteration [11/12] | Loss 0.20 | Norm 3.540
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 2.581
Epoch: 1341/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.29 | Norm 3.730
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 1.390
TRAINING: | Iteration [3/12] | Loss 0.17 | Norm 4.124
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 3.135
TRAINING: | Iteration [5/12] | Loss 0.14 | Norm 2.427
TRAINING: | Iteration [6/12] | Loss 0.14 | Norm 1.230
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 1.641
TRAINING: | Iteration [8/12] | Loss 0.25 | Norm 3.461
TRAINING: | Iteration [9/12] | Loss 0.17 | Norm 2.670
TRAINING: | Iteration [10/12] | Loss 0.15 | Norm 3.041
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 2.376
TRAINING: | Iteration [12/12] | Loss 0.08 | Norm 1.306
Epoch: 1342/10000 | Epoch Time: 0.117 seconds
TRAINING: | Iteration [1/12] | Loss 0.17 | Norm 3.400
TRAINING: | Iteration [2/12] | Loss 0.17 | Norm 2.023
TRAINING: | Iteration [3/12] | Loss 0.14 | Norm 1.196
TRAINING: | Iteration [4/12] | Loss 0.21 | Norm 3.555
TRAINING: | Iteration [5/12] | Loss 0.21 | Norm 4.704
TRAINING: | Iteration [6/12] | Loss 0.16 | Norm 3.204
TRAINING: | Iteration [7/12] | Loss 0.14 | Norm 1.595
TRAINING: | Iteration [8/12] | Loss 0.16 | Norm 3.729
TRAINING: | Iteration [9/12] | Loss 0.08 | Norm 1.294
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 1.085
TRAINING: | Iteration [11/12] | Loss 0.27 | Norm 5.000
TRAINING: | Iteration [12/12] | Loss 0.25 | Norm 5.000
Epoch: 1343/10000 | Epoch Time: 0.116 seconds
TRAINING: | Iteration [1/12] | Loss 0.15 | Norm 4.531
TRAINING: | Iteration [2/12] | Loss 0.16 | Norm 4.005
TRAINING: | Iteration [3/12] | Loss 0.14 | Norm 2.229
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 1.350
TRAINING: | Iteration [5/12] | Loss 0.23 | Norm 5.000
TRAINING: | Iteration [6/12] | Loss 0.15 | Norm 3.927
TRAINING: | Iteration [7/12] | Loss 0.14 | Norm 1.535
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 1.853
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 2.623
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 1.289
TRAINING: | Iteration [11/12] | Loss 0.08 | Norm 0.988
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 2.716
Epoch: 1344/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.657
TRAINING: | Iteration [2/12] | Loss 0.15 | Norm 2.869
TRAINING: | Iteration [3/12] | Loss 0.15 | Norm 3.092
TRAINING: | Iteration [4/12] | Loss 0.17 | Norm 3.219
TRAINING: | Iteration [5/12] | Loss 0.15 | Norm 3.237
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 1.515
TRAINING: | Iteration [7/12] | Loss 0.30 | Norm 4.665
TRAINING: | Iteration [8/12] | Loss 0.15 | Norm 2.325
TRAINING: | Iteration [9/12] | Loss 0.07 | Norm 1.028
TRAINING: | Iteration [10/12] | Loss 0.24 | Norm 3.526
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 1.856
TRAINING: | Iteration [12/12] | Loss 0.21 | Norm 4.072
Epoch: 1345/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.07 | Norm 0.700
TRAINING: | Iteration [2/12] | Loss 0.24 | Norm 4.286
TRAINING: | Iteration [3/12] | Loss 0.34 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 0.15 | Norm 2.422
TRAINING: | Iteration [5/12] | Loss 0.14 | Norm 3.881
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 1.543
TRAINING: | Iteration [7/12] | Loss 0.16 | Norm 2.964
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.656
TRAINING: | Iteration [9/12] | Loss 0.40 | Norm 5.000
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 3.199
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 1.048
TRAINING: | Iteration [12/12] | Loss 0.19 | Norm 1.628
Epoch: 1346/10000 | Epoch Time: 0.100 seconds
TRAINING: | Iteration [1/12] | Loss 0.37 | Norm 5.000
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 2.510
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 2.849
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 1.875
TRAINING: | Iteration [5/12] | Loss 0.14 | Norm 3.137
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 2.223
TRAINING: | Iteration [7/12] | Loss 0.15 | Norm 3.450
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 2.158
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 1.979
TRAINING: | Iteration [10/12] | Loss 0.18 | Norm 3.225
TRAINING: | Iteration [11/12] | Loss 0.16 | Norm 3.555
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 1.448
Epoch: 1347/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.23 | Norm 4.683
TRAINING: | Iteration [2/12] | Loss 0.34 | Norm 5.000
TRAINING: | Iteration [3/12] | Loss 0.47 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 0.17 | Norm 3.901
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 2.808
TRAINING: | Iteration [6/12] | Loss 0.22 | Norm 4.310
TRAINING: | Iteration [7/12] | Loss 0.13 | Norm 1.701
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 2.135
TRAINING: | Iteration [9/12] | Loss 0.21 | Norm 3.389
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 2.430
TRAINING: | Iteration [11/12] | Loss 0.14 | Norm 2.987
TRAINING: | Iteration [12/12] | Loss 0.07 | Norm 0.774
Epoch: 1348/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.461
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 2.811
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 1.157
TRAINING: | Iteration [4/12] | Loss 0.10 | Norm 2.202
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 1.642
TRAINING: | Iteration [6/12] | Loss 0.24 | Norm 3.193
TRAINING: | Iteration [7/12] | Loss 0.20 | Norm 3.481
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 1.961
TRAINING: | Iteration [9/12] | Loss 0.20 | Norm 3.669
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 2.580
TRAINING: | Iteration [11/12] | Loss 0.28 | Norm 4.565
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 1.691
Epoch: 1349/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.09 | Norm 1.659
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 3.058
TRAINING: | Iteration [3/12] | Loss 0.25 | Norm 4.081
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 2.229
TRAINING: | Iteration [5/12] | Loss 0.25 | Norm 3.706
TRAINING: | Iteration [6/12] | Loss 0.29 | Norm 4.714
TRAINING: | Iteration [7/12] | Loss 0.13 | Norm 2.637
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.481
TRAINING: | Iteration [9/12] | Loss 0.14 | Norm 3.394
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 3.124
TRAINING: | Iteration [11/12] | Loss 0.24 | Norm 3.985
TRAINING: | Iteration [12/12] | Loss 0.24 | Norm 4.037
Epoch: 1350/10000 | Epoch Time: 0.101 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 3.802
TRAINING: | Iteration [2/12] | Loss 0.15 | Norm 3.126
TRAINING: | Iteration [3/12] | Loss 0.15 | Norm 2.919
TRAINING: | Iteration [4/12] | Loss 0.14 | Norm 3.195
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 1.080
TRAINING: | Iteration [6/12] | Loss 0.16 | Norm 1.887
TRAINING: | Iteration [7/12] | Loss 0.16 | Norm 2.632
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 1.556
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 2.078
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 2.304
TRAINING: | Iteration [11/12] | Loss 0.23 | Norm 4.306
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 1.425
Epoch: 1351/10000 | Epoch Time: 0.118 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 1.680
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 1.844
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 0.765
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 1.339
TRAINING: | Iteration [5/12] | Loss 0.14 | Norm 2.408
TRAINING: | Iteration [6/12] | Loss 0.21 | Norm 2.461
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 1.541
TRAINING: | Iteration [8/12] | Loss 0.17 | Norm 3.049
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 1.599
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 3.311
TRAINING: | Iteration [11/12] | Loss 0.19 | Norm 4.173
TRAINING: | Iteration [12/12] | Loss 0.22 | Norm 3.976
Epoch: 1352/10000 | Epoch Time: 0.114 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 1.469
TRAINING: | Iteration [2/12] | Loss 0.14 | Norm 2.543
TRAINING: | Iteration [3/12] | Loss 0.18 | Norm 2.658
TRAINING: | Iteration [4/12] | Loss 0.15 | Norm 2.090
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.352
TRAINING: | Iteration [6/12] | Loss 0.17 | Norm 3.842
TRAINING: | Iteration [7/12] | Loss 0.20 | Norm 4.097
TRAINING: | Iteration [8/12] | Loss 0.17 | Norm 3.473
TRAINING: | Iteration [9/12] | Loss 0.18 | Norm 2.665
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 2.679
TRAINING: | Iteration [11/12] | Loss 0.17 | Norm 2.932
TRAINING: | Iteration [12/12] | Loss 0.15 | Norm 2.219
Epoch: 1353/10000 | Epoch Time: 0.114 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 1.973
TRAINING: | Iteration [2/12] | Loss 0.15 | Norm 1.442
TRAINING: | Iteration [3/12] | Loss 0.21 | Norm 4.303
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 1.950
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 0.697
TRAINING: | Iteration [6/12] | Loss 0.28 | Norm 4.291
TRAINING: | Iteration [7/12] | Loss 0.13 | Norm 1.547
TRAINING: | Iteration [8/12] | Loss 0.09 | Norm 1.318
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 2.408
TRAINING: | Iteration [10/12] | Loss 0.09 | Norm 2.047
TRAINING: | Iteration [11/12] | Loss 0.15 | Norm 2.309
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 1.629
Epoch: 1354/10000 | Epoch Time: 0.112 seconds
TRAINING: | Iteration [1/12] | Loss 0.14 | Norm 2.874
TRAINING: | Iteration [2/12] | Loss 0.15 | Norm 2.709
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.136
TRAINING: | Iteration [4/12] | Loss 0.18 | Norm 3.554
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 1.163
TRAINING: | Iteration [6/12] | Loss 0.19 | Norm 2.898
TRAINING: | Iteration [7/12] | Loss 0.17 | Norm 3.062
TRAINING: | Iteration [8/12] | Loss 0.27 | Norm 4.834
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 2.316
TRAINING: | Iteration [10/12] | Loss 0.16 | Norm 4.045
TRAINING: | Iteration [11/12] | Loss 0.15 | Norm 2.262
TRAINING: | Iteration [12/12] | Loss 0.18 | Norm 1.542
Epoch: 1355/10000 | Epoch Time: 0.113 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 2.769
TRAINING: | Iteration [2/12] | Loss 0.19 | Norm 4.722
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 1.465
TRAINING: | Iteration [4/12] | Loss 0.14 | Norm 2.176
TRAINING: | Iteration [5/12] | Loss 0.14 | Norm 1.966
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 1.417
TRAINING: | Iteration [7/12] | Loss 0.26 | Norm 4.739
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 2.887
TRAINING: | Iteration [9/12] | Loss 0.26 | Norm 3.768
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 1.766
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 1.875
TRAINING: | Iteration [12/12] | Loss 0.16 | Norm 3.416
Epoch: 1356/10000 | Epoch Time: 0.113 seconds
TRAINING: | Iteration [1/12] | Loss 0.16 | Norm 2.617
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 2.364
TRAINING: | Iteration [3/12] | Loss 0.25 | Norm 3.899
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 1.561
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 1.275
TRAINING: | Iteration [6/12] | Loss 0.15 | Norm 1.494
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 2.856
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.257
TRAINING: | Iteration [9/12] | Loss 0.19 | Norm 3.541
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 1.402
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 2.068
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 1.917
Epoch: 1357/10000 | Epoch Time: 0.113 seconds
TRAINING: | Iteration [1/12] | Loss 0.22 | Norm 4.359
TRAINING: | Iteration [2/12] | Loss 0.17 | Norm 2.810
TRAINING: | Iteration [3/12] | Loss 0.07 | Norm 0.715
TRAINING: | Iteration [4/12] | Loss 0.09 | Norm 1.276
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 1.702
TRAINING: | Iteration [6/12] | Loss 0.14 | Norm 2.193
TRAINING: | Iteration [7/12] | Loss 0.16 | Norm 2.298
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.194
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 1.787
TRAINING: | Iteration [10/12] | Loss 0.20 | Norm 3.550
TRAINING: | Iteration [11/12] | Loss 0.22 | Norm 2.853
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 1.693
Epoch: 1358/10000 | Epoch Time: 0.117 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 0.903
TRAINING: | Iteration [2/12] | Loss 0.26 | Norm 3.999
TRAINING: | Iteration [3/12] | Loss 0.17 | Norm 1.475
TRAINING: | Iteration [4/12] | Loss 0.17 | Norm 2.471
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 1.527
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 1.820
TRAINING: | Iteration [7/12] | Loss 0.28 | Norm 4.861
TRAINING: | Iteration [8/12] | Loss 0.18 | Norm 2.995
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 2.269
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 1.880
TRAINING: | Iteration [11/12] | Loss 0.15 | Norm 3.095
TRAINING: | Iteration [12/12] | Loss 0.47 | Norm 5.000
Epoch: 1359/10000 | Epoch Time: 0.119 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 2.217
TRAINING: | Iteration [2/12] | Loss 0.25 | Norm 4.316
TRAINING: | Iteration [3/12] | Loss 0.20 | Norm 3.355
TRAINING: | Iteration [4/12] | Loss 0.15 | Norm 2.083
TRAINING: | Iteration [5/12] | Loss 0.21 | Norm 4.025
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 3.205
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 2.324
TRAINING: | Iteration [8/12] | Loss 0.31 | Norm 4.747
TRAINING: | Iteration [9/12] | Loss 0.14 | Norm 2.188
TRAINING: | Iteration [10/12] | Loss 0.28 | Norm 3.580
TRAINING: | Iteration [11/12] | Loss 0.17 | Norm 3.915
TRAINING: | Iteration [12/12] | Loss 0.15 | Norm 2.243
Epoch: 1360/10000 | Epoch Time: 0.106 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 2.328
TRAINING: | Iteration [2/12] | Loss 0.15 | Norm 1.632
TRAINING: | Iteration [3/12] | Loss 0.19 | Norm 3.154
TRAINING: | Iteration [4/12] | Loss 0.24 | Norm 3.804
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 1.439
TRAINING: | Iteration [6/12] | Loss 0.19 | Norm 3.642
TRAINING: | Iteration [7/12] | Loss 0.18 | Norm 2.540
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 2.108
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 2.602
TRAINING: | Iteration [10/12] | Loss 0.18 | Norm 2.998
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 1.498
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 1.810
Epoch: 1361/10000 | Epoch Time: 0.106 seconds
TRAINING: | Iteration [1/12] | Loss 0.23 | Norm 2.958
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 2.211
TRAINING: | Iteration [3/12] | Loss 0.15 | Norm 2.065
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 2.014
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 0.702
TRAINING: | Iteration [6/12] | Loss 0.15 | Norm 2.011
TRAINING: | Iteration [7/12] | Loss 0.24 | Norm 4.293
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 2.151
TRAINING: | Iteration [9/12] | Loss 0.20 | Norm 3.153
TRAINING: | Iteration [10/12] | Loss 0.26 | Norm 4.344
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 2.224
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 1.526
Epoch: 1362/10000 | Epoch Time: 0.105 seconds
TRAINING: | Iteration [1/12] | Loss 0.15 | Norm 1.857
TRAINING: | Iteration [2/12] | Loss 0.16 | Norm 2.456
TRAINING: | Iteration [3/12] | Loss 0.32 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 1.926
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 1.017
TRAINING: | Iteration [6/12] | Loss 0.25 | Norm 4.814
TRAINING: | Iteration [7/12] | Loss 0.16 | Norm 1.847
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 2.020
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 1.963
TRAINING: | Iteration [10/12] | Loss 0.15 | Norm 2.327
TRAINING: | Iteration [11/12] | Loss 0.20 | Norm 4.364
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 0.896
Epoch: 1363/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.175
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 1.844
TRAINING: | Iteration [3/12] | Loss 0.16 | Norm 3.002
TRAINING: | Iteration [4/12] | Loss 0.35 | Norm 5.000
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.395
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 1.754
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 2.655
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 2.061
TRAINING: | Iteration [9/12] | Loss 0.15 | Norm 2.863
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 1.602
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 1.899
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 1.869
Epoch: 1364/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.14 | Norm 1.744
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 1.967
TRAINING: | Iteration [3/12] | Loss 0.14 | Norm 3.582
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 1.768
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 1.489
TRAINING: | Iteration [6/12] | Loss 0.14 | Norm 2.059
TRAINING: | Iteration [7/12] | Loss 0.13 | Norm 3.023
TRAINING: | Iteration [8/12] | Loss 0.47 | Norm 5.000
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 1.503
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 1.400
TRAINING: | Iteration [11/12] | Loss 0.18 | Norm 2.969
TRAINING: | Iteration [12/12] | Loss 0.29 | Norm 5.000
Epoch: 1365/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.18 | Norm 3.074
TRAINING: | Iteration [2/12] | Loss 0.32 | Norm 5.000
TRAINING: | Iteration [3/12] | Loss 0.30 | Norm 5.000
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 1.909
TRAINING: | Iteration [5/12] | Loss 0.15 | Norm 2.479
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 0.925
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 1.845
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 2.231
TRAINING: | Iteration [9/12] | Loss 0.20 | Norm 3.506
TRAINING: | Iteration [10/12] | Loss 0.19 | Norm 2.380
TRAINING: | Iteration [11/12] | Loss 0.10 | Norm 1.907
TRAINING: | Iteration [12/12] | Loss 0.15 | Norm 2.873
Epoch: 1366/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.16 | Norm 2.423
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 1.961
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 2.201
TRAINING: | Iteration [4/12] | Loss 0.21 | Norm 3.878
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 1.219
TRAINING: | Iteration [6/12] | Loss 0.15 | Norm 2.760
TRAINING: | Iteration [7/12] | Loss 0.09 | Norm 1.196
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.585
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 2.906
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 1.724
TRAINING: | Iteration [11/12] | Loss 0.19 | Norm 2.639
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 1.938
Epoch: 1367/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 2.606
TRAINING: | Iteration [2/12] | Loss 0.31 | Norm 4.982
TRAINING: | Iteration [3/12] | Loss 0.20 | Norm 2.886
TRAINING: | Iteration [4/12] | Loss 0.29 | Norm 5.000
TRAINING: | Iteration [5/12] | Loss 0.10 | Norm 2.951
TRAINING: | Iteration [6/12] | Loss 0.15 | Norm 2.442
TRAINING: | Iteration [7/12] | Loss 0.23 | Norm 4.257
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.541
TRAINING: | Iteration [9/12] | Loss 0.23 | Norm 3.862
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 1.952
TRAINING: | Iteration [11/12] | Loss 0.18 | Norm 3.832
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 2.281
Epoch: 1368/10000 | Epoch Time: 0.118 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 1.687
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 2.400
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.980
TRAINING: | Iteration [4/12] | Loss 0.18 | Norm 3.702
TRAINING: | Iteration [5/12] | Loss 0.16 | Norm 3.172
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 1.536
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 1.136
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.545
TRAINING: | Iteration [9/12] | Loss 0.14 | Norm 2.481
TRAINING: | Iteration [10/12] | Loss 0.16 | Norm 3.148
TRAINING: | Iteration [11/12] | Loss 0.21 | Norm 3.188
TRAINING: | Iteration [12/12] | Loss 0.17 | Norm 2.179
Epoch: 1369/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.051
TRAINING: | Iteration [2/12] | Loss 0.14 | Norm 2.101
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 1.634
TRAINING: | Iteration [4/12] | Loss 0.14 | Norm 2.170
TRAINING: | Iteration [5/12] | Loss 0.16 | Norm 2.928
TRAINING: | Iteration [6/12] | Loss 0.08 | Norm 1.451
TRAINING: | Iteration [7/12] | Loss 0.13 | Norm 1.596
TRAINING: | Iteration [8/12] | Loss 0.35 | Norm 4.950
TRAINING: | Iteration [9/12] | Loss 0.23 | Norm 3.850
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 1.758
TRAINING: | Iteration [11/12] | Loss 0.32 | Norm 5.000
TRAINING: | Iteration [12/12] | Loss 0.19 | Norm 2.420
Epoch: 1370/10000 | Epoch Time: 0.102 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.14 | Norm 2.148
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 2.472
TRAINING: | Iteration [3/12] | Loss 0.09 | Norm 1.100
TRAINING: | Iteration [4/12] | Loss 0.07 | Norm 0.464
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 2.187
TRAINING: | Iteration [6/12] | Loss 0.16 | Norm 2.265
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 1.733
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 0.954
TRAINING: | Iteration [9/12] | Loss 0.21 | Norm 3.467
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 1.784
TRAINING: | Iteration [11/12] | Loss 0.32 | Norm 4.463
TRAINING: | Iteration [12/12] | Loss 0.18 | Norm 3.272
Epoch: 1371/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 1.402
TRAINING: | Iteration [2/12] | Loss 0.15 | Norm 2.096
TRAINING: | Iteration [3/12] | Loss 0.15 | Norm 3.090
TRAINING: | Iteration [4/12] | Loss 0.18 | Norm 2.407
TRAINING: | Iteration [5/12] | Loss 0.15 | Norm 3.567
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 1.410
TRAINING: | Iteration [7/12] | Loss 0.19 | Norm 3.692
TRAINING: | Iteration [8/12] | Loss 0.15 | Norm 3.751
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 1.870
TRAINING: | Iteration [10/12] | Loss 0.18 | Norm 3.237
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 2.539
TRAINING: | Iteration [12/12] | Loss 0.22 | Norm 2.104
Epoch: 1372/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.15 | Norm 2.484
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 1.251
TRAINING: | Iteration [3/12] | Loss 0.15 | Norm 2.995
TRAINING: | Iteration [4/12] | Loss 0.68 | Norm 5.000
TRAINING: | Iteration [5/12] | Loss 0.18 | Norm 3.335
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 1.359
TRAINING: | Iteration [7/12] | Loss 0.25 | Norm 3.350
TRAINING: | Iteration [8/12] | Loss 0.21 | Norm 3.527
TRAINING: | Iteration [9/12] | Loss 0.17 | Norm 2.865
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 3.161
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 1.101
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 2.119
Epoch: 1373/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.14 | Norm 1.970
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 1.950
TRAINING: | Iteration [3/12] | Loss 0.10 | Norm 1.949
TRAINING: | Iteration [4/12] | Loss 0.17 | Norm 3.438
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 2.425
TRAINING: | Iteration [6/12] | Loss 0.18 | Norm 4.487
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 1.933
TRAINING: | Iteration [8/12] | Loss 0.22 | Norm 2.728
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 2.064
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 1.718
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 3.318
TRAINING: | Iteration [12/12] | Loss 0.16 | Norm 2.764
Epoch: 1374/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.17 | Norm 3.076
TRAINING: | Iteration [2/12] | Loss 0.14 | Norm 2.302
TRAINING: | Iteration [3/12] | Loss 0.15 | Norm 3.248
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 3.321
TRAINING: | Iteration [5/12] | Loss 0.13 | Norm 1.459
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 2.222
TRAINING: | Iteration [7/12] | Loss 0.21 | Norm 4.256
TRAINING: | Iteration [8/12] | Loss 0.16 | Norm 2.543
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 2.660
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 3.256
TRAINING: | Iteration [11/12] | Loss 0.17 | Norm 3.099
TRAINING: | Iteration [12/12] | Loss 0.42 | Norm 5.000
Epoch: 1375/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.22 | Norm 4.125
TRAINING: | Iteration [2/12] | Loss 0.38 | Norm 5.000
TRAINING: | Iteration [3/12] | Loss 0.23 | Norm 4.712
TRAINING: | Iteration [4/12] | Loss 0.16 | Norm 3.582
TRAINING: | Iteration [5/12] | Loss 0.21 | Norm 2.637
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 1.325
TRAINING: | Iteration [7/12] | Loss 0.20 | Norm 3.852
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 2.208
TRAINING: | Iteration [9/12] | Loss 0.15 | Norm 3.548
TRAINING: | Iteration [10/12] | Loss 0.30 | Norm 5.000
TRAINING: | Iteration [11/12] | Loss 0.30 | Norm 4.850
TRAINING: | Iteration [12/12] | Loss 0.41 | Norm 5.000
Epoch: 1376/10000 | Epoch Time: 0.106 seconds
TRAINING: | Iteration [1/12] | Loss 0.14 | Norm 3.372
TRAINING: | Iteration [2/12] | Loss 0.14 | Norm 2.017
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 1.293
TRAINING: | Iteration [4/12] | Loss 0.15 | Norm 2.999
TRAINING: | Iteration [5/12] | Loss 0.14 | Norm 1.816
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.493
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 2.286
TRAINING: | Iteration [8/12] | Loss 0.27 | Norm 5.000
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 1.545
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 2.388
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.203
TRAINING: | Iteration [12/12] | Loss 0.20 | Norm 3.545
Epoch: 1377/10000 | Epoch Time: 0.105 seconds
TRAINING: | Iteration [1/12] | Loss 0.14 | Norm 4.116
TRAINING: | Iteration [2/12] | Loss 0.17 | Norm 3.005
TRAINING: | Iteration [3/12] | Loss 0.23 | Norm 4.060
TRAINING: | Iteration [4/12] | Loss 0.21 | Norm 4.030
TRAINING: | Iteration [5/12] | Loss 0.20 | Norm 3.834
TRAINING: | Iteration [6/12] | Loss 0.22 | Norm 4.094
TRAINING: | Iteration [7/12] | Loss 0.25 | Norm 4.976
TRAINING: | Iteration [8/12] | Loss 0.23 | Norm 3.892
TRAINING: | Iteration [9/12] | Loss 0.14 | Norm 3.854
TRAINING: | Iteration [10/12] | Loss 0.19 | Norm 4.142
TRAINING: | Iteration [11/12] | Loss 0.17 | Norm 2.529
TRAINING: | Iteration [12/12] | Loss 0.42 | Norm 5.000
Epoch: 1378/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 2.169
TRAINING: | Iteration [2/12] | Loss 0.30 | Norm 4.841
TRAINING: | Iteration [3/12] | Loss 0.16 | Norm 2.857
TRAINING: | Iteration [4/12] | Loss 0.28 | Norm 3.650
TRAINING: | Iteration [5/12] | Loss 0.11 | Norm 1.163
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 1.407
TRAINING: | Iteration [7/12] | Loss 0.16 | Norm 2.722
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 1.497
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 1.802
TRAINING: | Iteration [10/12] | Loss 0.25 | Norm 4.299
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 1.521
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 1.626
Epoch: 1379/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 2.584
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 3.116
TRAINING: | Iteration [3/12] | Loss 0.23 | Norm 4.545
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 2.323
TRAINING: | Iteration [5/12] | Loss 0.23 | Norm 3.883
TRAINING: | Iteration [6/12] | Loss 0.24 | Norm 3.292
TRAINING: | Iteration [7/12] | Loss 0.16 | Norm 2.856
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 1.200
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 2.058
TRAINING: | Iteration [10/12] | Loss 0.15 | Norm 2.328
TRAINING: | Iteration [11/12] | Loss 0.16 | Norm 2.621
TRAINING: | Iteration [12/12] | Loss 0.16 | Norm 2.151
Epoch: 1380/10000 | Epoch Time: 0.100 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.14 | Norm 2.315
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 1.094
TRAINING: | Iteration [3/12] | Loss 0.20 | Norm 4.565
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 1.980
TRAINING: | Iteration [5/12] | Loss 0.26 | Norm 4.533
TRAINING: | Iteration [6/12] | Loss 0.16 | Norm 2.694
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 1.887
TRAINING: | Iteration [8/12] | Loss 0.42 | Norm 5.000
TRAINING: | Iteration [9/12] | Loss 0.10 | Norm 1.941
TRAINING: | Iteration [10/12] | Loss 0.32 | Norm 4.883
TRAINING: | Iteration [11/12] | Loss 0.15 | Norm 2.278
TRAINING: | Iteration [12/12] | Loss 0.11 | Norm 2.398
Epoch: 1381/10000 | Epoch Time: 0.104 seconds
TRAINING: | Iteration [1/12] | Loss 0.33 | Norm 5.000
TRAINING: | Iteration [2/12] | Loss 0.11 | Norm 0.975
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 1.794
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 2.126
TRAINING: | Iteration [5/12] | Loss 0.19 | Norm 4.710
TRAINING: | Iteration [6/12] | Loss 0.43 | Norm 5.000
TRAINING: | Iteration [7/12] | Loss 0.13 | Norm 2.754
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 0.760
TRAINING: | Iteration [9/12] | Loss 0.11 | Norm 1.455
TRAINING: | Iteration [10/12] | Loss 0.08 | Norm 1.215
TRAINING: | Iteration [11/12] | Loss 0.21 | Norm 4.266
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 1.899
Epoch: 1382/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 2.546
TRAINING: | Iteration [2/12] | Loss 0.19 | Norm 3.970
TRAINING: | Iteration [3/12] | Loss 0.14 | Norm 1.801
TRAINING: | Iteration [4/12] | Loss 0.32 | Norm 4.646
TRAINING: | Iteration [5/12] | Loss 0.27 | Norm 4.376
TRAINING: | Iteration [6/12] | Loss 0.18 | Norm 2.750
TRAINING: | Iteration [7/12] | Loss 0.20 | Norm 2.924
TRAINING: | Iteration [8/12] | Loss 0.17 | Norm 2.287
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 2.209
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 2.218
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 1.752
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 1.183
Epoch: 1383/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.17 | Norm 2.536
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 1.302
TRAINING: | Iteration [3/12] | Loss 0.23 | Norm 3.589
TRAINING: | Iteration [4/12] | Loss 0.15 | Norm 2.357
TRAINING: | Iteration [5/12] | Loss 0.18 | Norm 3.359
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.710
TRAINING: | Iteration [7/12] | Loss 0.14 | Norm 2.333
TRAINING: | Iteration [8/12] | Loss 0.17 | Norm 3.544
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 1.735
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 1.252
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.339
TRAINING: | Iteration [12/12] | Loss 0.15 | Norm 1.797
Epoch: 1384/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.16 | Norm 2.655
TRAINING: | Iteration [2/12] | Loss 0.20 | Norm 3.408
TRAINING: | Iteration [3/12] | Loss 0.23 | Norm 3.216
TRAINING: | Iteration [4/12] | Loss 0.15 | Norm 1.051
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.111
TRAINING: | Iteration [6/12] | Loss 0.12 | Norm 3.328
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 1.857
TRAINING: | Iteration [8/12] | Loss 0.15 | Norm 2.421
TRAINING: | Iteration [9/12] | Loss 0.17 | Norm 3.125
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 2.799
TRAINING: | Iteration [11/12] | Loss 0.31 | Norm 4.481
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.925
Epoch: 1385/10000 | Epoch Time: 0.117 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 2.686
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 2.067
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 1.390
TRAINING: | Iteration [4/12] | Loss 0.20 | Norm 3.314
TRAINING: | Iteration [5/12] | Loss 0.16 | Norm 2.720
TRAINING: | Iteration [6/12] | Loss 0.14 | Norm 1.513
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 1.329
TRAINING: | Iteration [8/12] | Loss 0.08 | Norm 1.479
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 1.951
TRAINING: | Iteration [10/12] | Loss 0.10 | Norm 1.416
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 1.513
TRAINING: | Iteration [12/12] | Loss 0.17 | Norm 1.531
Epoch: 1386/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.17 | Norm 2.900
TRAINING: | Iteration [2/12] | Loss 0.22 | Norm 4.190
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 1.307
TRAINING: | Iteration [4/12] | Loss 0.19 | Norm 1.364
TRAINING: | Iteration [5/12] | Loss 0.16 | Norm 2.624
TRAINING: | Iteration [6/12] | Loss 0.24 | Norm 5.000
TRAINING: | Iteration [7/12] | Loss 0.16 | Norm 2.662
TRAINING: | Iteration [8/12] | Loss 0.41 | Norm 5.000
TRAINING: | Iteration [9/12] | Loss 0.17 | Norm 4.657
TRAINING: | Iteration [10/12] | Loss 0.19 | Norm 4.210
TRAINING: | Iteration [11/12] | Loss 0.15 | Norm 4.010
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.709
Epoch: 1387/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.21 | Norm 3.127
TRAINING: | Iteration [2/12] | Loss 0.30 | Norm 5.000
TRAINING: | Iteration [3/12] | Loss 0.11 | Norm 3.510
TRAINING: | Iteration [4/12] | Loss 0.13 | Norm 2.137
TRAINING: | Iteration [5/12] | Loss 0.14 | Norm 3.165
TRAINING: | Iteration [6/12] | Loss 0.09 | Norm 1.866
TRAINING: | Iteration [7/12] | Loss 0.14 | Norm 2.721
TRAINING: | Iteration [8/12] | Loss 0.10 | Norm 1.240
TRAINING: | Iteration [9/12] | Loss 0.24 | Norm 4.354
TRAINING: | Iteration [10/12] | Loss 0.17 | Norm 1.828
TRAINING: | Iteration [11/12] | Loss 0.16 | Norm 2.286
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 1.953
Epoch: 1388/10000 | Epoch Time: 0.115 seconds
TRAINING: | Iteration [1/12] | Loss 0.14 | Norm 2.071
TRAINING: | Iteration [2/12] | Loss 0.25 | Norm 3.698
TRAINING: | Iteration [3/12] | Loss 0.15 | Norm 3.268
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 1.700
TRAINING: | Iteration [5/12] | Loss 0.19 | Norm 2.765
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 1.919
TRAINING: | Iteration [7/12] | Loss 0.13 | Norm 2.167
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 1.745
TRAINING: | Iteration [9/12] | Loss 0.30 | Norm 4.979
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 2.036
TRAINING: | Iteration [11/12] | Loss 0.13 | Norm 2.022
TRAINING: | Iteration [12/12] | Loss 0.13 | Norm 1.393
Epoch: 1389/10000 | Epoch Time: 0.118 seconds
TRAINING: | Iteration [1/12] | Loss 0.17 | Norm 2.484
TRAINING: | Iteration [2/12] | Loss 0.09 | Norm 1.176
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 0.840
TRAINING: | Iteration [4/12] | Loss 0.40 | Norm 5.000
TRAINING: | Iteration [5/12] | Loss 0.50 | Norm 5.000
TRAINING: | Iteration [6/12] | Loss 0.17 | Norm 3.093
TRAINING: | Iteration [7/12] | Loss 0.30 | Norm 5.000
TRAINING: | Iteration [8/12] | Loss 0.15 | Norm 4.842
TRAINING: | Iteration [9/12] | Loss 0.13 | Norm 1.879
TRAINING: | Iteration [10/12] | Loss 0.17 | Norm 1.828
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 1.319
TRAINING: | Iteration [12/12] | Loss 0.16 | Norm 2.500
Epoch: 1390/10000 | Epoch Time: 0.102 seconds
Saving Model
TRAINING: | Iteration [1/12] | Loss 0.17 | Norm 2.874
TRAINING: | Iteration [2/12] | Loss 0.16 | Norm 2.813
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 3.241
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 1.255
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 1.066
TRAINING: | Iteration [6/12] | Loss 0.30 | Norm 4.268
TRAINING: | Iteration [7/12] | Loss 0.17 | Norm 3.035
TRAINING: | Iteration [8/12] | Loss 0.14 | Norm 2.705
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 1.851
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 2.227
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.564
TRAINING: | Iteration [12/12] | Loss 0.30 | Norm 5.000
Epoch: 1391/10000 | Epoch Time: 0.119 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 1.583
TRAINING: | Iteration [2/12] | Loss 0.22 | Norm 3.113
TRAINING: | Iteration [3/12] | Loss 0.15 | Norm 2.929
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 1.917
TRAINING: | Iteration [5/12] | Loss 0.27 | Norm 3.772
TRAINING: | Iteration [6/12] | Loss 0.13 | Norm 1.609
TRAINING: | Iteration [7/12] | Loss 0.17 | Norm 2.392
TRAINING: | Iteration [8/12] | Loss 0.11 | Norm 0.973
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 1.263
TRAINING: | Iteration [10/12] | Loss 0.17 | Norm 2.775
TRAINING: | Iteration [11/12] | Loss 0.11 | Norm 1.041
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 2.679
Epoch: 1392/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 2.431
TRAINING: | Iteration [2/12] | Loss 0.16 | Norm 3.392
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 2.970
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 1.006
TRAINING: | Iteration [5/12] | Loss 0.17 | Norm 4.002
TRAINING: | Iteration [6/12] | Loss 0.11 | Norm 2.119
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 1.201
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 1.930
TRAINING: | Iteration [9/12] | Loss 0.21 | Norm 2.895
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 2.052
TRAINING: | Iteration [11/12] | Loss 0.14 | Norm 2.170
TRAINING: | Iteration [12/12] | Loss 0.20 | Norm 2.996
Epoch: 1393/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.19 | Norm 3.330
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 1.907
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 1.715
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 1.748
TRAINING: | Iteration [5/12] | Loss 0.08 | Norm 2.268
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 1.026
TRAINING: | Iteration [7/12] | Loss 0.12 | Norm 1.608
TRAINING: | Iteration [8/12] | Loss 0.13 | Norm 1.934
TRAINING: | Iteration [9/12] | Loss 0.16 | Norm 3.269
TRAINING: | Iteration [10/12] | Loss 0.26 | Norm 4.370
TRAINING: | Iteration [11/12] | Loss 0.12 | Norm 1.392
TRAINING: | Iteration [12/12] | Loss 0.14 | Norm 3.076
Epoch: 1394/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.11 | Norm 0.973
TRAINING: | Iteration [2/12] | Loss 0.16 | Norm 2.154
TRAINING: | Iteration [3/12] | Loss 0.14 | Norm 2.031
TRAINING: | Iteration [4/12] | Loss 0.12 | Norm 1.698
TRAINING: | Iteration [5/12] | Loss 0.09 | Norm 2.135
TRAINING: | Iteration [6/12] | Loss 0.14 | Norm 2.337
TRAINING: | Iteration [7/12] | Loss 0.15 | Norm 2.756
TRAINING: | Iteration [8/12] | Loss 0.35 | Norm 5.000
TRAINING: | Iteration [9/12] | Loss 0.36 | Norm 5.000
TRAINING: | Iteration [10/12] | Loss 0.13 | Norm 2.940
TRAINING: | Iteration [11/12] | Loss 0.14 | Norm 1.384
TRAINING: | Iteration [12/12] | Loss 0.34 | Norm 4.891
Epoch: 1395/10000 | Epoch Time: 0.105 seconds
TRAINING: | Iteration [1/12] | Loss 0.10 | Norm 1.109
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 1.510
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 1.147
TRAINING: | Iteration [4/12] | Loss 0.11 | Norm 1.829
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 2.198
TRAINING: | Iteration [6/12] | Loss 0.19 | Norm 2.000
TRAINING: | Iteration [7/12] | Loss 0.11 | Norm 1.578
TRAINING: | Iteration [8/12] | Loss 0.12 | Norm 1.879
TRAINING: | Iteration [9/12] | Loss 0.22 | Norm 3.157
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 1.296
TRAINING: | Iteration [11/12] | Loss 0.15 | Norm 2.744
TRAINING: | Iteration [12/12] | Loss 0.09 | Norm 1.896
Epoch: 1396/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.13 | Norm 2.752
TRAINING: | Iteration [2/12] | Loss 0.12 | Norm 0.985
TRAINING: | Iteration [3/12] | Loss 0.15 | Norm 2.010
TRAINING: | Iteration [4/12] | Loss 0.17 | Norm 2.932
TRAINING: | Iteration [5/12] | Loss 0.31 | Norm 5.000
TRAINING: | Iteration [6/12] | Loss 0.23 | Norm 4.499
TRAINING: | Iteration [7/12] | Loss 0.10 | Norm 1.628
TRAINING: | Iteration [8/12] | Loss 0.15 | Norm 4.422
TRAINING: | Iteration [9/12] | Loss 0.12 | Norm 1.527
TRAINING: | Iteration [10/12] | Loss 0.14 | Norm 1.769
TRAINING: | Iteration [11/12] | Loss 0.09 | Norm 1.343
TRAINING: | Iteration [12/12] | Loss 0.12 | Norm 1.604
Epoch: 1397/10000 | Epoch Time: 0.102 seconds
TRAINING: | Iteration [1/12] | Loss 0.16 | Norm 4.776
TRAINING: | Iteration [2/12] | Loss 0.10 | Norm 1.717
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 1.059
TRAINING: | Iteration [4/12] | Loss 0.18 | Norm 2.386
TRAINING: | Iteration [5/12] | Loss 0.12 | Norm 3.104
TRAINING: | Iteration [6/12] | Loss 0.15 | Norm 3.639
TRAINING: | Iteration [7/12] | Loss 0.15 | Norm 3.246
TRAINING: | Iteration [8/12] | Loss 0.22 | Norm 3.075
TRAINING: | Iteration [9/12] | Loss 0.09 | Norm 2.320
TRAINING: | Iteration [10/12] | Loss 0.11 | Norm 1.699
TRAINING: | Iteration [11/12] | Loss 0.16 | Norm 1.304
TRAINING: | Iteration [12/12] | Loss 0.16 | Norm 2.561
Epoch: 1398/10000 | Epoch Time: 0.101 seconds
TRAINING: | Iteration [1/12] | Loss 0.16 | Norm 1.812
TRAINING: | Iteration [2/12] | Loss 0.16 | Norm 4.042
TRAINING: | Iteration [3/12] | Loss 0.13 | Norm 2.935
TRAINING: | Iteration [4/12] | Loss 0.17 | Norm 3.328
TRAINING: | Iteration [5/12] | Loss 0.16 | Norm 2.757
TRAINING: | Iteration [6/12] | Loss 0.22 | Norm 2.748
TRAINING: | Iteration [7/12] | Loss 0.13 | Norm 2.083
TRAINING: | Iteration [8/12] | Loss 0.15 | Norm 4.328
TRAINING: | Iteration [9/12] | Loss 0.27 | Norm 4.360
TRAINING: | Iteration [10/12] | Loss 0.12 | Norm 1.513
TRAINING: | Iteration [11/12] | Loss 0.18 | Norm 3.806
TRAINING: | Iteration [12/12] | Loss 0.10 | Norm 1.013
Epoch: 1399/10000 | Epoch Time: 0.103 seconds
TRAINING: | Iteration [1/12] | Loss 0.12 | Norm 2.072
TRAINING: | Iteration [2/12] | Loss 0.13 | Norm 2.110
TRAINING: | Iteration [3/12] | Loss 0.12 | Norm 1.875
TRAINING: | Iteration [4/12] | Loss 0.14 | Norm 1.350
TRAINING: | Iteration [5/12] | Loss 0.20 | Norm 2.845
TRAINING: | Iteration [6/12] | Loss 0.10 | Norm 1.521
TRAINING: | Iteration [7/12] | Loss 0.18 | Norm 2.900
TRAINING: | Iteration [8/12] | Loss 0.15 | Norm 1.973
TRAINING: | Iteration [9/12] | Loss 0.19 | Norm 3.128
TRAINING: | Iteration [10/12] | Loss 0.15 | Norm 2.835
TRAINING: | Iteration [11/12] | Loss 0.20 | Norm 4.220
TRAINING: | Iteration [12/12] | Loss 0.27 | Norm 3.955
Epoch: 1400/10000 | Epoch Time: 0.104 seconds
Saving Model
